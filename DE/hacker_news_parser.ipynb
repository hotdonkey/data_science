{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n",
      "HTTPSConnectionPool(host='www.bbc.com', port=443): Max retries exceeded with url: /news/world-australia-67340901 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1002)')))\n",
      "HTTPSConnectionPool(host='www.bbc.com', port=443): Max retries exceeded with url: /news/uk-england-wiltshire-67336495 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1002)')))\n",
      "HTTPSConnectionPool(host='www.telegraph.co.uk', port=443): Max retries exceeded with url: /politics/2023/11/07/kings-speech-driverless-cars-users-not-prosecuted/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1002)')))\n",
      "Invalid URL 'item?id=38184195': No scheme supplied. Perhaps you meant https://item?id=38184195?\n",
      "Invalid URL 'item?id=38182965': No scheme supplied. Perhaps you meant https://item?id=38182965?\n",
      "Invalid URL 'item?id=38161369': No scheme supplied. Perhaps you meant https://item?id=38161369?\n",
      "HTTPSConnectionPool(host='www.xfire.com', port=443): Max retries exceeded with url: /xbox-facing-backlash-recent-ai-partnership/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1002)')))\n",
      "('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n",
      "HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=3.0)\n",
      "Invalid URL 'item?id=38185403': No scheme supplied. Perhaps you meant https://item?id=38185403?\n",
      "Invalid URL 'item?id=38181383': No scheme supplied. Perhaps you meant https://item?id=38181383?\n",
      "HTTPSConnectionPool(host='iknowwhatyoudownload.com', port=443): Read timed out. (read timeout=3.0)\n",
      "('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>points</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>load_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Northlight technology in Alan Wake 2 (remedyga...</td>\n",
       "      <td>349</td>\n",
       "      <td>167 comments</td>\n",
       "      <td>38180846</td>\n",
       "      <td>https://www.remedygames.com/article/how-northl...</td>\n",
       "      <td>0.65255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh my poor business logic (rednafi.com)</td>\n",
       "      <td>92</td>\n",
       "      <td>41 comments</td>\n",
       "      <td>38159363</td>\n",
       "      <td>https://rednafi.com/misc/oh_my_poor_business_l...</td>\n",
       "      <td>0.39949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go, Containers, and the Linux Scheduler (river...</td>\n",
       "      <td>245</td>\n",
       "      <td>90 comments</td>\n",
       "      <td>38181346</td>\n",
       "      <td>https://www.riverphillips.dev/blog/go-cfs/</td>\n",
       "      <td>0.314109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect Dark: Recompiled (hackaday.com)</td>\n",
       "      <td>34</td>\n",
       "      <td>10 comments</td>\n",
       "      <td>38159905</td>\n",
       "      <td>https://hackaday.com/2023/11/05/perfect-dark-r...</td>\n",
       "      <td>0.381835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interactive examples for learning jq (ishan.page)</td>\n",
       "      <td>38</td>\n",
       "      <td>5 comments</td>\n",
       "      <td>38186153</td>\n",
       "      <td>https://ishan.page/blog/2023-11-06-jq-by-example/</td>\n",
       "      <td>1.454779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>RenderDoc is a free MIT licensed stand-alone g...</td>\n",
       "      <td>15</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>38154296</td>\n",
       "      <td>https://renderdoc.org/</td>\n",
       "      <td>1.389319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Representations and srategies for games with i...</td>\n",
       "      <td>90</td>\n",
       "      <td>5 comments</td>\n",
       "      <td>38144772</td>\n",
       "      <td>https://www2.cs.sfu.ca/~bbart/personal/masters...</td>\n",
       "      <td>1.520471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Mass producing the most expensive rice cooker ...</td>\n",
       "      <td>125</td>\n",
       "      <td>225 comments</td>\n",
       "      <td>38142586</td>\n",
       "      <td>https://www.youtube.com/watch?v=xLCwr8qG1p4</td>\n",
       "      <td>0.294055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Cortextual (cortextual.net)</td>\n",
       "      <td>68</td>\n",
       "      <td>12 comments</td>\n",
       "      <td>38149839</td>\n",
       "      <td>https://cortextual.net/</td>\n",
       "      <td>0.43771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Curated links to the best documentaries: over ...</td>\n",
       "      <td>17</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>38156039</td>\n",
       "      <td>https://rocumentaries.com/</td>\n",
       "      <td>1.665746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  news points     n_comments  \\\n",
       "0    Northlight technology in Alan Wake 2 (remedyga...    349   167 comments   \n",
       "1              Oh my poor business logic (rednafi.com)     92    41 comments   \n",
       "2    Go, Containers, and the Linux Scheduler (river...    245    90 comments   \n",
       "3              Perfect Dark: Recompiled (hackaday.com)     34    10 comments   \n",
       "4    Interactive examples for learning jq (ishan.page)     38     5 comments   \n",
       "..                                                 ...    ...            ...   \n",
       "295  RenderDoc is a free MIT licensed stand-alone g...     15      1 comment   \n",
       "296  Representations and srategies for games with i...     90     5 comments   \n",
       "297  Mass producing the most expensive rice cooker ...    125   225 comments   \n",
       "298                        Cortextual (cortextual.net)     68    12 comments   \n",
       "299  Curated links to the best documentaries: over ...     17     2 comments   \n",
       "\n",
       "           id                                               link load_time  \n",
       "0    38180846  https://www.remedygames.com/article/how-northl...   0.65255  \n",
       "1    38159363  https://rednafi.com/misc/oh_my_poor_business_l...   0.39949  \n",
       "2    38181346         https://www.riverphillips.dev/blog/go-cfs/  0.314109  \n",
       "3    38159905  https://hackaday.com/2023/11/05/perfect-dark-r...  0.381835  \n",
       "4    38186153  https://ishan.page/blog/2023-11-06-jq-by-example/  1.454779  \n",
       "..        ...                                                ...       ...  \n",
       "295  38154296                             https://renderdoc.org/  1.389319  \n",
       "296  38144772  https://www2.cs.sfu.ca/~bbart/personal/masters...  1.520471  \n",
       "297  38142586        https://www.youtube.com/watch?v=xLCwr8qG1p4  0.294055  \n",
       "298  38149839                            https://cortextual.net/   0.43771  \n",
       "299  38156039                         https://rocumentaries.com/  1.665746  \n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Парсер на основе связки pandas, requests, bs4\n",
    "\n",
    "def hacker_news(pages=10):\n",
    "\n",
    "    news = pd.DataFrame(columns=['news', 'points'])\n",
    "\n",
    "    # Функция расчета времени\n",
    "    def get_load_time(article_url):\n",
    "        # будем ждать 3 секунды, иначе выводить exception и присваивать константное значение\n",
    "        try:\n",
    "\n",
    "            # делаем запрос по url статьи article_url\n",
    "            response = requests.get(\n",
    "                article_url, stream=True, timeout=3.000\n",
    "            )\n",
    "            # получаем время загрузки страницы\n",
    "            load_time = response.elapsed.total_seconds()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            load_time = \">3\"\n",
    "        return load_time\n",
    "\n",
    "    # Функция получения id, news_headline, rating, link\n",
    "    def get_info(page=1):\n",
    "        url = f'https://news.ycombinator.com/?p={page}'\n",
    "\n",
    "        responce = requests.get(url)\n",
    "\n",
    "        # Получаем заголовок\n",
    "        page = pd.read_html(responce.text)[2]\n",
    "        page.drop([1], axis=1, inplace=True)\n",
    "        page.rename(columns={0: 'index', 2: 'news'}, inplace=True)\n",
    "\n",
    "        page = page[(~page['news'].isna()) & (page['news'] != 'More')]\n",
    "\n",
    "        # Получаем рейтинг\n",
    "        points = pd.DataFrame(\n",
    "            page['news'][page['index'].isna()].reset_index(drop=True))\n",
    "        points.rename(columns={'news': 'points'}, inplace=True)\n",
    "\n",
    "        # Проверяем есть ли у новости рейтинг, если его нет то присваиваем ноль\n",
    "        points['contains_points'] = points['points'].str.contains(\"points\")\n",
    "        points['points'] = points['points'].str.split(' ')\n",
    "\n",
    "        def set_points(row):\n",
    "            if row['contains_points']:\n",
    "                return row[0][0]\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        points['points'] = points.apply(set_points, axis=1)\n",
    "        \n",
    "        \n",
    "        # Получаем колличество комментариев\n",
    "        comments = pd.DataFrame(\n",
    "            page['news'][page['index'].isna()].reset_index(drop=True))\n",
    "        comments.rename(columns={'news': 'comments'}, inplace=True)\n",
    "        \n",
    "        comments['n_comments'] = comments['comments'].str.split('|')\n",
    "        comments['contains_comments'] = comments['comments'].str.contains(\"comment*\")\n",
    "        comments['n_comments'] = comments['n_comments'].apply(lambda x: x[-1])\n",
    "\n",
    "\n",
    "        def set_comments(row):\n",
    "            if row['contains_comments']:\n",
    "                return row[1]\n",
    "            else:\n",
    "                return '0 comments'\n",
    "\n",
    "        # Чистим на отсутвие \n",
    "        comments['n_comments'] = comments.apply(set_comments, axis=1)\n",
    "\n",
    "        # Прикручиваем рейтинг к новости\n",
    "        news = pd.DataFrame(\n",
    "            page['news'][~page['index'].isna()].reset_index(drop=True))\n",
    "\n",
    "        result = pd.concat([news, points['points'], comments['n_comments']], axis=1)\n",
    "        \n",
    "        # Начинаем собирать ссылки и id\n",
    "        soup = BeautifulSoup(responce.text, 'html.parser')\n",
    "\n",
    "        link_list = []\n",
    "\n",
    "        for i in range(len(soup.find_all(class_='title'))):\n",
    "            try:\n",
    "                link = soup.find_all(class_='title')[i].find('a')['href']\n",
    "                text = soup.find_all(class_='title')[i].text\n",
    "\n",
    "                if text != 'More':\n",
    "                    link_list.append([text, link])\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Получаем id новостей\n",
    "        trs = soup.find_all('tr', class_='athing')\n",
    "        id_list = []\n",
    "\n",
    "        for tr in trs:\n",
    "            tr_id = tr['id']\n",
    "            id_list.append(tr_id)\n",
    "\n",
    "        id = pd.DataFrame(id_list, columns=['id'])\n",
    "        \n",
    "        # Получаем ссылки новостей\n",
    "        links = pd.DataFrame(link_list)\n",
    "        links = pd.concat([id, links], axis=1)\n",
    "\n",
    "        links.rename(columns={0: 'news', 1: 'link'}, inplace=True)\n",
    "\n",
    "        # Прикручиваем ссылки\n",
    "        result = pd.merge(left=result, right=links)\n",
    "\n",
    "        # Расчитываем время\n",
    "        result['load_time'] = result['link'].apply(get_load_time)\n",
    "\n",
    "        return result\n",
    "\n",
    "    for i in range(pages):\n",
    "        news = pd.concat([news, get_info(i+1)])\n",
    "\n",
    "    news.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return news\n",
    "\n",
    "\n",
    "test = hacker_news(10)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"./data/hacker.xlsx\") as writer:\n",
    "    test.to_excel(writer, sheet_name='hacker_news', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
