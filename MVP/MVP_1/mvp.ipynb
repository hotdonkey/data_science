{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Рекомендательная система книг.\n",
    "2. Решение задачи кредитного скоринга.\n",
    "3. Подсчет посетителей в магазине по видео камере.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендательная система книг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_books = './data/books.csv'\n",
    "path_ratings = './data/input/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>2657</td>\n",
       "      <td>3275794</td>\n",
       "      <td>487</td>\n",
       "      <td>61120081</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>...</td>\n",
       "      <td>3198671</td>\n",
       "      <td>3340896</td>\n",
       "      <td>72586</td>\n",
       "      <td>60427</td>\n",
       "      <td>117415</td>\n",
       "      <td>446835</td>\n",
       "      <td>1001952</td>\n",
       "      <td>1714267</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>4671</td>\n",
       "      <td>245494</td>\n",
       "      <td>1356</td>\n",
       "      <td>743273567</td>\n",
       "      <td>9.780743e+12</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>...</td>\n",
       "      <td>2683664</td>\n",
       "      <td>2773745</td>\n",
       "      <td>51992</td>\n",
       "      <td>86236</td>\n",
       "      <td>197621</td>\n",
       "      <td>606158</td>\n",
       "      <td>936012</td>\n",
       "      <td>947718</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  book_id  best_book_id  work_id  books_count       isbn        isbn13  \\\n",
       "0   1  2767052       2767052  2792775          272  439023483  9.780439e+12   \n",
       "1   2        3             3  4640799          491  439554934  9.780440e+12   \n",
       "2   3    41865         41865  3212258          226  316015849  9.780316e+12   \n",
       "3   4     2657          2657  3275794          487   61120081  9.780061e+12   \n",
       "4   5     4671          4671   245494         1356  743273567  9.780743e+12   \n",
       "\n",
       "                        authors  original_publication_year  \\\n",
       "0               Suzanne Collins                     2008.0   \n",
       "1  J.K. Rowling, Mary GrandPrÃ©                     1997.0   \n",
       "2               Stephenie Meyer                     2005.0   \n",
       "3                    Harper Lee                     1960.0   \n",
       "4           F. Scott Fitzgerald                     1925.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "3                     To Kill a Mockingbird  ...       3198671   \n",
       "4                          The Great Gatsby  ...       2683664   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "3            3340896                    72586      60427     117415   \n",
       "4            2773745                    51992      86236     197621   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "3     446835    1001952    1714267   \n",
       "4     606158     936012     947718   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "3  https://images.gr-assets.com/books/1361975680m...   \n",
       "4  https://images.gr-assets.com/books/1490528560m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "3  https://images.gr-assets.com/books/1361975680s...  \n",
       "4  https://images.gr-assets.com/books/1490528560s...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv(path_books, encoding = \"ISO-8859-1\")\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[[\"book_id\",\"original_title\",'authors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  user_id  rating\n",
       "0        1      314       5\n",
       "1        1      439       3\n",
       "2        1      588       5\n",
       "3        1     1169       4\n",
       "4        1     1185       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(path_ratings, encoding = \"ISO-8859-1\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>314</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>2077</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>2487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>2900</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                            original_title  \\\n",
       "0        3  Harry Potter and the Philosopher's Stone   \n",
       "1        3  Harry Potter and the Philosopher's Stone   \n",
       "2        3  Harry Potter and the Philosopher's Stone   \n",
       "3        3  Harry Potter and the Philosopher's Stone   \n",
       "4        3  Harry Potter and the Philosopher's Stone   \n",
       "\n",
       "                        authors  user_id  rating  \n",
       "0  J.K. Rowling, Mary GrandPrÃ©      314       3  \n",
       "1  J.K. Rowling, Mary GrandPrÃ©      588       1  \n",
       "2  J.K. Rowling, Mary GrandPrÃ©     2077       2  \n",
       "3  J.K. Rowling, Mary GrandPrÃ©     2487       3  \n",
       "4  J.K. Rowling, Mary GrandPrÃ©     2900       3  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.merge(left=books, right=ratings, left_on=\"book_id\", right_on=\"book_id\")\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©, Rufus Beck</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                   authors  \\\n",
       "0        1              J.K. Rowling, Mary GrandPrÃ©   \n",
       "1        2              J.K. Rowling, Mary GrandPrÃ©   \n",
       "2        3              J.K. Rowling, Mary GrandPrÃ©   \n",
       "3        5  J.K. Rowling, Mary GrandPrÃ©, Rufus Beck   \n",
       "4        6              J.K. Rowling, Mary GrandPrÃ©   \n",
       "\n",
       "                              original_title  rating  \n",
       "0     Harry Potter and the Half-Blood Prince    4.24  \n",
       "1  Harry Potter and the Order of the Phoenix    4.21  \n",
       "2   Harry Potter and the Philosopher's Stone    3.09  \n",
       "3   Harry Potter and the Prisoner of Azkaban    3.89  \n",
       "4        Harry Potter and the Goblet of Fire    4.09  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = full_df.groupby(['book_id', 'authors', 'original_title'], as_index=False).rating.mean()\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Подготовка признаков\n",
    "2. Подбор модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince</td>\n",
       "      <td>4.24</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ© Harry Potter and the Half-Blood Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>4.21</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ© Harry Potter and the Order of the Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>3.09</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ© Harry Potter and the Philosopher's Stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©, Rufus Beck</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>3.89</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©, Rufus Beck Harry Potter and the Prisoner of Azkaban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>4.09</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ© Harry Potter and the Goblet of Fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                   authors  \\\n",
       "0        1              J.K. Rowling, Mary GrandPrÃ©   \n",
       "1        2              J.K. Rowling, Mary GrandPrÃ©   \n",
       "2        3              J.K. Rowling, Mary GrandPrÃ©   \n",
       "3        5  J.K. Rowling, Mary GrandPrÃ©, Rufus Beck   \n",
       "4        6              J.K. Rowling, Mary GrandPrÃ©   \n",
       "\n",
       "                              original_title  rating  \\\n",
       "0     Harry Potter and the Half-Blood Prince    4.24   \n",
       "1  Harry Potter and the Order of the Phoenix    4.21   \n",
       "2   Harry Potter and the Philosopher's Stone    3.09   \n",
       "3   Harry Potter and the Prisoner of Azkaban    3.89   \n",
       "4        Harry Potter and the Goblet of Fire    4.09   \n",
       "\n",
       "                                                                         Review Text  \n",
       "0                J.K. Rowling, Mary GrandPrÃ© Harry Potter and the Half-Blood Prince  \n",
       "1             J.K. Rowling, Mary GrandPrÃ© Harry Potter and the Order of the Phoenix  \n",
       "2              J.K. Rowling, Mary GrandPrÃ© Harry Potter and the Philosopher's Stone  \n",
       "3  J.K. Rowling, Mary GrandPrÃ©, Rufus Beck Harry Potter and the Prisoner of Azkaban  \n",
       "4                   J.K. Rowling, Mary GrandPrÃ© Harry Potter and the Goblet of Fire  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = full_df.copy()\n",
    "Corpus['Review Text'] = full_df['authors'] + \" \" + full_df['original_title']\n",
    "Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus['Review Text'] = [str(entry).lower() for entry in Corpus['Review Text']] \n",
    "\n",
    "Corpus['Review Text']= [word_tokenize(str(entry)) for entry in Corpus['Review Text']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = defaultdict(lambda : wn.NOUN)         \n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,entry in enumerate(Corpus['Review Text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        #print('word' + word)\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            #print('Word final: '+ str(word_Final))\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    Corpus.loc[index,'Review_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=50)\n",
    "Tfidf_vect.fit(Corpus['Review_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Corpus['Review_final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.936170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.677778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.460674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.336957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.326316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>794 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9   ...   41   42   43  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "789  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "790  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "791  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "792  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "793  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      44   45   46   47   48   49        50  \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  4.240000  \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  4.210000  \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  3.090000  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  3.890000  \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  4.090000  \n",
       "..   ...  ...  ...  ...  ...  ...       ...  \n",
       "789  0.0  0.0  0.0  0.0  0.0  0.0  3.936170  \n",
       "790  0.0  0.0  0.0  0.0  0.0  0.0  3.677778  \n",
       "791  0.0  0.0  0.0  0.0  0.0  0.0  4.460674  \n",
       "792  0.0  0.0  0.0  0.0  0.0  0.0  3.336957  \n",
       "793  0.0  0.0  0.0  0.0  0.0  0.0  4.326316  \n",
       "\n",
       "[794 rows x 51 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.hstack([Train_X_Tfidf.toarray(),Corpus.rating.values.reshape(-1,1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR(\n",
      "  (linear): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n",
      "0/100 Epoch,Loss 16.07861328125\n",
      "1/100 Epoch,Loss 16.0721492767334\n",
      "2/100 Epoch,Loss 16.065683364868164\n",
      "3/100 Epoch,Loss 16.059223175048828\n",
      "4/100 Epoch,Loss 16.05276107788086\n",
      "5/100 Epoch,Loss 16.046306610107422\n",
      "6/100 Epoch,Loss 16.039854049682617\n",
      "7/100 Epoch,Loss 16.033401489257812\n",
      "8/100 Epoch,Loss 16.026952743530273\n",
      "9/100 Epoch,Loss 16.0205078125\n",
      "10/100 Epoch,Loss 16.014062881469727\n",
      "11/100 Epoch,Loss 16.007619857788086\n",
      "12/100 Epoch,Loss 16.001182556152344\n",
      "13/100 Epoch,Loss 15.99474811553955\n",
      "14/100 Epoch,Loss 15.988312721252441\n",
      "15/100 Epoch,Loss 15.981884002685547\n",
      "16/100 Epoch,Loss 15.975455284118652\n",
      "17/100 Epoch,Loss 15.969029426574707\n",
      "18/100 Epoch,Loss 15.962606430053711\n",
      "19/100 Epoch,Loss 15.95618724822998\n",
      "20/100 Epoch,Loss 15.949769973754883\n",
      "21/100 Epoch,Loss 15.94335651397705\n",
      "22/100 Epoch,Loss 15.936944007873535\n",
      "23/100 Epoch,Loss 15.930533409118652\n",
      "24/100 Epoch,Loss 15.924125671386719\n",
      "25/100 Epoch,Loss 15.91772174835205\n",
      "26/100 Epoch,Loss 15.911319732666016\n",
      "27/100 Epoch,Loss 15.904919624328613\n",
      "28/100 Epoch,Loss 15.89852237701416\n",
      "29/100 Epoch,Loss 15.892128944396973\n",
      "30/100 Epoch,Loss 15.885737419128418\n",
      "31/100 Epoch,Loss 15.879348754882812\n",
      "32/100 Epoch,Loss 15.872962951660156\n",
      "33/100 Epoch,Loss 15.866578102111816\n",
      "34/100 Epoch,Loss 15.860197067260742\n",
      "35/100 Epoch,Loss 15.853818893432617\n",
      "36/100 Epoch,Loss 15.847441673278809\n",
      "37/100 Epoch,Loss 15.841068267822266\n",
      "38/100 Epoch,Loss 15.834698677062988\n",
      "39/100 Epoch,Loss 15.82833194732666\n",
      "40/100 Epoch,Loss 15.821964263916016\n",
      "41/100 Epoch,Loss 15.815600395202637\n",
      "42/100 Epoch,Loss 15.809240341186523\n",
      "43/100 Epoch,Loss 15.802882194519043\n",
      "44/100 Epoch,Loss 15.796527862548828\n",
      "45/100 Epoch,Loss 15.790173530578613\n",
      "46/100 Epoch,Loss 15.783823013305664\n",
      "47/100 Epoch,Loss 15.777474403381348\n",
      "48/100 Epoch,Loss 15.77113151550293\n",
      "49/100 Epoch,Loss 15.764788627624512\n",
      "50/100 Epoch,Loss 15.758447647094727\n",
      "51/100 Epoch,Loss 15.752111434936523\n",
      "52/100 Epoch,Loss 15.745777130126953\n",
      "53/100 Epoch,Loss 15.7394437789917\n",
      "54/100 Epoch,Loss 15.733115196228027\n",
      "55/100 Epoch,Loss 15.726785659790039\n",
      "56/100 Epoch,Loss 15.720463752746582\n",
      "57/100 Epoch,Loss 15.714140892028809\n",
      "58/100 Epoch,Loss 15.707820892333984\n",
      "59/100 Epoch,Loss 15.701501846313477\n",
      "60/100 Epoch,Loss 15.695188522338867\n",
      "61/100 Epoch,Loss 15.688875198364258\n",
      "62/100 Epoch,Loss 15.682567596435547\n",
      "63/100 Epoch,Loss 15.676260948181152\n",
      "64/100 Epoch,Loss 15.669955253601074\n",
      "65/100 Epoch,Loss 15.663656234741211\n",
      "66/100 Epoch,Loss 15.657356262207031\n",
      "67/100 Epoch,Loss 15.6510591506958\n",
      "68/100 Epoch,Loss 15.644766807556152\n",
      "69/100 Epoch,Loss 15.638474464416504\n",
      "70/100 Epoch,Loss 15.632184982299805\n",
      "71/100 Epoch,Loss 15.625898361206055\n",
      "72/100 Epoch,Loss 15.619613647460938\n",
      "73/100 Epoch,Loss 15.613332748413086\n",
      "74/100 Epoch,Loss 15.607054710388184\n",
      "75/100 Epoch,Loss 15.600777626037598\n",
      "76/100 Epoch,Loss 15.594504356384277\n",
      "77/100 Epoch,Loss 15.588233947753906\n",
      "78/100 Epoch,Loss 15.581963539123535\n",
      "79/100 Epoch,Loss 15.575699806213379\n",
      "80/100 Epoch,Loss 15.569436073303223\n",
      "81/100 Epoch,Loss 15.563175201416016\n",
      "82/100 Epoch,Loss 15.556916236877441\n",
      "83/100 Epoch,Loss 15.550660133361816\n",
      "84/100 Epoch,Loss 15.544408798217773\n",
      "85/100 Epoch,Loss 15.538156509399414\n",
      "86/100 Epoch,Loss 15.53190803527832\n",
      "87/100 Epoch,Loss 15.52566146850586\n",
      "88/100 Epoch,Loss 15.51941967010498\n",
      "89/100 Epoch,Loss 15.513177871704102\n",
      "90/100 Epoch,Loss 15.506939888000488\n",
      "91/100 Epoch,Loss 15.500703811645508\n",
      "92/100 Epoch,Loss 15.49447250366211\n",
      "93/100 Epoch,Loss 15.488240242004395\n",
      "94/100 Epoch,Loss 15.482012748718262\n",
      "95/100 Epoch,Loss 15.475786209106445\n",
      "96/100 Epoch,Loss 15.469563484191895\n",
      "97/100 Epoch,Loss 15.463342666625977\n",
      "98/100 Epoch,Loss 15.45712661743164\n",
      "99/100 Epoch,Loss 15.450910568237305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ymochalova/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([794])) that is different to the input size (torch.Size([794, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # Neural network constructor\n",
    "import numpy as np # For data manipulation\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "\n",
    "# Creating data for classification\n",
    "X = torch.from_numpy(Train_X_Tfidf.toarray().astype(np.float32)).float()\n",
    "y = torch.from_numpy(Corpus.rating.values).float()\n",
    "\n",
    "# Creating the model\n",
    "class LR(nn.Module):\n",
    "    def __init__(self , input_size , output_size):\n",
    "        super(LR,self).__init__()\n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        pred = self.linear(x)\n",
    "        return pred\n",
    "    \n",
    "# Creating the model instance\n",
    "torch.manual_seed(1)  # Just for you to get similar output as mine\n",
    "model = LR(50, 1)\n",
    "print(model)\n",
    "\n",
    "# Collecting the weights and biases\n",
    "[w ,b] = model.parameters()\n",
    "def get_params():\n",
    "    return(w[0][0].item(),b[0].item())\n",
    "\n",
    "\n",
    "#Loss anad Optimizer defenitions\n",
    "criterion = nn.MSELoss() # MSE stands for Mean Square Error\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = 0.0001) # SGD stands for Stochastic Gradient Decent , lr = learning rate\n",
    "\n",
    "#Training\n",
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for i_epoch in range(epochs):\n",
    "    y_pred = model.forward(X) # Forward pass\n",
    "    loss = criterion(y_pred,y) # Finding the loss\n",
    "    print(\"{}/{} Epoch,Loss {}\".format(i_epoch,epochs,loss.item())) # Monitoring the loss\n",
    "    losses.append(loss.item()) # Stroing the loss for later visualization\n",
    "    optimizer.zero_grad()  #Setting the gradients to zero\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step() # Updates the parameters\n",
    "\n",
    "# Loss vs epochs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR(\n",
      "  (linear): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "0/100 Epoch,Loss 14.579277992248535\n",
      "1/100 Epoch,Loss 14.573119163513184\n",
      "2/100 Epoch,Loss 14.566965103149414\n",
      "3/100 Epoch,Loss 14.56081485748291\n",
      "4/100 Epoch,Loss 14.554665565490723\n",
      "5/100 Epoch,Loss 14.5485200881958\n",
      "6/100 Epoch,Loss 14.542377471923828\n",
      "7/100 Epoch,Loss 14.536234855651855\n",
      "8/100 Epoch,Loss 14.530097007751465\n",
      "9/100 Epoch,Loss 14.523958206176758\n",
      "10/100 Epoch,Loss 14.517827033996582\n",
      "11/100 Epoch,Loss 14.511696815490723\n",
      "12/100 Epoch,Loss 14.50556755065918\n",
      "13/100 Epoch,Loss 14.499443054199219\n",
      "14/100 Epoch,Loss 14.49332046508789\n",
      "15/100 Epoch,Loss 14.487200736999512\n",
      "16/100 Epoch,Loss 14.481082916259766\n",
      "17/100 Epoch,Loss 14.474967956542969\n",
      "18/100 Epoch,Loss 14.468856811523438\n",
      "19/100 Epoch,Loss 14.462746620178223\n",
      "20/100 Epoch,Loss 14.456639289855957\n",
      "21/100 Epoch,Loss 14.450535774230957\n",
      "22/100 Epoch,Loss 14.44443416595459\n",
      "23/100 Epoch,Loss 14.438334465026855\n",
      "24/100 Epoch,Loss 14.43223762512207\n",
      "25/100 Epoch,Loss 14.426143646240234\n",
      "26/100 Epoch,Loss 14.420052528381348\n",
      "27/100 Epoch,Loss 14.413966178894043\n",
      "28/100 Epoch,Loss 14.407877922058105\n",
      "29/100 Epoch,Loss 14.401795387268066\n",
      "30/100 Epoch,Loss 14.39571475982666\n",
      "31/100 Epoch,Loss 14.38963508605957\n",
      "32/100 Epoch,Loss 14.383560180664062\n",
      "33/100 Epoch,Loss 14.377486228942871\n",
      "34/100 Epoch,Loss 14.371416091918945\n",
      "35/100 Epoch,Loss 14.365348815917969\n",
      "36/100 Epoch,Loss 14.359283447265625\n",
      "37/100 Epoch,Loss 14.353221893310547\n",
      "38/100 Epoch,Loss 14.347161293029785\n",
      "39/100 Epoch,Loss 14.341103553771973\n",
      "40/100 Epoch,Loss 14.335047721862793\n",
      "41/100 Epoch,Loss 14.328995704650879\n",
      "42/100 Epoch,Loss 14.322944641113281\n",
      "43/100 Epoch,Loss 14.316899299621582\n",
      "44/100 Epoch,Loss 14.3108549118042\n",
      "45/100 Epoch,Loss 14.304814338684082\n",
      "46/100 Epoch,Loss 14.298773765563965\n",
      "47/100 Epoch,Loss 14.292737007141113\n",
      "48/100 Epoch,Loss 14.286703109741211\n",
      "49/100 Epoch,Loss 14.280671119689941\n",
      "50/100 Epoch,Loss 14.274641990661621\n",
      "51/100 Epoch,Loss 14.26861572265625\n",
      "52/100 Epoch,Loss 14.262591361999512\n",
      "53/100 Epoch,Loss 14.256571769714355\n",
      "54/100 Epoch,Loss 14.2505521774292\n",
      "55/100 Epoch,Loss 14.244535446166992\n",
      "56/100 Epoch,Loss 14.23852252960205\n",
      "57/100 Epoch,Loss 14.232510566711426\n",
      "58/100 Epoch,Loss 14.226503372192383\n",
      "59/100 Epoch,Loss 14.22049617767334\n",
      "60/100 Epoch,Loss 14.214492797851562\n",
      "61/100 Epoch,Loss 14.208494186401367\n",
      "62/100 Epoch,Loss 14.202494621276855\n",
      "63/100 Epoch,Loss 14.196500778198242\n",
      "64/100 Epoch,Loss 14.190505027770996\n",
      "65/100 Epoch,Loss 14.184514999389648\n",
      "66/100 Epoch,Loss 14.178526878356934\n",
      "67/100 Epoch,Loss 14.172542572021484\n",
      "68/100 Epoch,Loss 14.166559219360352\n",
      "69/100 Epoch,Loss 14.160579681396484\n",
      "70/100 Epoch,Loss 14.154603004455566\n",
      "71/100 Epoch,Loss 14.148627281188965\n",
      "72/100 Epoch,Loss 14.142653465270996\n",
      "73/100 Epoch,Loss 14.136683464050293\n",
      "74/100 Epoch,Loss 14.130717277526855\n",
      "75/100 Epoch,Loss 14.124752044677734\n",
      "76/100 Epoch,Loss 14.118789672851562\n",
      "77/100 Epoch,Loss 14.112831115722656\n",
      "78/100 Epoch,Loss 14.106873512268066\n",
      "79/100 Epoch,Loss 14.100918769836426\n",
      "80/100 Epoch,Loss 14.094965934753418\n",
      "81/100 Epoch,Loss 14.089017868041992\n",
      "82/100 Epoch,Loss 14.083069801330566\n",
      "83/100 Epoch,Loss 14.077125549316406\n",
      "84/100 Epoch,Loss 14.071182250976562\n",
      "85/100 Epoch,Loss 14.065245628356934\n",
      "86/100 Epoch,Loss 14.059308052062988\n",
      "87/100 Epoch,Loss 14.053374290466309\n",
      "88/100 Epoch,Loss 14.047441482543945\n",
      "89/100 Epoch,Loss 14.041512489318848\n",
      "90/100 Epoch,Loss 14.0355863571167\n",
      "91/100 Epoch,Loss 14.029662132263184\n",
      "92/100 Epoch,Loss 14.023738861083984\n",
      "93/100 Epoch,Loss 14.017822265625\n",
      "94/100 Epoch,Loss 14.0119047164917\n",
      "95/100 Epoch,Loss 14.005989074707031\n",
      "96/100 Epoch,Loss 14.000079154968262\n",
      "97/100 Epoch,Loss 13.994171142578125\n",
      "98/100 Epoch,Loss 13.988264083862305\n",
      "99/100 Epoch,Loss 13.982359886169434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ymochalova/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([794])) that is different to the input size (torch.Size([794, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rc/myq009851pxc5x20pbfypm8c0000gp/T/ipykernel_55708/883724198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss --->'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mplot_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trained\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Visualizing the trained network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/rc/myq009851pxc5x20pbfypm8c0000gp/T/ipykernel_55708/2920418785.py\u001b[0m in \u001b[0;36mplot_fit\u001b[0;34m(title)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   3066\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[0;32m-> 3068\u001b[0;31m     __ret = gca().scatter(\n\u001b[0m\u001b[1;32m   3069\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4496\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4498\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # Neural network constructor\n",
    "import numpy as np # For data manipulation\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "\n",
    "# Creating data for classification\n",
    "X = torch.from_numpy(Train_X_Tfidf.toarray().astype(np.float32)).float()\n",
    "y = torch.from_numpy(Corpus.Label.values).float()\n",
    "plt.plot(X.numpy() , y.numpy(),'o') # For matplotlib to plot the inouts cannot be tensors so we have to convert them into numpy arrays\n",
    "plt.xlabel('X') # Setting the X label\n",
    "plt.ylabel('Y') # Setting the Y label\n",
    "\n",
    "# Creating the model\n",
    "class LR(nn.Module):\n",
    "    def __init__(self , input_size , output_size):\n",
    "        super(LR,self).__init__()\n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        pred = self.linear(x)\n",
    "        return pred\n",
    "    \n",
    "# Creating the model instance\n",
    "torch.manual_seed(1)  # Just for you to get similar output as mine\n",
    "model = LR(30 , 1)\n",
    "print(model)\n",
    "\n",
    "# Collecting the weights and biases\n",
    "[w ,b] = model.parameters()\n",
    "def get_params():\n",
    "    return(w[0][0].item(),b[0].item())\n",
    "\n",
    "\n",
    "#Loss anad Optimizer defenitions\n",
    "criterion = nn.MSELoss() # MSE stands for Mean Square Error\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = 0.0001) # SGD stands for Stochastic Gradient Decent , lr = learning rate\n",
    "\n",
    "#Training\n",
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for i_epoch in range(epochs):\n",
    "    y_pred = model.forward(X) # Forward pass\n",
    "    loss = criterion(y_pred,y) # Finding the loss\n",
    "    print(\"{}/{} Epoch,Loss {}\".format(i_epoch,epochs,loss.item())) # Monitoring the loss\n",
    "    losses.append(loss.item()) # Stroing the loss for later visualization\n",
    "    optimizer.zero_grad()  #Setting the gradients to zero\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step() # Updates the parameters\n",
    "\n",
    "# Loss vs epochs\n",
    "plt.plot(range(epochs) , losses)\n",
    "plt.xlabel('epochs --->')\n",
    "plt.ylabel('Loss --->')\n",
    "\n",
    "plot_fit(\"Trained\") # Visualizing the trained network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/input/regression_4_degree_polynomial.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rc/myq009851pxc5x20pbfypm8c0000gp/T/ipykernel_55708/2587806178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/rc/myq009851pxc5x20pbfypm8c0000gp/T/ipykernel_55708/82262748.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                                 \u001b[0;31m# Load GPU model on CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ckp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/input/regression_4_degree_polynomial.pth'"
     ]
    }
   ],
   "source": [
    "lr.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pl_bolts (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for pl_bolts\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pl_bolts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
