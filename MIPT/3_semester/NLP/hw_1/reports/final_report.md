
# ОТЧЕТ ПО ДОМАШНЕМУ ЗАДАНИЮ

## 1. Описание данных

Исходный датасет содержит **500 000 отзывов** с полями:
- `address` - адрес места
- `name_ru` - название места (с небольшим количеством пропусков)
- `rating` - рейтинг от 1 до 5
- `rubrics` - категория места
- `text` - текст отзыва

Целевая переменная - `sentiment`, сформированная на основе `rating`:
- **Позитивный** (`1`) - рейтинг ≥ 4
- **Негативный** (`0`) - рейтинг ≤ 2  
(Отзывы с рейтингом 3 исключены как нейтральные)

### Проблема: Классовый дисбаланс
Изначально распределение классов было крайне несбалансированным:
- **Позитивные**: 431 675 (90.3%)
- **Негативные**: 46 439 (9.7%)

### Решение:
- **Сэмплирование** бОльшего класса по размером малого

## 2. Предобработка

### Этапы обработки:
1. **Очистка текста**:
   - Удаление HTML-тегов, URL, спецсимволов
   - Приведение к нижнему регистру
   - Удаление лишних пробелов

2. **Токенизация**:
   - Использован `nltk.word_tokenize()` с поддержкой русского языка
   - Удаление стоп-слов 

3. **Создание целевой переменной**:
   - `rating >= 4` → `sentiment = 1`
   - `rating <= 2` → `sentiment = 0`
   - `rating == 3` → исключены

## 3. Модели и методы
### Использованные модели:
| Модель | Описание |
|--------|----------|
| **Logistic Regression + TF-IDF** | Базовая модель на мешке слов |
| **Logistic Regression + Word2Vec** | Эмбеддинги на Word2Vec |
| **Logistic Regression + FastText** | Эмбеддинги на FastText |

###Сравнение моделей на валидационной выборке

| Модель      | Accuracy | Precision | Recall   | F1-Score | ROC-AUC  |
|-------------|----------|-----------|----------|----------|----------|
| W2V         | 0.9357   | 0.9434    | 0.9270   | 0.9351   | 0.9785   |
| TF_IDF      | 0.9248   | 0.9293    | 0.9197   | 0.9245   | 0.9759   |
| FastText    | 0.9377   | 0.9455    | 0.9288   | 0.9371   | 0.9788   |
