{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Выбран кодовый формат\n",
        "```\n",
        "\n",
        "# Домашнее задание 2. Поисковая система для документов\n",
        "\n",
        "**Модуль 2. Классический поиск и рекуррентные архитектуры**\n",
        "\n",
        "**ФИО студента: Кузнецов Кирилл Игоревич**\n",
        "\n",
        "**Дата выполнения: 17 сентября 2025**\n",
        "\n",
        "## Описание задания\n",
        "\n",
        "В этом задании вы разработаете полнофункциональную поисковую систему, включающую:\n",
        "1. **Предобработку корпуса.**\n",
        "2. **BM25.**\n",
        "3. **Векторный поиск** — на основе эмбеддингов.\n",
        "4. **Гибридный поиск** — комбинация BM25 и векторного поиска.\n",
        "5. **Выбор метрики и оценку качества** — для конкретной задачи.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## Установка и импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# # Установка необходимых библиотек\n",
        "# !pip install sentence-transformers\n",
        "# !pip install faiss-cpu\n",
        "# !pip install rank-bm25  # для сравнения\n",
        "# !pip install pymorphy3 pymorphy3-dicts-ru\n",
        "# !pip install tqdm\n",
        "# !pip install matplotlib seaborn\n",
        "# !pip install pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import re\n",
        "import math\n",
        "import time\n",
        "from typing import List, Dict, Tuple, Optional, Set\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pymorphy3\n",
        "\n",
        "# Векторный поиск\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "# BM25\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Создание директорий\n",
        "for dir_name in ['data', 'indices', 'models', 'results', 'tests']:\n",
        "    pathlib.Path(dir_name).mkdir(exist_ok=True)\n",
        "\n",
        "# Загрузка NLTK ресурсов\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# Инициализация морфологического анализатора\n",
        "morph = pymorphy3.MorphAnalyzer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1"
      },
      "source": [
        "## Часть 1. Подготовка данных\n",
        "\n",
        "1. Загрузите и изучите предложенный датасет.  \n",
        "2. Реализуйте функцию предобработки текста, которая включает:\n",
        "- Лемматизацию с использованием pymorphy3.\n",
        "- Удаление стоп-слов и пунктуации.  \n",
        "3. Обработайте весь корпус документов и сохраните результат для последующих шагов.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1447c2a1faef4df593d8b1e2c9126696",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4598b61eae00465db9ed17dc827791fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "retrieval_dataset.jsonl:   0%|          | 0.00/566M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "431228a6ff6e4c238eb82f5d793f5fc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "retrieval_dataset_src.jsonl:   0%|          | 0.00/576M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e9496e51d1747c0bf37bab3e84e3334",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/90556 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Загружаем корпус документов\n",
        "ds = load_dataset(\"MLNavigator/russian-retrieval\")\n",
        "df = pd.DataFrame(ds['train'])\n",
        "questions_df = df[['text','q']]\n",
        "\n",
        "\n",
        "# Уберем дубли, так как датасет имеет соответствие много вопросов -> один документ\n",
        "documents = df['text'].drop_duplicates().to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocessing"
      },
      "outputs": [],
      "source": [
        "# Предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part2"
      },
      "source": [
        "## Часть 2. Реализация BM25\n",
        "\n",
        "1. Постройте инвертированный индекс для корпуса. Индекс должен содержать частоту термина в документе (TF) и документную частоту (DF).\n",
        "2. Реализуйте функцию поиска BM25 с нуля. Формула для ранжирования:\n",
        "score(D, Q) = Σ IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D| / avgdl))\n",
        "3. Проведите оптимизацию гиперпараметра k1, чтобы улучшить качество поиска."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inverted_index"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm25_implementation"
      },
      "outputs": [],
      "source": [
        "# Реализация поиска используя BM25\n",
        "\n",
        "# Тестовые запросы\n",
        "test_queries = [\n",
        "    \"машинное обучение\",\n",
        "    \"нейронные сети\",\n",
        "    \"поисковые системы BM25\",\n",
        "    \"Python программирование\"\n",
        "]\n",
        "\n",
        "print(\"Тестирование BM25:\")\n",
        "for query in test_queries:\n",
        "    results = bm25.search(query, top_k=3)\n",
        "    print(f\"Запрос: '{query}'\")\n",
        "    for doc_id, score in results:\n",
        "        doc = documents[doc_id]\n",
        "        print(f\"  [{score:.3f}] {doc.title[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part3"
      },
      "source": [
        "## Часть 3. Векторный поиск\n",
        "\n",
        "1. Используйте предобученную модель sentence-transformers для получения векторных представлений (эмбеддингов) всех документов.\n",
        "2. Создайте индекс для быстрого поиска ближайших соседей с помощью faiss-cpu.\n",
        "3. Реализуйте функцию векторного поиска, которая по запросу находит top-k наиболее близких документов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vector_search"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('BAAI/bge-m3', device='cuda')\n",
        "\n",
        "\n",
        "# Тестируем\n",
        "print(\"Тестирование векторного поиска:\")\n",
        "for query in test_queries:\n",
        "    results = vector_search.search(query, top_k=3)\n",
        "    print(f\"Запрос: '{query}'\")\n",
        "    for doc_id, score in results:\n",
        "        doc = documents[doc_id]\n",
        "        print(f\"  [{score:.3f}] {doc.title[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part4"
      },
      "source": [
        "## Часть 4. Гибридный поиск\n",
        "\n",
        "1. Разработайте функцию, которая комбинирует результаты ранжирования от BM25 и векторного поиска.\n",
        "2. Реализуйте механизм взвешивания скоров с помощью параметра α:\n",
        "hybrid_score = α * bm25_score + (1 - α) * vector_score\n",
        "3. Проведите автоматическую оптимизацию параметра α на валидационном наборе данных.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hybrid_search"
      },
      "outputs": [],
      "source": [
        "# Тестируем гибридный поиск\n",
        "print(\"Тестирование гибридного поиска:\")\n",
        "for query in test_queries:\n",
        "    results = hybrid_search.search(query, top_k=3)\n",
        "    print(f\"Запрос: '{query}'\")\n",
        "    for doc_id, score in results:\n",
        "        doc = documents[doc_id]\n",
        "        print(f\"  [{score:.3f}] {doc.title[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part6"
      },
      "source": [
        "## Часть 5. Оценка качества\n",
        "\n",
        "1. Выберите и **обоснуйте метрику** для оценки качества вашей поисковой системы (например, MRR, MAP@k или NDCG@k). **Обязательно подумайте о том, какой топ-к нужно выбрать исходя из данных**.\n",
        "2. **Создайте небольшой датасет для оценки**, состоящий из запросов и релевантных им документов.  \n",
        "3. **Сравните качество** всех трех реализованных подходов (BM25, векторный, гибридный) на вашем датасете.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "metrics"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
