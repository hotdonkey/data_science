{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# –í—ã–±—Ä–∞–Ω –∫–æ–¥–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç\n",
        "```\n",
        "\n",
        "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 2. –ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
        "\n",
        "**–ú–æ–¥—É–ª—å 2. –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∏ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã**\n",
        "\n",
        "**–§–ò–û —Å—Ç—É–¥–µ–Ω—Ç–∞: –ö—É–∑–Ω–µ—Ü–æ–≤ –ö–∏—Ä–∏–ª–ª –ò–≥–æ—Ä–µ–≤–∏—á**\n",
        "\n",
        "**–î–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: 17 —Å–µ–Ω—Ç—è–±—Ä—è 2025**\n",
        "\n",
        "## –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è\n",
        "\n",
        "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –≤—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–µ—Ç–µ –ø–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –ø–æ–∏—Å–∫–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É, –≤–∫–ª—é—á–∞—é—â—É—é:\n",
        "1. **–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –∫–æ—Ä–ø—É—Å–∞.**\n",
        "2. **BM25.**\n",
        "3. **–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫** ‚Äî –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\n",
        "4. **–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫** ‚Äî –∫–æ–º–±–∏–Ω–∞—Ü–∏—è BM25 –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.\n",
        "5. **–í—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫–∏ –∏ –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞** ‚Äî –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
        "# !pip install sentence-transformers\n",
        "# !pip install faiss-cpu\n",
        "# !pip install rank-bm25  # –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "# !pip install pymorphy3 pymorphy3-dicts-ru\n",
        "# !pip install tqdm\n",
        "# !pip install matplotlib seaborn\n",
        "# !pip install pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import re\n",
        "import math\n",
        "import time\n",
        "from typing import List, Dict, Tuple, Optional, Set\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pymorphy3\n",
        "\n",
        "# –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "# BM25\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π\n",
        "for dir_name in ['data', 'indices', 'models', 'results', 'tests']:\n",
        "    pathlib.Path(dir_name).mkdir(exist_ok=True)\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ NLTK —Ä–µ—Å—É—Ä—Å–æ–≤\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞\n",
        "morph = pymorphy3.MorphAnalyzer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1"
      },
      "source": [
        "## –ß–∞—Å—Ç—å 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –∏–∑—É—á–∏—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç.  \n",
        "2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è –≤–∫–ª—é—á–∞–µ—Ç:\n",
        "- –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º pymorphy3.\n",
        "- –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏.  \n",
        "3. –û–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –≤–µ—Å—å –∫–æ—Ä–ø—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ—Ä–ø—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
        "ds = load_dataset(\"MLNavigator/russian-retrieval\")\n",
        "df = pd.DataFrame(ds['train'])\n",
        "questions_df = df[['text','q']]\n",
        "\n",
        "\n",
        "# –£–±–µ—Ä–µ–º –¥—É–±–ª–∏, —Ç–∞–∫ –∫–∞–∫ –¥–∞—Ç–∞—Å–µ—Ç –∏–º–µ–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤ -> –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç\n",
        "documents = df['text'].drop_duplicates().to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ—Ä–ø—É—Å–∞:\n",
            "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: 100.6 —Å–ª–æ–≤\n",
            "–ú–µ–¥–∏–∞–Ω–Ω–∞—è –¥–ª–∏–Ω–∞: 91.0 —Å–ª–æ–≤\n",
            "–ú–∏–Ω/–ú–∞–∫—Å: 41/1041 —Å–ª–æ–≤\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAGJCAYAAAB8VSkIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXalJREFUeJzt3Qm8TPX7wPHn7te+r9mXskS2kiUJEVppUUKofkTWItlJSqUiUb9CQlJJ/VLKlpA9sotc+0527nr+r+f7+5/5zcxd55ox9975vF+v486cc+bMd86cGeeZ5/t9TpBlWZYAAAAAALwq2LubAwAAAAAogi0AAAAA8AGCLQAAAADwAYItAAAAAPABgi0AAAAA8AGCLQAAAADwAYItAAAAAPABgi0AAAAA8AGCLQAAAADwAYItAAAAAPABgi0AHps+fboEBQU5psjISLn55pulZ8+ecuLECX83DwAAIEMI9XcDAGReo0aNkrJly8q1a9dk5cqVMnnyZPnxxx9l27Ztkj17dn83DwAAwK8ItgCkW8uWLaVOnTrm9rPPPisFChSQ8ePHy3fffSdPPvmkv5sHAADgV3QjBOA1TZo0MX+joqLM37Nnz8pLL70k1apVk5w5c0ru3LlNgPbnn38meqxmx0aMGGG6I2q3xGLFikmbNm3k77//Nsv379/v0nXRfWrcuLFjW7/++quZ9+WXX8qrr74qRYsWlRw5csiDDz4ohw4dSvTca9eulfvuu0/y5MljMnJ33323rFq1KsnXqM+T1PNr293NnDlTateuLdmyZZP8+fNLu3btknz+lF6bs4SEBHnvvfekatWqZh8VKVJE/vWvf8k///zjsl6ZMmXk/vvvT/Q82s3TfZtJtf2tt95KtE9VdHS0DB8+XCpUqCARERFSsmRJGTBggJmfVsm9Tn3P3D3zzDOp7mtdR1+vM93Hus91Xd236dkv3ngNJ0+elK5du5r3Sd+v2267TT777LMk33vtmmu7ePGiOW40a3zs2DGxLMu0/aGHHkryc6PHrR4Hzse+Tps3b3ZZ98iRIxISEmKWff311y7Ldu3aJY8++qg5TrWt+iPK999/n2T34Q0bNrjMP336tMv7on9T+qy676uvvvrK8TkpWLCgPP3006atKR0L+fLlM8fnihUrUnm3rv+x7seXfq6Dg4PljTfecJm/dOlSueuuu8x3Td68ec37tXPnTpd17H2j+/vxxx8334n6I1Xv3r3Ne+kspf1nt8mTYyMt37OefM8ASBsyWwC8xv4PW08e1L59+2T+/Pny2GOPmRNHHc/10UcfmWBmx44dUrx4cbNefHy8OQlesmSJCUj0xENPOBctWmS6JJYvX97xHJoxa9WqlcvzDho0KMn2jBkzxpyYDBw40Jz46glEs2bNzEmontjZJ0gaAOrJngYSehI1bdo0Ezjqydgdd9yRaLslSpSQsWPHmtuXLl2S7t27J/ncQ4cONSdUmvU7deqUTJw4URo1aiSbNm0yJ2Punn/+eXOypubNmyfffvuty3I94dET3s6dO0uvXr1MUPvBBx+Y7WlwGBYWJtfr3LlzjtfmTE/ANFjV7qLazsqVK8vWrVvl3Xfflb/++su8z2l17733SseOHc3t9evXy4QJE5JdV0++9TlsHTp0SHX7w4YNS3Ti6m2pvYarV6+aE/q9e/eaYE6Pfw0q9ORd97Ee40mJjY2Vtm3bysGDB817qifDSgOQcePGmR8wNCCy/ec//5ELFy6Y5c70JFmP4/fff98xTwO98PDwRPtm+/bt0qBBA7npppvklVdeMcHC3Llz5eGHH5ZvvvlGHnnkEY/2jZ68a0Bu69u3rzle9Lix6X1lH8+33367Oe70O0LbrK/d/XPifCwcPnzYrKffBRpcJ/V5cnY9j3X2yy+/SJcuXcx7qvvKtnjxYvM9Uq5cORPM6Puvn3fdr3/88UeigE2/F3SevuY1a9aY40eDmRkzZiR7nNneeecdR+Cj329pPTbS+j17I75ngIBiAYCHpk2bZunXx+LFi61Tp05Zhw4dsubMmWMVKFDAypYtm3X48GGz3rVr16z4+HiXx0ZFRVkRERHWqFGjHPOmTp1qtjd+/PhEz5WQkOB4nK7z1ltvJVqnatWq1t133+24v2zZMrPuTTfdZF24cMExf+7cuWb++++/79h2xYoVrRYtWjieR125csUqW7asde+99yZ6rvr161u33nqr476+ft3m8OHDHfP2799vhYSEWGPGjHF57NatW63Q0NBE8/fs2WO28dlnnznm6facv6JXrFhh7s+aNcvlsQsXLkw0v3Tp0lbr1q0Ttb1Hjx4u21TubR8wYIBVuHBhq3bt2i779PPPP7eCg4NNO5xNmTLFbGPVqlVWamJiYsy6PXv2dMz76quvzDx9z9y1b9/evA8ptbdTp07m9dq2bdtm2tmyZUuzrh436dkv1/sa3nvvPTNv5syZLo+tV6+elTNnTsdxaR/X+pnSY1Bfc/bs2a21a9e6PO/u3bvNepMnT3aZ/+CDD1plypRxHL/2sf/kk0+az2N0dLRjXT3Wn3rqKbNc22xr2rSpVa1aNfN5ten29FjXx7h/7tevX+/ShqQ+A850v+v7lNS+1GNNP09Xr151zP/hhx/M9oYNG5bs+6w+/vhjs966deuSfF5vP3bDhg3mvXvssccSfa/VqFHDvJYzZ8445v3555/mWOzYsWOiz7W+b85eeOEFM18fY9P7emy602PY+fWk9dhIy/esJ98zANKGboQA0k2zRIUKFTLdyfSXUu0qqNkY/YVcaVczzRTZv6qeOXPGrHPLLbeYX3tt+uu5/vL84osvJnoOT7p3udNfhHPlyuW4r92kNFOgRTyUZrj27NkjTz31lGmbdofS6fLly9K0aVP57bffTEbHmWYFNGuQEs1K6eP012t7mzppd8aKFSvKsmXLXNaPiYlx7K/kaFZEuwTpL93O29SMnO5T921qhsR5PZ1Sy/Zo1y39NV4zcrpN9+fXbESlSpVctml3HXV//qTYz5/a/nPeLyntk6RolrNWrVomm5qU9OyX9LwGPcb0/XYeu6gZAc0UaDZ0+fLliR7z8ssvy6xZs0xWyT2jqt2+6tata5bbNJPx008/Sfv27RN9Th544AEzz+4KqFlazeg88cQTLuvpNjS7q8eqZjnsfaKfhxYtWpjPh3uXvvPnz7vsP91Gemh3RM04v/DCCy77s3Xr1uY4W7Bggcv6+pmyn1M/u5oF0s+znSVLyfU81s7Sa7tq1Kghn3/+ueN7TWlXT92mZi2dM0vVq1c3n1f7+8ZZjx49XO7b331JrZuatB4bafme9fR7BkDq6EYIIN0mTZpk/qMPDQ01/fo1iHI+CdETHO2u8+GHH5quKBpw2eyuhnb3Q32sbsebNLBxP6HQ7k32OB49kVSdOnVKdht6YqljPGx64uG+XXe6Xf1hOrn13LvhaLcy5R7guG9T21K4cOEkl+tJq3t3Jw2EPaHdKLVrp3Yjch/To8+v40+S26b78ydF953Sk7m00P2S0j5xp10cteuUdpPSbnhJSc9+Sc9rOHDggHn/nT8Pyj651+XOtHutdidTyY2N0R8PtPuaPrZ06dLmxFiDx6S6Vuoxpt3Hpk6dan5k0L/aPVHHCDnTbo56rGqArVNy7639A4r9I4s32PtAP/vuNNjS99OZdvlzfu80WNIAIi3HyPU8Vn980cBTuzjq95Z7YJvS69D3++effzbb0O6ZNvfvBu3Cp8eK8xhDT6Tl2EjL96yn3zMAUkewBSDd9Nd3uxphUl5//XVzAqdjHEaPHm1+9dUTij59+iTKGPmD3QYtCKG/WCfF+WRMMy36K7b+6pvadvWETH9Z1oIEKW1THT9+3PzVTEhK29QTIOdfr525BxD6S/drr73mMk/HXWilyKRoIKXjNHTwf1JjMvT5tdCJVptMimY3U2OfSLqPX0mO7hc9cUwrHZunJ8WabXMuOHE9++V6X0NaaaCl4/x0/JeOcdKCLZqFcKbZY12mx4AWftH3Sj9/SZ3kK/3c1axZU3bv3m1Ovt0LXjh/BrSQje67pDiPv3L+kcWm44I0kPM1/UFHX7PSgEADSN1PGpTpsemrx2qArYGSBvI6jk3HWekPE950PRn89Bwb3vqeAZA6gi0APqPZkXvuuUc+/fTTRBkL5xNJ/VVXKwLqL7HeHHxtZ65s+gu+/pKv3Xvs51X6a39afq3XKoraxpQCTHu7+lxaFMH5pDQ5WixET7ZSOjHSbeogfB1wbxf3SInuX/fXlFIRC+1+pwGnezcz5+fX16/dK9N7YmhXsUtt/yndz/pe6QlxWuhrW716tUv3VG/sl/S+Bg0St2zZYk5enbNbWoXOXu4eGOlJ8tGjR6VKlSrmxFm7qznTHyu0K5ueCGv3MC1WoEVfkqNBhAZb2kVQT5L1s+jefVELOij93KU1Y+X+I4ud7fOUvQ80GLS7o9p0nvs+0q6Gzm3Ugi26TzRY1sxgSq7nsVqhdOHChSbbpu+L/oik+9TOUjq/Dnf6fusx55zVsr+b9PvBpse6HivpDeLTcmyk5XvW0+8ZAKljzBYAn9Gszn/Hef+P/sLuPgZEfxXXEzY98XHn/nhP6LgMHYfiHPxpZkqrhikdh6AnF2+//bYZR+NOKwi6t11fU1Llw92rsel6I0eOTNR+va/jYWxxcXGmO5OewKbUpUlP7rQbpmYI3ek27K6I6aFBimZ2tJR1coGUPr++b//+978TLdPKa9pNKjW6/zWg1JPW1Gh7dLvuJ+FJ0f2igYqOvUsuQ+ktaX0NWulOM3N6+QHn90nHxOn7rBU5ndlVKLUb55tvvmkyE9rl0Z12C9PgXMd36TGmGY2UaBCnQZ9d/tydZjG0aqIGHPrZSO0z4E0asOnzT5kyxeXyAZoR1kyrBg8p0Uyz7lNPLj2QnsdqoGq/33ohd61G+txzzzk+29olUY87rfbo/DnUCn/6HrpXT7Wzg870uFD2d1N6pHZspOV71pffM0CgIrMFwGc0KNGTEy0hXL9+fVMqXH95tX9Ndx5voIFRv379ZN26debEU0/e9RdWHTyf1DVk0vprb8OGDc3z63gL/aVXu0TpiZLSjMMnn3xiTnD0mjK6no5N0aBCB4Jrxku7Dmlb9ORIyzNrpsr5GkF2kKYntBq01KtXzwRw2lVNs0Xa7Uy7HmmhDh23pgVEtAS2dtvS16fdLPWx+jwp0ZNzHUulXZh0MH7z5s3Nr9P6C7kGgTo2TsfmpIeeEGrXyJQyG3oip4UbunXrZvaN/vKtJ2X6y73O13EpyWV7tLiAlqbW91YDUbs7l9Juc0rLT5cqVcp0pdQuWjrOT48ZfZ2p0cIPWtI8PcUF0sqT16DHt77HGsBokLNx40aTsdBAzc44OBducaePnT17ttnXesKumRWbBiA6bkjfcz1ukxtbY9NjXYuFpDTGTI9t/ZxoJkzX1/br50WPZ923SV0Xzxv0+NXAUj93enxrMRG79LvuL80iOdPPoXNXQM38acGStJSmv57HOtNsz8cff2w+K5MnTzbfT3ZXZH0/9POv11azS7/rfk/qGnz6XaDZNc3c6n7WtumPBXottvRK7dhIy/esL79ngICVxqqFAJBqCWh3Wkq6f//+VrFixUxJ+AYNGlirV682JcWdy4rb5dYHDx5sSn2HhYVZRYsWtR599FHr77//Tnfp9y+++MIaNGiQKcmsz68lkw8cOJDo8Zs2bbLatGljSmVrWXotq/z4449bS5YscXnu1Cb38tbffPON1bBhQytHjhxmqlSpkinlrKWa1Ysvvmg1atTIlFV251763blktZZl19eTK1cuU7Jby7UfPXo03aXfg4KCrI0bN7rMT+o90lLdb775ptnfup/y5ctn2jJy5Ejr/PnzVmrHS2qTrqeXDShZsqTVp0+fJLeZVOl3nde7d+8kn9Nbpd89eQ22EydOWJ07d7YKFixohYeHm/fKebl76XdneoxERkZaffv2TdQWu0z47NmzEy2zj33n0u5pWa6fMy1Rrp87/fzpZRPuv/9+6+uvv/ZZ6Xfbl19+adWsWdMcU/nz5zfl7+3LR7i/z/akJdhr1aplLkmQmut9rHvZeKXva+7cuV3aqZfC0O84/WzqsgceeMDasWNHkp9rna/fb/oZ1s+RXkrAufy9J6Xf03pspOV71pPvGQBpE6T/+DvgAwBv0syTjk/RX2K98SusZqd0fIX+Gp3cmAr99VrXS64wQyDTfWLvn+RoVzbNAumUEWWk16AZHx0Hqd0UnbNeyPj0GNLuxdo9070AijdwbAAZD2O2AADIJLTrm3Y50/E3nEzDGccGkDExZgsAUqEFDbTCV0oFLLTCoRY3QGI6hi21sTE6ZsyuDpkR+fs16PWNdGyNjvvSAiu9e/f2yfMg8+HYADI2gi0ASIV293EuiJAULZqApOlAfLvaXnIGDx4sGZm/X4NWmdOAX4seaKEWX1ddRObBsQFkbIzZAgAAAAAfYMwWAAAAAPgAwRYAAAAA+ABjttIgISFBjh49ai5CGRQU5O/mAAAAAPATHYV18eJFUxgrODjl3BXBVhpooFWyZEl/NwMAAABABnHo0CEpUaJEiusQbKWBZrTsHZo7d25/NwcAAACAn1y4cMEkYuwYISUEW2lgdx3UQItgK42uXBG5/fb/3l6/XoQLLAIAACALScvwIoIt+IZeUWDHjv/dBgAAAAIM1QgBAAAAwAcItgAAAADAB+hGCAAAgAxbYjsuLk7i4+P93RQEmLCwMAkJCbnu7RBsAQAAIMOJiYmRY8eOyRUtugX4ofiFlnXPmTPndW2HYAsAAAAZSkJCgkRFRZnMgl44Njw8PE2V3wBvZVRPnTolhw8flooVK15XhotgC76hX4ilS//vNgAAgAdZLQ249FpG2bl8DPygUKFCsn//fomNjSXYQgakX4z79/u7FQAAIBMLDqaWG/zDW5lUjmAAAAAA8AGCLQAAAADwAboRBhgd7HfhwgWPH5c7d27TdzXNrl4VadTov7d/+00kWzaPnxMAAADIzAi2AizQ6tj5WTl30fMSqnlzZZcZ0z5Je8CVkCCyYcP/bgMAAASA48ePy5gxY2TBggVy5MgRKVy4sNSoUUP69OkjTZs2lUA2b948mTJlimzcuFHOnj0rmzZtMvvG2bVr16R///4yZ84ciY6OlhYtWsiHH34oRYoUcaxz8OBB6d69uyxbtsyUZu/UqZOMHTtWQkNTDm30PRk1apRs2bJFIiMj5e6775b58+eLLxFsBRDNaGmgVfHutpK7QJG0P+7MCdmz/BvzeI+yWwAAAAFEq9c1aNBA8ubNK2+99ZZUq1bNVLP7+eefpUePHrJr1y4JZJcvX5aGDRvK448/Ls8991yS6/Tt29cERV999ZXkyZNHevbsKW3atJFVq1aZ5XqB69atW0vRokXl999/N9di69ixo7kI8euvv57sc3/zzTfmOXWdJk2amItlb9u2TXyNMVsBSAOt/EVKpHnyJDADAADwqcuXk5+uXUv7ujrkIbV1PfTCCy+YKnbr1q2Ttm3bys033yxVq1aVfv36yZo1axzr6TqTJ0+Wli1bSrZs2aRcuXLy9ddfu2zr0KFDJijRwC1//vzy0EMPmWDOmd7XbblP586dc3ku9+xN48aNTabNphmkl156SW666SbJkSOH1K1bV3799VeXx6xcuVLuuusu014tyd+rVy8TPHmiQ4cOMmzYMGnWrFmSy8+fPy+ffvqpjB8/3gREtWvXlmnTppmgyt5/v/zyi+zYsUNmzpxpsmK6D0ePHi2TJk0ylwxIigZWvXv3NgFwt27dzPtSpUoVs399jWALAAAAmUfOnMlPbdu6rlu4cPLrtmzpum6ZMonX8YB2i1u4cKHJYGnA4k6DJmdDhw41Admff/4p7du3l3bt2snOnTvNMs2Gafe5XLlyyYoVK0xWR7vL3XfffUkGFIsXLzYZHs3epIdmj1avXm267mkXu8cee8w81549e8zyv//+29zX9uryL7/80gRf+jjbiBEjpIzuw+uwceNG89qdg7FKlSpJqVKlTPuU/tWMoXO3Qt1X2gNr+/btSW73jz/+MF069VICNWvWlGLFipkgjcwWAAAAkAns3btXLMsywUFaaEDz7LPPmiyLZmbq1KkjEydONMs0mNGLOn/yyScmsKhcubLJ8OhYJeeMk2aklHap00kzYJ7Sbeq2tdueZq7Kly9vslza3U/nKx0PpQGhZsMqVqwo9evXlwkTJsiMGTPMGCtVsGBB89jrHe8WHh6eKDDVwEqX2es4B1r2cntZUvbt2+cICIcMGSI//PCD5MuXz2T4NEj2JcZsAQAAIPO4dCn5ZSEhrvdPnkx+XfcLJrt10fOUBlqeqFevXqL7mzdvNrc126XBm2a2nGlgo1km25kzZxxVo1Py5JNPSojTvrl69aqjMMXWrVvNOCgN+pxpIFegQAFHezSjNWvWLJfXqwFhVFSUCQY1y+Wc6cpIEv6/WNvgwYNNdk5pIFmiRAkTZP7rX//y2XMTbMF3Chb0dwsAAEBWk0QXvRu+bhI046Pjo7xRBOPSpUtmvJJzcGNzLlamGRvNBBUvXjzF7b377rsuXfM0S+X8XBqIaRc+54BMaddFex0NSHScljvt4uctRYsWNd0kdcyZc3brxIkTZpm9jo6Jc6bL7WVJ0W6DSsdp2SIiIsxYOc3s+RLdCOEb+oV16tR/p+v88gIAAMjotAufjh3SQg1JFY5wLlqhnAtm2Pc1Q6Rq1aplxktp2fgKFSq4TFqhz7Z8+XLTpc89SHKnQYjzNrTIhU3HMGlm6+TJk4meyw5etD1alMJ9uU4a7HlL7dq1TVXBJUuWOObt3r3bBER2JlD/ajZO22tbtGiRye45B1Pu29XgSrdl07FhWmCkdOnS4ksEWwAAAIAXaKClgcsdd9xhilVowKRFL3R8k3u3Qe2+NnXqVPnrr79k+PDhJltjd8PTzJOOgdIKhFogQ7vq6VgtzSwdPnzYPMdvv/0ms2fPNmXRdaySTvb4I+dAJDXafVCfT8un63Ww9Lm0LTpOS0uwq4EDB5qKgNo+7eqor+u7775z6Tb4wQcfpHodsbNnz5rHa+CmNPjR+/ZYKw0ku3btaqo36jW0NNvWuXNns+/uvPNOs07z5s1NUKWVDbV7o5bV13FYWphEAyql7dexc1oUQ2kgplUIdT9rNUN9Xr1Olz12zpfoRggAAAB4gXZL08p3elFjvTCvVgjUbn+aWdFS785Gjhxpqv9puXjt5vbFF184MjPZs2c3wZQGORpMXbx40ZRl12BGAwctC68X5FUagLl377vllls8GkOm45dee+0102YNUDTQ0+Dm/vvvN8urV69usmg65kmLaOi2tRjGE0884djG6dOnXcaTJeX77783wZNNKzAqDYK0eIXd5VGrBurYKueLGts0i6cFLjRY0iBMKz/qRY31YsW2K1eumIBKs1c2LfuuFz3WIE3HrGl5+6VLl5pCGb4UZHk6mi8AaSlJjbS19n9qAxAzMv0APN2lm9Ru84K5flZanT1xWDbO+1BmTp2S9iozeu0Ku6TqTz+JOKWrAQAAUqKFIDTDUrZsWYmMjJSsRsd2ffvtt/Lwww+n6/Ha/U0r6blfd8um453cuy3Ce8egJ7EBmS34hlZ9Wb78f7cBAADgFZrdcS6U4c69NDr8h2ALaRIbEyMHDhxI8/pBV65IOZ+2CAAAIDCVLFlS1q9fn+xy50IQ8C+CLaTq6qXzEhW1T14ePELCw/878DA1kfHxsuz/b586dUoKUZEQAADAYBRP4CDYQqpirl0VKzhUyjdsI4VLpK08Znj0NZFV/w23dFBn8oluAAAAIGsi2EKa5cpfKM2FNcKuXfV5ewAAQNZGBgiZ/djjOlsAAADIUPTCtnYJb8AfYmJizN/ULhidGjJb8Jno8AhJiPvf9Q0AAADSQk9wtXy5fXFeve6UlksHboSEhARTc0CPO7021/Ug2IJPxEZmk/7jvvjv9bmyZ/d3cwAAQCZTtGhR89cOuIAbSS+sXKpUqesO8gm2AAAAkOHoSW6xYsWkcOHCEhtLTxncWOHh4Sbgul4EWwAAAMjQXQqvd9wM4C8EW/CJ0Jho6fbxa3L++AEJio72d3MAAACAG45gCz4RlJAgt+74w9zeFx/v7+YAAAAANxyl3wEAAAAgqwVbY8eOldtvv11y5cplBj8+/PDDsnv3bpd1GjdubAZIOk/dunVzWefgwYPSunVrU55Rt/Pyyy9LXFycyzq//vqr1KpVSyIiIqRChQoyffr0G/IaAQAAAAQmvwZby5cvlx49esiaNWtk0aJFptJM8+bN5fLlyy7rPffcc3Ls2DHHNG7cOMey+Ph4E2jphcd+//13+eyzz0wgNWzYMMc6UVFRZp177rlHNm/eLH369JFnn31Wfv755xv6egEAAAAEDr+O2Vq4cKHLfQ2SNDO1ceNGadSokWO+Zqzsay24++WXX2THjh2yePFiKVKkiNSoUUNGjx4tAwcOlBEjRpiyjVOmTJGyZcvKO++8Yx5TuXJlWblypbz77rvSokULH79KAAAAAIEoQ43ZOn/+vPmbP39+l/mzZs2SggULyq233iqDBg2SK1euOJatXr1aqlWrZgItmwZQFy5ckO3btzvWadasmcs2dR2dn5To6GjzeOcJAAAAADJlNcKEhATTva9BgwYmqLI99dRTUrp0aSlevLhs2bLFZKx0XNe8efPM8uPHj7sEWsq+r8tSWkeDqKtXr0q2bNkSjSUbOXKkz14rAAAAgKwvwwRbOnZr27Ztpnufs+eff95xWzNYeiXxpk2byt9//y3ly5f3SVs0e9avXz/HfQ3KSpYs6ZPnyqpiI7NJz/fmycZ5H8rM7Nn93RwAAAAgMLsR9uzZU3744QdZtmyZlChRIsV169ata/7u3bvX/NWxXCdOnHBZx75vj/NKbp3cuXMnymoprVioy5wnAAAAAMg0wZZlWSbQ+vbbb2Xp0qWmiEVqtJqg0gyXqlevnmzdulVOnjzpWEcrG2qAVKVKFcc6S5YscdmOrqPzAQAAACDLdSPUroOzZ8+W7777zlxryx5jlSdPHpNx0q6CurxVq1ZSoEABM2arb9++plJh9erVzbpaKl6Dqg4dOpiS8LqNIUOGmG1rhkrpdbk++OADGTBggHTp0sUEdnPnzpUFCxb48+VnaaEx0dJl2lvS5sjfEhQd7e/mAAAAAIGV2Zo8ebKpQKgXLtZMlT19+eWXZrmWbdeS7hpQVapUSfr37y9t27aV//znP45thISEmC6I+lczVU8//bR07NhRRo0a5VhHM2YaWGk267bbbjMl4D/55BPKvvtQUEKC1PpztTQ5fVIvhubv5gAAAACBldnSboQp0aIUeuHj1Gi1wh9//DHFdTSg27Rpk8dtBAAAAIBMWyADAAAAALIagi0AAAAA8AGCLQAAAADwAYItAAAAAPABgi0AAAAA8AGCLfhEbESk9HtzttzT4B6xsmXzd3MAAACAG45gC74RFCQxEZFyLSTE3AYAAAACDcEWAAAAAGS1ixoj6wqJjZGnZ02Ulgd3iURH+7s5AAAAwA1HsAWfCI6PlzvXLzO398XH+7s5AAAAwA1HN0IAAAAA8AGCLQAAAADwAYItAAAAAPABgi0AAAAA8AGCLQAAAADwAYItAAAAAPABgi34RGxEpLzy2jRpeWcjsbJl83dzAAAAgBuOYAu+ERQkl3LmkXPh4eY2AAAAEGjSFWzt3r1bDh8+bG6vW7dOhg0bJl988YW32wYAAAAAgRNsjR8/XipXrizlypWTKVOmSNOmTeWnn36SZ599VkaOHOmbViLTCYmNkce//lhe2rNLJDra380BAAAAMn6wNXHiRBNwaSard+/e8uGHH8r69etl1qxZMm3aNN+0EplOcHy8NFq5UNoeOyxB8fH+bg4AAABww4V6+gDtPvj4449L8eLFJTg4WO68804zv27dunLkyBFftBEAAAAAsn5mKz4+XsLCwszt0NBQM5kNBQdLQkKC91sIAAAAAIGQ2VI6TkuDrKtXr8oDDzwg4eHhEhcX5/3WAQAAAECgBFvDhw933H7ooYdclrVt29Y7rQIAAACAQA62AAAAAABe7EaoNm7cKDt37jS3q1atKjVr1kzvpgAAAAAgy/E42Dp58qS0a9dOfv31V8mbN6+Zd+7cObnnnntkzpw5UqhQIV+0E5lMXHiEDBs6Rbb+/Lm8HRnp7+YAAAAAGb8a4YsvvigXL16U7du3y9mzZ820bds2uXDhgvTq1cs3rUSmYwUHy9kCheV4ZDYtVenv5gAAAAAZP7O1cOFCWbx4sVSuXNkxr0qVKjJp0iRp3ry5t9sHAAAAAIERbOm1tOzrbDnTeVxnC7aQuFh5+LvPpN6+PSIxMf5uDgAAAHDDedy/q0mTJtK7d285evSoY96RI0ekb9++5vpbgAqOi5Nmy76T9ocPSBDXYAMAAEAA8jjY+uCDD8z4rDJlykj58uXNVLZsWTNv4sSJvmklAAAAAGT1boQlS5aUP/74w4zb2rVrl5mn47eaNWvmi/YBAAAAQGAEWzNmzJAnnnhC7r33XjMBAAAAALzQjbBz585y/vx5Tx8GAAAAAAHF42DLsizftAQAAAAAArkboZo7d67kzp07yWUdO3a83jYBAAAAQGAGW+PGjZOQkJBE84OCggi2YMSFR8hrA9+THYvnyOjISH83BwAAAMgcwdaGDRukcOHC3m8NsgwrOFiOFyslUTlyigR73FsVAAAAyPQ4CwYAAACAjJDZKl26dJJdCAFnIXGx0uqnOVJj/98iMTH+bg4AAACQ8TNbUVFRUqBAAa88+dixY+X222+XXLlymW6JDz/8sOzevdtlnWvXrkmPHj3Mc+bMmVPatm0rJ06ccFnn4MGD0rp1a8mePbvZzssvvyxxcXEu6/z6669Sq1YtiYiIkAoVKsj06dO98hqQtOC4OGn181x59mCUBLm9FwAAAEAg8DizNWHChBSX9+rVK83bWr58uQmkNODS4OjVV1+V5s2by44dOyRHjhxmnb59+8qCBQvkq6++kjx58kjPnj2lTZs2smrVKrM8Pj7eBFpFixaV33//XY4dO2aKdISFhcnrr7/uCBB1nW7dusmsWbNkyZIl8uyzz0qxYsWkRYsWnu4CAAAAAPB+sPXuu+86bh86dMgELKGhoY5qhJ4EWwsXLnS5r9kmzUxt3LhRGjVqZC6e/Omnn8rs2bOlSZMmZp1p06ZJ5cqVZc2aNXLnnXfKL7/8YoKzxYsXS5EiRaRGjRoyevRoGThwoIwYMULCw8NlypQpUrZsWXnnnXfMNvTxK1euNK+FYAsAAABAhulGaE/ZsmUz2Sn7/r59+66rMRpcqfz585u/GnTFxsZKs2bNHOtUqlRJSpUqJatXrzb39W+1atVMoGXTAOrChQuyfft2xzrO27DXsbfhLjo62jzeeQIAAACATFmNMCEhQfr06SMNGjSQW2+91cw7fvy4yUzlzZvXZV0NrHSZvY5zoGUvt5eltI4GUVevXk1yLJl2WbSnkiVLevnVAgAAAMjqMkywpWO3tm3bJnPmzPF3U2TQoEEmy2ZP2l0SAAAAAHw6ZmvLli2O25Zlya5du+TSpUuOedWrV/d0k6boxQ8//CC//fablChRwjFfi17ExMTIuXPnXLJbWo1Ql9nrrFu3zmV7drVC53XcKxjq/dy5c5uukO60YqFOAAAAAHDDgi0tQKGFMDTQUvfff7/jvv7V6oBppY958cUX5dtvvzWl2bWIhbPatWubqoJaPVBLvistDa+l3uvVq2fu698xY8bIyZMnTXENtWjRIhNIValSxbHOjz/+6LJtXcfeBrwvLjxcxvV7U3Yt+1oGE7gCAAAgAHkcbGkhDG92HdRKg99995251pY9xkrHSWnGSf927dpV+vXrZ4pmaAClwZkGSVqJUGmpeA2qOnToIOPGjTPbGDJkiNm2nZ3Sku8ffPCBDBgwQLp06SJLly6VuXPnmpLy8A0rOEQOlqooO3PlEeEi2AAAAAhAHgdbpUuX9tqTT5482fxt3Lixy3wt7/7MM8+Y21qePTg42GS2tEqgVhH88MMPHeuGhISYLojdu3c3QZhen6tTp04yatQoxzqaMdPASq/Z9f7775uuip988gll3wEAAABknGBLff755+baVZrl0vLpGoC99957Jqh56KGH0rwduytiSiIjI2XSpElmSo4+v3s3QXca0G3atCnNbcP1CYmLlaZL50ulQ/tFYmL83RwAAAAg41cj1GyUdutr1aqVKVxhj9HSAhYacAEqOC5OHvl+hvSM2itBcXH+bg4AAACQ8YOtiRMnyr///W8ZPHiw6cJnq1OnjmzdutXb7QMAAACAwAi2tOtgzZo1E83XYhSXL1/2VrsAAAAAILCCLR2XtXnz5kTzFy5cKJUrV/ZWuwAAAAAgsApk6HgtLat+7do1U+BCLyj8xRdfyNixY02FPwAAAABAOoKtZ5991lwDS69ldeXKFXnqqaekePHipqR6u3btfNNKAAAAAAiE0u/t27c3kwZbly5dksKFC3u/ZQAAAAAQSGO2nGXPnp1AC0mKCw+X93uMkheq1xIrIsLfzQEAAAAyfmarXLlyKS7ft2/f9bQHWYQVHCJ7Kt4qm7b+JuJ0iQAAAAAgUHgcbO3fv19KlCghHTp0IKsFAAAAAN4KtrTs+0cffSQff/yxNG7cWJ5//nm59957Pd0MsrjguDhptOInKXP0kEhsrL+bAwAAAGT8MVvVq1eXSZMmycGDB6VVq1YydOhQqVChgixatMg3LUSmFBIXK49/8295ae9uCSLYAgAAQABKd4EMLf9+9913yz333COnT5+Ww4cPe7dlAAAAABBIwVZcXJzMnTtXmjVrJo0aNZKQkBDTtbBz586+aSEAAAAABMKYrZtuukkiIiKkS5cuMm7cOAkNDZULFy7Ili1bHN0MAQAAACDQeRxsnTp1yvwdNWqUjB492ty2LMv8DQoKkvj4eG+3EQAAAACyfrAVFRXlm5YAAAAAQCAHWwULFpQcOXL4pjUAAAAAEKgFMooUKWLGa61cudI3LUKWEB8WJpOfe1X6V60hVni4v5sDAAAAZPxga+bMmXL27Flp0qSJ3HzzzfLGG2/I0aNHfdM6ZFoJIaGyvWod+b1AQZFQjxOoAAAAQOAFWw8//LDMnz9fjhw5It26dZPZs2dL6dKl5f7775d58+aZ0vAAAAAAEOjSfVHjQoUKSb9+/UzJ9/Hjx8vixYvl0UcfleLFi8uwYcPkypUr3m0pMpXguDipu3aptDp+VCQ21t/NAQAAAG64dPfvOnHihHz22Wcyffp0OXDggAm0unbtKocPH5Y333xT1qxZI7/88ot3W4tMIyQuVjp88YG5vY9gCwAAAAHI42BLuwpOmzZNfv75Z6lSpYq88MIL8vTTT0vevHkd69SvX18qV67s7bYCAAAAQNYNtjp37izt2rWTVatWye23357kOtqVcPDgwd5oHwAAAAAERrB17NgxyZ49e4rrZMuWTYYPH3497QIAAACAwCqQcfr06STnaxXCIUOGeKNNAAAAABB4wVbDhg3lr7/+cpm3ceNGqVmzpikJDwAAAABIR7DVsWNHueuuu2Tz5s0SGxsrr776qrmv19n6448/fNNKAAAAAMjqY7Zee+01yZcvnzRu3FhuuukmCQoKkuXLlydbLAOBKT4sTD595iXZt/Zn6RIe7u/mAAAAAJnjOlv9+/eXPHnySLdu3WTu3LkEWkgkISRUNtWoLxv3bZYuoem+nBsAAACQaXl8FjxhwgTH7UaNGslTTz0lgwYNMtku1atXL++2EAAAAAACIdh69913Xe4XK1ZMpk+fbm5rl0KCLajg+Dipufl3yXPqhJaq9HdzAAAAgIwfbEVFRfmmJchSQmJjpev0t83tfTEx/m4OAAAAkPGrETqzLMtMAAAAAAAvBFszZsyQatWqSbZs2cxUvXp1+fzzz9OzKQAAAADIkjzuRjh+/HgZOnSo9OzZUxo0aGDmrVy50lQmPH36tPTt29cX7QQAAACArB1sTZw4USZPnmwubmx78MEHpWrVqjJixAiCLQAAAABITzfCY8eOSf369RPN13m6DAAAAACQjmCrQoUK5kLG7r788kupWLGit9oFAAAAAIHVjXDkyJHyxBNPyG+//eYYs7Vq1SpZsmRJkkEYAlN8aJh8/mRP2b9xqTwVFubv5gAAAAAZP7PVtm1bWbt2rRQsWFDmz59vJr29bt06eeSRR3zTSmQ6CaGhsrZuE/mxaHERgi0AAAAEoHSVfq9du7bMnDlTNm7caCa9XbNmTY+3o9mxBx54QIoXLy5BQUEmcHP2zDPPmPnO03333eeyztmzZ6V9+/aSO3duyZs3r3Tt2lUuXbrkss6WLVvkrrvuksjISClZsqSMGzcuPS8b6RAbEyMHDhyQv//+26Pp1KlT/m46AAAAcGO7ESbn4sWL0rt3b3M7T5488u6776b6mMuXL8ttt90mXbp0kTZt2iS5jgZX06ZNc9yPiIhwWa6BlhbmWLRokcTGxkrnzp3l+eefl9mzZ5vlFy5ckObNm0uzZs1kypQpsnXrVvN8GpjpevCN4Pg4qbjxNzm9a7u88upwCYmI9OjxeXNllxnTPpFChQr5rI0AAABAhgq2kguKoqOjZeHChTJv3jyTQUqLli1bmiklGlwVLVo0yWU7d+40z7l+/XqpU6eOozR9q1at5O233zYZs1mzZklMTIxMnTpVwsPDTYn6zZs3m+uFEWz5TkhsrPT+/D3R8LtD3fslT7mb0/zYC2dOyJ7l35hAmWALAAAAARNsaVe/xx9/XLJly+Yy/+rVq+bvQw895L3Wicivv/4qhQsXlnz58kmTJk3ktddekwIFCphlq1evNhkqO9BSmsEKDg4248p0DJmu06hRIxNo2Vq0aCFvvvmm/PPPP2a7SQWOOtn0pB/plzN/QclfpIS/mwEAAABk/G6EEyZMMAGQs+PHj8tXX30l3qRdCDWTVrZsWTOO59VXXzWZMA2gQkJCzHO6tyM0NFTy589vltnt0sc7K1KkiGNZUsHW2LFjTdVFAAAAALhhwZZdqCKp+d7Wrl07x+1q1apJ9erVpXz58ibb1bRpU68/n23QoEHSr18/l8yWFtYAAAAAAJ8FW5ZlmUBHuxFqBUDNGmk3vfr164uvlStXzpSZ37t3r2mDjuU6efKkyzpxcXGmQqE9zkv/njhxwmUd+35yY8F0nJh7IQ4AAAAA8GmwNXz4cPNXxzSdOXNG9u3bJ19++aVPMlvuDh8+bJ6zWLFi5n69evXk3Llzpvy8lqNXS5culYSEBKlbt65jncGDB5tKhWH/f70nrVx4yy23JNmFEAAAAAD8Gmw508Br6NChpgLgqFGjJGfOnC7d8JKj18PSLJUtKirKVArUMVc66bgpvYiyZqB0zNaAAQOkQoUKpsCFqly5shnX9dxzz5my7hpQ9ezZ03Q/1EqE6qmnnjLb0etvDRw4ULZt2ybvv/9+mkrTAwAAAIBfr7OlXe40CMuRI4fpZqhTWmzYsEHuuecex307QOvUqZNMnjzZXIz4s88+M9krDZ70elmjR4926eKnpd01wNJuhVqFUIMzLeBh02t+/fLLL9KjRw+T/dJuiMOGDaPsu4/Fh4bJZ/c9Idt+XyTxIV67nBsAAACQaXjtLFgDraSyXilp3LhxioHZzz//nOo2NANmX8A4OVpYY8WKFR61DdcnITRUFte5Wxb8uVYeIdgCAABAAAr2dwMAAAAAICsi5QCfCEqIl0r7/5Jz0VclKCHB380BAAAAbjiCLfhEaEyMDJ75nrndPS7G380BAAAAbji6EQIAAABARslsxcfHy/z582Xnzp3mftWqVeXBBx+UkJAQb7cPAAAAAAIj2NLrYrVu3dpcYFgvDKzGjh0rJUuWlAULFkj58uV90U4AAAAAyNrdCHv16iXlypWTQ4cOyR9//GGmgwcPStmyZc0yAAAAAEA6MlvLly+XNWvWmOtb2QoUKCBvvPGGNGjQwNvtAwAAAIDAyGxFRETIxYsXE82/dOmShIeHe6tdAAAAABBYwdb9998vzz//vKxdu1YsyzKTZrq6detmimQAKiE0VL5o+ogMz5VP4oO5wgAAAAACj8fB1oQJE0wRjHr16klkZKSZtPtghQoV5P333/dNK5HpxIeGyY/17pWJOfNIfCjBFgAAAAKPx2fBefPmle+++0727Nkju3btMvMqV65sgi0AAAAAwH+lO+VQsWJFM9nX3QKcBSXES9mj+6VmTLQEJST4uzkAAABAxu9GGBUVJU8++aR0795d/vnnHzNOS4tm6DW3tmzZ4ptWItMJjYmRUVPHyZIzxyQsLsbfzQEAAAAyfrD1r3/9S3bu3Cnbtm2TJk2aSExMjOlWWKVKFenTp49vWgkAAAAAWb0boVYhXLFihZQuXdpca2v9+vVSq1YtM2arbt26vmklAAAAAGT1zJZeY6tYsWKSJ08eyZ49uymYofRvUtffAgAAAIBAlK4CGQsXLjTBVkJCgixZssR0KTx37pz3WwcAAAAAgRRsderUyWUMly0oKMg7rQIAAACAQAu2NJsFAAAAAPDymK0ZM2ZIdHS0pw9DgEkIDZV5d7WSN3PmkfjgdF/ODQAAAAicYKtz585y/vx537QGWUZ8aJh8e/f98maufBIfSrAFAACAwONxsGVZlm9aAgAAAABZSLpSDnPnzpXcuXMnuaxjx47X2yZkAUEJCXLTqaNSKTbG3AYAAAACTbqCrXHjxklISEii+VqNkGALKjQmWkZ+9Jq53T0uxt/NAQAAADJHsLVhwwYpXLiw91sDAAAAAIE6ZgsAAAAA4INgq3Tp0kl2IQQAAAAAXEc3wqioKE8fAgAAAAABx+PMVq9evWTChAmJ5n/wwQfSp08fb7ULAAAAAAIr2Prmm2+kQYMGiebXr19fvv76a2+1CwAAAAACqxvhmTNnJE+ePInm63W3Tp8+7a12IZNLCA2VBXc2k31b10l8cLqKXgIAAACBldmqUKGCLFy4MNH8n376ScqVK+etdiGTiw8NkznN2sjw3PklPpRgCwAAAIHH47Pgfv36Sc+ePeXUqVPSpEkTM2/JkiXyzjvvyHvvveeLNgIAAABA1g+2unTpItHR0TJmzBgZPXq0mVemTBmZPHmydOzY0RdtRCYUlJAgBc+dkZJxseY2AAAAEGjS1b+re/fuZtLsVrZs2SRnzpzebxkytdCYaHn3g6Hmdve4GH83BwAAAMj4Y7ZUXFycLF68WObNmyeWZZl5R48elUuXLnm7fQAAAAAQGJmtAwcOyH333ScHDx403QnvvfdeyZUrl7z55pvm/pQpU3zTUgAAAADIypmt3r17S506deSff/4xXQhtjzzyiCmUAQAAAABIR2ZrxYoV8vvvv0t4eLjLfC2SceTIEW+2DQAAAAACJ7OVkJAg8fHxieYfPnzYdCcEAAAAAKQj2GrevLnL9bSCgoJMYYzhw4dLq1atvN0+AAAAAAiMboR68eIWLVpIlSpV5Nq1a/LUU0/Jnj17pGDBgvLFF1/4ppXIdBJCQmRx7Uayf+cmSQgO8XdzAAAAgIyf2SpRooT8+eef8uqrr0rfvn2lZs2a8sYbb8imTZukcOHCHm3rt99+kwceeECKFy9uMmTz5893Wa5l5YcNGybFihUzxTiaNWtmAjtnZ8+elfbt20vu3Lklb9680rVr10Ql6Lds2SJ33XWXREZGSsmSJWXcuHGevmx4KD4sXD5r2U4G5CkgcaFh/m4OAAAAkDkuahwaGipPP/30dT/55cuX5bbbbpMuXbpImzZtEi3XoGjChAny2WefSdmyZWXo0KEmq7Zjxw4TOCkNtI4dOyaLFi2S2NhY6dy5szz//PMye/Zss/zChQum66MGalqWfuvWreb5NDDT9QAAAAAgQwRb33//fYrLH3zwwTRvq2XLlmZKima1dGzYkCFD5KGHHjLzZsyYIUWKFDEZsHbt2snOnTtl4cKFsn79elOOXk2cONGMHXv77bdNxmzWrFkSExMjU6dONRUUq1atKps3b5bx48cnG2zp9cJ0smnABg9ZluS6fFEKaDGV/7/wNQAAABBIPA62Hn74YZf72v1PAyP7dlKVCtMjKipKjh8/bjJStjx58kjdunVl9erVJtjSv5qhsgMtpesHBwfL2rVrzbW/dJ1GjRq5lKrX7JhehFmvFZYvX75Ezz127FgZOXKkV15HoAqLviYfvjvQ3O4e+7/AFQAAAAgU6Sr97jxlz55d9u7dm2xJ+PTSQEtpJsuZ3reX6V/3cWLaxTF//vwu6yS1DefncDdo0CA5f/68Yzp06JDXXhcAAACAwJCuMVvONJuV1URERJgJAAAAAG5YZsvZ/v37TZELX1zMuGjRoubviRMnXObrfXuZ/j158qTL8ri4OFOh0HmdpLbh/BwAAAAA4PdgS6sG6qSFLbTse9OmTaVQoUJeb5hWH9RgaMmSJS6FKnQsVr169cx9/Xvu3DnZuHGjY52lS5eaLo06tsteR0vMa6VCm1YuvOWWW5IcrwUAAAAAfgm2tEiFThoMjRkzJtXqhCnR62FpZUCd7KIYevvgwYOme2KfPn3ktddeM8+hJds7duxoKgzaRToqV64s9913nzz33HOybt06WbVqlfTs2dMUz9D1lF50WYtj6PW3tm/fLl9++aW8//770q9fv3S3GwAAAAC8PmZr2rRp4i0bNmyQe+65x3HfDoA6deok06dPlwEDBphuilqiXTNYDRs2NKXe7WtsKS3trgGWZti0CmHbtm3NtblsGhj+8ssv0qNHD6ldu7YULFjQXCiZa2wBAAAAyFDBVmrXnMqdO3eat9W4cWNH2fikaHZr1KhRZkqOVh60L2CcnOrVq8uKFSvS3C5cv4SQEFlR/U45tGerJASH+Ls5AAAAQMYPtvS6VklVINSgyZvX2ULmFh8WLh8/2FEWfDpOHgkN83dzAAAAgIwfbJUrV85UAHzllVekQYMGvmkVAAAAAARasLVz506ZOHGiKY6xadMmGTdunCmWAbiwLImIiZbsCQnmtqdiY2LkwIEDHj9Ou7H6ojomAAAA4PNgKywszBSyeOaZZ8xYKh0PpcUmhg4daroYAios+pp8Mq6vud09Ntqjx169dF6iovbJy4NHSHi4ZxeXzpsru8yY9gkBFwAAADJfsOVcmOK9994zlQAHDhwoFSpUkCFDhphy7cD1iLl2VazgUCnfsI0ULlE6zY+7cOaE7Fn+jSniQrAFAACATBds6YWM3QtkaHGM6Oho6d+/P8EWvCZX/kKSv0gJfzcDAAAAuDHBln1BYQAAAACAF4Ot4cOHe/oQAAAAAAg4fr2oMQAAAABkVVzUGAAAAAAySjXCr7/+2lQjBJJjBQfLuso15VjUbkkICvZ3cwAAAIDMEWw1aNBAChcu7P3WIMuIC4+QiW2fkwWfjpNHwsL93RwAAAAgcwRbO3bskDNnzkiOHDmkaNGiEh7OyTQAAAAAOEtX/66mTZtK1apVpWzZsibgqlatmrz77rvp2RQAAAAAZEkeZ7aioqJMMYzY2FhTmfDo0aOybt06GTp0qMTFxcnLL7/sm5YiUwm7dlU+f+0Fc7t7zDV/NwcAAADI+MFW6dKlXe7Xrl1bHnjgAbn55ptl1KhRBFsAAAAAkN4xW0lp166d6VoIAAAAALiOYGvjxo2yc+dOc7tKlSpSq1YtMwEAAAAA0hFsnTx50mSxfv31V3OBY3Xu3Dm55557ZM6cOVKoUCFftBMAAAAAsnY1whdffFEuXrwo27dvl7Nnz5pp27ZtplhGr169fNNKAAAAAMjqma2FCxfK4sWLpXLlyo552o1w0qRJ0rx5c2+3DwAAAAACI9hKSEiQsLCwRPN1ni4DlBUcLJsrVJWTh/ZJQlC6LucGAAAAZGoenwU3adJEevfuba6vZTty5Ij07dvXXOwYUHHhEfJOux7SLn8RiQsL93dzAAAAgIwfbH3wwQdmfFaZMmWkfPnyZipbtqyZN3HiRN+0EgAAAACyejfCkiVLyh9//GHGbe3atcvM0/FbzZo180X7AAAAACBrB1tagTBXrlzmdlBQkNx7771mcrZ+/Xq5/fbbvd9KZDph167KJ2/2kbi4WHkp5pq/mwMAAABk3G6EWmnw0qVLSS6Li4uTIUOGSIMGDbzZNmRyEbExksOy/N0MAAAAIGMHW5rZ0q6COjbLmV5jS7NZ06dPl/nz5/uijQAAAACQdYOtZcuWyeXLl03XQQ24LMuSN998U+rUqWPGbG3dulVatWrl29YCAAAAQFYbs1WoUCFZunSpyW5p+feIiAjZs2ePzJw5Ux599FHfthIAAAAAsnI1Qg24lixZYgIu7T64efNmqVSpku9aBwAAAACBcp2tggULmgxXlSpV5KmnnpJ//vnHNy0DAAAAgEDIbLVp08blfu7cueW3336TO+64Q6pVq+aYP2/ePO+2EJmSFRwkO0tVlDPHD4oV5HFMDwAAAAROsJUnT55E98uWLeuLNiELiAuPlNc79pUFn46TR8LC/d0cAAAAIOMGW9OmTfNtSwAAAAAgC6F/FwAAAAD4AMEWfCLs2lWZNH6A/HXioITHXPN3cwAAAICMXfod8ETuK5f83QQAAADAb8hsAQAAAIAPEGwBAAAAgA/QjRBZSmxMjBw4cMDjx+l14woVKuSTNgEAACAwEWwhy7h66bxERe2TlwePkPDwCI8emzdXdpkx7RMCLgAAAARGsDVixAgZOXKky7xbbrlFdu3aZW5fu3ZN+vfvL3PmzJHo6Ghp0aKFfPjhh1KkSBHH+gcPHpTu3bvLsmXLJGfOnNKpUycZO3ashIZm6JeOdIi5dlWs4FAp37CNFC5ROs2Pu3DmhOxZ/o1cuHCBYAsAAABek+EjjqpVq8rixYsd952DpL59+8qCBQvkq6++kjx58kjPnj2lTZs2smrVKrM8Pj5eWrduLUWLFpXff/9djh07Jh07dpSwsDB5/fXX/fJ6AoUVHCT7ipWSc6ePixV0Y4cG5spfSPIXKXFDnxMAAADIdAUyNLjSYMmeChYsaOafP39ePv30Uxk/frw0adJEateuLdOmTTNB1Zo1a8w6v/zyi+zYsUNmzpwpNWrUkJYtW8ro0aNl0qRJEhMT4+dXlrXFhUfK8K6vSLOCxSU2LNzfzQEAAABuuAwfbO3Zs0eKFy8u5cqVk/bt25tugWrjxo0SGxsrzZo1c6xbqVIlKVWqlKxevdrc17/VqlVz6VaoXQ21u9j27duTfU7tkqjrOE8AAAAAkGWCrbp168r06dNl4cKFMnnyZImKipK77rpLLl68KMePH5fw8HDJmzevy2M0sNJlSv86B1r2cntZcnRMl3ZLtKeSJUv65PUBAAAAyLoy9Jgt7fZnq169ugm+SpcuLXPnzpVs2bL57HkHDRok/fr1c9zXzBYBl2fCoq/J+IlDZMyl8zI2JtrfzQEAAABuuAyd2XKnWaybb75Z9u7da8Zv6birc+fOuaxz4sQJs0zpX73vvtxelpyIiAhz3SXnCR6yLCl0/qyUio/XO/5uDQAAAHDDZapg69KlS/L3339LsWLFTEEMrSq4ZMkSx/Ldu3ebMV316tUz9/Xv1q1b5eTJk451Fi1aZIKnKlWq+OU1AAAAAAgMGbob4UsvvSQPPPCA6Tp49OhRGT58uISEhMiTTz5pxlJ17drVdPfLnz+/CaBefPFFE2Ddeeed5vHNmzc3QVWHDh1k3LhxZpzWkCFDpEePHiZ7BQAAAAABGWwdPnzYBFZnzpwxF5tt2LChKetuX3j23XffleDgYGnbtq3LRY1tGpj98MMP5qLGGoTlyJHDXNR41KhRfnxVAAAAAAJBhg625syZk+LyyMhIc80snZKjWbEff/zRB60DAAAAgCwyZgsAAAAAMosMndlCJhYUJIcLFpNL507rHX+3BgAAALjhyGzBJ2IjImVQt6FSv9BNEhNOMRIAAAAEHoItAAAAAPABgi0AAAAA8AGCLfhEWPQ1GTtltPx+6oiEx0T7uzkAAADADUeBDPiGZUmJ08fsO35uDAAAAHDjkdkCAAAAAB8g2AIAAAAAHyDYAgAAAAAfINgCAAAAAB8g2AIAAAAAHyDYgm8EBcmpPPnlYEiI3vF3awAAAIAbjmALPhEbESn9XnxNahQuKTHhEf5uDgAAAHDDcZ0tQIPDmBg5cOCAx4/LnTu3FCpUyCdtAgAAQOZGsIWAd/XSeYmK2icvDx4h4R5m4fLmyi4zpn1CwAUAAIBECLbgE6Ex12Tkp29I39PH5ePYGMnIYq5dFSs4VMo3bCOFS5RO8+MunDkhe5Z/IxcuXCDYAgAAQCIEW/CJoARLyh07+N/bVoJkBrnyF5L8RUr4uxkAAADIIiiQAQAAAAA+QLAFAAAAAD5AsAUAAAAAPkCwBQAAAAA+QLAFAAAAAD5AsAWfuZA9p5wO5hADAABAYOJMGD4RG5lNevQbJzcXKSUx4ZH+bg4AAABwwxFsAQAAAIAPcFHjTOrUqVNy4cIFjx5z4MABiYuP81mbAAAAAPwPwVYmDbQ6dn5Wzl284tHjrl29IkeOHZNaMbHia6Ex1+TVGe/Kv84ck5mxMT5/PgAAACCjIdjKhDSjpYFWxbvbSu4CRdL8uCN7tsmBeVMlLs73wVZQgiWVD+4xt2dZCT5/PgAAACCjIdjKxDTQyl+kRJrXP3/6uE/bAwAAAOB/KJABAAAAAD5AsAUAAAAAPkCwBQAAAAA+wJgt4DrExsSYkvqeyp07txQqVMgnbQIAAEDGQLAFn4kOC78hlQ/95eql8xIVtU9eHjxCwsMjPHps3lzZZca0Twi4AAAAsjCCLfhEbGQ2eXbge7Lg03HySHikZEUx166KFRwq5Ru2kcIlSqf5cRfOnJA9y78xJfwJtgAAALIugi3gOuXKX8ijEvwAAAAIDBTIAAAAAAAfINiCT4TGREv/OZNkztkTEhob4+/mAAAAADcc3QjhE0EJCVJj73Zz+1srwd/NAQAAAG44MlsAAAAA4ANktgA/4PpcAAAAWV9ABVuTJk2St956S44fPy633XabTJw4Ue644w5/NwsB5nquz5U9PETGjhklBQoU8Ph5Y2JiJDw83OPHEeABAACkT8AEW19++aX069dPpkyZInXr1pX33ntPWrRoIbt375bChQv7u3kIIOm9PtfJg3tlyawJ0r33Sx4HaZpJO3zogJQsU1ZCQ0JvSIBHkAYAAAJdwARb48ePl+eee046d+5s7mvQtWDBApk6daq88sor/m4eApCn1+c6f/p4uoI0dWTPNtl3YKqUrffQDQvw0hukkYHzrlOnTpkLaHuK/QkAwPULiGBLT942btwogwYNcswLDg6WZs2ayerVqxOtHx0dbSbb+fPnzd/0nLD4wsWLFyUuLk5OH90vMdeupPlx/5w4LFZCgpw9dkhCPCiNkp7HhUVfE3tvnT12WOIjIzNkOzPj42Kjr3n0vqvYmGvpeuyVi+ckQYIlf8U7JF+htGeA/zlxVDb+8pU836OPhHkQpMXFxMiRI4ekRKnSEuJpBi4iVIYPGST58+f36HFZ2dmzZ2XU62Pl8tU4jx/L/gQAZDR58+bNEP8v2TGBZVmprhtkpWWtTO7o0aNy0003ye+//y716tVzzB8wYIAsX75c1q5d67L+iBEjZOTIkX5oKQAAAIDM4NChQ1KiRMq9lAIis+UpzYDp+C5bgmYhzp413aGCgoISRbYlS5Y0O1u73QCp4ZiBpzhm4AmOF3iKYwaeCvRjxrIs09OsePHiqa4bEMFWwYIFJSQkRE6cOOEyX+8XLVo00foRERFmck9bpkQPtEA82JB+HDPwFMcMPMHxAk9xzMBTgXzM5MmTJ03rBcRFjXWwfe3atWXJkiUu2Sq979ytEAAAAAC8JSAyW0q7BXbq1Enq1Kljrq2lpd8vX77sqE4IAAAAAN4UMMHWE088YUogDxs2zFzUuEaNGrJw4UIpUqTIdW1XuxsOHz48UbdDIDkcM/AUxww8wfECT3HMwFMcM2kXENUIAQAAAOBGC4gxWwAAAABwoxFsAQAAAIAPEGwBAAAAgA8QbAEAAACADxBsXYdJkyZJmTJlJDIyUurWrSvr1q3zd5PgJ2PHjpXbb79dcuXKJYULF5aHH35Ydu/e7bLOtWvXpEePHlKgQAHJmTOntG3bNtGFtg8ePCitW7eW7Nmzm+28/PLLEhcXd4NfDW60N954Q4KCgqRPnz6OeRwvcHfkyBF5+umnzTGRLVs2qVatmmzYsMGxXOtdacXdYsWKmeXNmjWTPXv2uGzj7Nmz0r59e3MR0rx580rXrl3l0qVLfng18LX4+HgZOnSolC1b1hwP5cuXl9GjR5vjxMYxE9h+++03eeCBB6R48eLm/6D58+e7LPfW8bFlyxa56667zPlyyZIlZdy4cRJQtBohPDdnzhwrPDzcmjp1qrV9+3brueees/LmzWudOHHC302DH7Ro0cKaNm2atW3bNmvz5s1Wq1atrFKlSlmXLl1yrNOtWzerZMmS1pIlS6wNGzZYd955p1W/fn3H8ri4OOvWW2+1mjVrZm3atMn68ccfrYIFC1qDBg3y06vCjbBu3TqrTJkyVvXq1a3evXs75nO8wNnZs2et0qVLW88884y1du1aa9++fdbPP/9s7d2717HOG2+8YeXJk8eaP3++9eeff1oPPvigVbZsWevq1auOde677z7rtttus9asWWOtWLHCqlChgvXkk0/66VXBl8aMGWMVKFDA+uGHH6yoqCjrq6++snLmzGm9//77jnU4ZgKb/r8xePBga968eRqBW99++63Lcm8cH+fPn7eKFClitW/f3pwjffHFF1a2bNmsjz76yAoUBFvpdMcdd1g9evRw3I+Pj7eKFy9ujR071q/tQsZw8uRJ88W1fPlyc//cuXNWWFiY+c/OtnPnTrPO6tWrHV96wcHB1vHjxx3rTJ482cqdO7cVHR3th1cBX7t48aJVsWJFa9GiRdbdd9/tCLY4XuBu4MCBVsOGDZNdnpCQYBUtWtR66623HPP0OIqIiDAnN2rHjh3mGFq/fr1jnZ9++skKCgqyjhw54uNXgButdevWVpcuXVzmtWnTxpz0Ko4ZOHMPtrx1fHz44YdWvnz5XP5f0u+zW265xQoUdCNMh5iYGNm4caNJp9qCg4PN/dWrV/u1bcgYzp8/b/7mz5/f/NXjJTY21uWYqVSpkpQqVcpxzOhf7RbkfKHtFi1ayIULF2T79u03/DXA97SboHYDdD4uFMcL3H3//fdSp04deeyxx0yX0Zo1a8q///1vx/KoqCg5fvy4yzGTJ08e08Xd+ZjRbj66HZuur/9/rV279ga/Ivha/fr1ZcmSJfLXX3+Z+3/++aesXLlSWrZsae5zzCAl3jo+Vq9eLY0aNZLw8HCX/6t0qMU///wjgSDU3w3IjE6fPm36Qjuf5Ci9v2vXLr+1CxlDQkKCGXvToEEDufXWW808/cLSLxr9UnI/ZnSZvU5Sx5S9DFnLnDlz5I8//pD169cnWsbxAnf79u2TyZMnS79+/eTVV181x02vXr3McdKpUyfHe57UMeF8zGig5iw0NNT8KMQxk/W88sor5scX/aEmJCTEnLeMGTPGjK9RHDNIibeOj+PHj5txg+7bsJfly5dPsjqCLcAH2Ypt27aZXxCBpBw6dEh69+4tixYtMgOGgbT8iKO/Hr/++uvmvma29HtmypQpJtgC3M2dO1dmzZols2fPlqpVq8rmzZvND4FaDIFjBrhx6EaYDgULFjS/ErlXBtP7RYsW9Vu74H89e/aUH374QZYtWyYlSpRwzNfjQrufnjt3LtljRv8mdUzZy5B1aDfBkydPSq1atcyvgDotX75cJkyYYG7rr34cL3Cm1cCqVKniMq9y5cqmIqXze57S/0v6V487Z1q9UquJccxkPVqdVLNb7dq1M12OO3ToIH379jXVcxXHDFLireOjKP9XEWylh3bbqF27tukL7fyro96vV6+eX9sG/9CxpRpoffvtt7J06dJEKXM9XsLCwlyOGe2vrCdK9jGjf7du3eryxaWZDy2n6n6ShcytadOm5r3WX5rtSbMW2r3Hvs3xAmfaLdn9chI6Fqd06dLmtn7n6ImL8zGjXch03ITzMaMBvAb7Nv2+0v+/dBwGspYrV66YsTPO9Idifb8VxwxS4q3jo169eqbEvI5Ddv6/6pZbbgmILoSGvyt0ZObS71qRZfr06aYay/PPP29KvztXBkPg6N69uymP+uuvv1rHjh1zTFeuXHEp5a3l4JcuXWpKederV89M7qW8mzdvbsrHL1y40CpUqBClvAOEczVCxfEC90sEhIaGmnLee/bssWbNmmVlz57dmjlzpkuZZv1/6LvvvrO2bNliPfTQQ0mWaa5Zs6YpH79y5UpTDZMy3llTp06drJtuuslR+l3Le+vlIQYMGOBYh2MmsGlFXL10iE4aEowfP97cPnDggNeOj3PnzpnS7x06dDCl3/X8Wb+7KP2ONJk4caI5GdLrbWkpeL3GAAKTfkklNem1t2z65fTCCy+YEqj6RfPII4+YgMzZ/v37rZYtW5prUOh/iv3797diY2P98Irg72CL4wXu/vOf/5gAW3/oq1SpkvXxxx+7LNdSzUOHDjUnNrpO06ZNrd27d7usc+bMGXMipNdb0ssEdO7c2ZxwIeu5cOGC+U7R85TIyEirXLly5ppKziW4OWYC27Jly5I8d9FA3ZvHx59//mkuXaHb0B8ANIgLJEH6j7+zawAAAACQ1TBmCwAAAAB8gGALAAAAAHyAYAsAAAAAfIBgCwAAAAB8gGALAAAAAHyAYAsAAAAAfIBgCwAAAAB8gGALAAAAAHyAYAsAgCzqzJkzUrhwYdm/f79kJgsXLpQaNWpIQkKCv5sCANeFYAsAMrlz585JUFBQoilv3rz+bhr8bMyYMfLQQw9JmTJlJDO57777JCwsTGbNmuXvpgDAdSHYAoAs4ptvvpFjx46Z6b333vN3c+BnV65ckU8//VS6du0qmdEzzzwjEyZM8HczAOC6EGwBQCYXFxdn/hYoUECKFi1qpjx58iR7AuueAevTp49jud6fP3++476erLuvo1kS92BOt/vwww+7dANr2LChya5pu+6//375+++/U30tv/76a6oZuq1bt0qTJk0kW7ZsZtvPP/+8XLp0Kdm2/PTTT5IzZ07zV+lje/bs6bLNU6dOSXh4uCxZssTxGvW5//jjD8c6sbGxUqRIETPfuVveypUr5a677jLtKVmypPTq1UsuX76c5v2V1HtiT7osvfvzxx9/lIiICLnzzjtd5m/fvt08Pnfu3JIrVy7TdudtpfYeaNe+UaNGSYkSJcz2tbufts+m+8b5sfnz55c2bdqYLo228ePHS7Vq1SRHjhxmn73wwgsu76F64IEHZMOGDWk6bgAgoyLYAoBMLjo62vzVE9/UWJZlumjZGbB69eolu64GDEOHDjWBiqf0sf369TMnyxrABAcHyyOPPJLmMTi7d+9OMkOn223RooXky5dP1q9fL1999ZUsXrw4UfBkW7FihTz++OMmaGzZsqWZ9+yzz8rs2bMd+03NnDlTbrrpJhOI2fT+xx9/7Lj/7bffmq5tzjQQ0P3Ztm1b2bJli3z55Zcm+EquPUl5//33He+HtlUn+74uS+/+1Ndeu3Ztl3lHjhyRRo0amWNl6dKlsnHjRunSpYsjYLePkZTeA23TO++8I2+//bZ5zfp+PPjgg7Jnzx6X9fR90ccvWLBA1q1bJ+PGjXMs0/Zr1koDv88++8y0ZcCAAS6PL1WqlAlu9XUAQGYV6u8GAACuz9mzZ81fzVKkRrMzGjxp9ktpNic5enJcpUoVlxPxtNLgw9nUqVOlUKFCsmPHDrn11luTfZwdAGmgo1kP9wydBknXrl2TGTNmmOXqgw8+MFmQN99805yc2zQrpfM1MHjiiScc8zXLosHQd999ZwIbNX36dEeGydahQwf597//bR6vz6WBlwYmo0ePdqwzduxYad++vSPzV7FiRRNE3H333TJ58mSJjIxMdV/pa7Rfp2bHlP3+XM/+PHDggBQvXtxl3qRJk8xzzZkzxxE43nzzzYmOkZTeAw2yBg4cKO3atTP3db8vW7bMBGW6fZudabVfl/N23DOlr732mnTr1k0+/PBDl+fS9uvrAIDMiswWAGRymq1QxYoVS3XdCxcuOIKUlBw9etR09dJAIyl6sq1Bmz25FzLQLMeTTz4p5cqVM93V7AINBw8eTPF5tatZaGioZM+ePcnlO3fulNtuu83lNTRo0MBkeDQTY4uKijIZFw3MGjdu7LINDYA0kNKAxQ7Ktm3b5uiyZ9PATR+rgYlmsDSw0eDN2Z9//mkCNed9oc+r7dE2pHV/pSY9+/Pq1auJgr3NmzebboPuGTr3Y0QzT3bg575Mjw3d5870vr43zurXr29eqx6X2lWwf//+Llmvpk2bmoBOfyTQ90Pfex1n5kzb4D4PADITgi0AyOQ0CNAsh46NSY2eKLtnO5IyePBgeeyxx0xgk5SXX37ZnLjbk3Yjc6ZBiWbcNDO0du1aM6mYmJgUn3ffvn1SunRplwxTemj3Nu0uqFknzUa5d7fTZYsWLZLDhw/LtGnTTPdBfV53Oh5MX4NmtTp16pQoSNFxRv/6179c9oUGYBoclS9fPs37KzXp2Z8FCxaUf/75x2VeUgFUUseIBpoacF0P7VKpr1W7AZ4/f15eeuklx5guHTNWvXp1U9RFuzLaGTH316OvWY9tAMisCLYAIJPTMTyaRUiNjvvR7EPNmjVTXE9PkL/++mvTtSulE/kKFSo4JucujJqh0CzTkCFDTPaicuXKiU76k7N8+XKTeUmObkuDGecCFKtWrTKBwS233OKYp+OStIufZue0G5o99smmxRnq1KljghftmqgBWVLuvfdeUzxjypQpJkBzV6tWLRPsOu8Le3LuopnS/kpNevenvs/aNmca4GjwY3cVTIqOhUvuGNGsmgbrus+d6X3tcupMs1n6WrWwR+fOnc2YN6XBlQa/mjXV4h3ajVEDPHealdSMYmrHKwBkZARbAJBJaTcxLfygVfa069rx48cdk2YStNCB3o6Pj5ddu3aZbmhaVc4uFJEcHZOjxRjSkgFLihav0PE6mg3au3evKX6g20uJZjQ0y6Hr6nWh3F+HBjxKM1XaNU6zTNr1T8cKvfjii6YbmvN4LW2D0nFC2g4NVNwLOGjw9MYbb5jta7GJpGiGTQMt3SfOmSrn7oG///67GQOmQao+h44F86RAhi/2p9JjQgtQOAdm2i7tCqjjrbTYhrb3888/N8GcZul03JUGnxocJUezdDpOSzNX+rhXXnnFvPbevXsnChL1PdQs4xdffCGVKlUy8zUA02Bv4sSJJpOpz6/72N2aNWtMIY+UirgAQEZHsAUAmZSe7GrAoMGCls7WsTH2pAUI9KRabx86dEhGjBhhCl3oWJnUqgtq1sW9MpwnNMuk45w0g6HFG/r27StvvfVWio/RgOXRRx81GQ8NfNxfx+23327W07FcP//8s+lepvP0MZrt0SIZydHgUoML9+6EGnzq+DD9m1IhC81uPffcc0ku00yRZuP++usvk5HTLMywYcPSHah6a3/a2TvNvM2dO9cxT4M2DdY0sNIiHlqtULN72j1Su1Xq7Y8++sjs1+RoaXsN9nQMlj6Hln3//vvvTXEQZ82aNTPvoT6PdnH95JNPzHztmqoZRw3Y9PXo+DXNQrrTAE2D6+TG7wFAZhBk2TVeAQCZihZm0Emvi5QczcxooQa7oEJGpa9BA8KkXsu5c+fMtZycr23lDbo9zVZptzkNSrIiLbuumSjNAl7vGKwb6fTp06ZbqGbfypYt6+/mAEC6UfodADIpLXaQWlEM7VoXEhIiGZ2Ob0rutWiQ4M0iCdqFTbu4addCHTOUVQMt1bp1a9NVUCtW6hiqzEIDYS0DT6AFILMjswUACCiaPbvnnntMYQYtBKJd4QAA8AWCLQAAAADwgczTgRsAAAAAMhGCLQAAAADwAYItAAAAAPABgi0AAAAA8AGCLQAAAADwAYItAAAAAPABgi0AAAAA8AGCLQAAAAAQ7/s/ftI6v9F0L9AAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "doc_lengths = [len(doc.split()) for doc in documents]\n",
        "print(f\"\\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ—Ä–ø—É—Å–∞:\")\n",
        "print(f\"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {np.mean(doc_lengths):.1f} —Å–ª–æ–≤\")\n",
        "print(f\"–ú–µ–¥–∏–∞–Ω–Ω–∞—è –¥–ª–∏–Ω–∞: {np.median(doc_lengths):.1f} —Å–ª–æ–≤\")\n",
        "print(f\"–ú–∏–Ω/–ú–∞–∫—Å: {min(doc_lengths)}/{max(doc_lengths)} —Å–ª–æ–≤\")\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª–∏–Ω\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.hist(doc_lengths, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "plt.xlabel('–î–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Å–ª–æ–≤–∞)')\n",
        "plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤')\n",
        "plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ')\n",
        "plt.axvline(np.mean(doc_lengths), color='red', linestyle='--', label=f'–°—Ä–µ–¥–Ω–µ–µ: {np.mean(doc_lengths):.1f}')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "preprocessing"
      },
      "outputs": [],
      "source": [
        "# üßπ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ - —á–∏—Å—Ç–∏–º, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –≥–æ—Ç–æ–≤–∏–º —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ –º–æ–¥–µ–ª–∏\n",
        "\n",
        "class TextPreprocessor:\n",
        "    \"\"\"\n",
        "    –ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞\n",
        "    \n",
        "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:\n",
        "    - –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é (–ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å–ª–æ–≤ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ: \"–±–µ–∂–∞–ª–∏\" ‚Üí \"–±–µ–∂–∞—Ç—å\")\n",
        "    - –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ (—Ç–∏–ø–∞ \"–∏\", \"–≤\", \"–Ω–∞\" - –æ–Ω–∏ —Ä–µ–¥–∫–æ –Ω–µ—Å—É—Ç —Å–º—ã—Å–ª)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_lemma=True, remove_stopwords=True):\n",
        "        \"\"\"\n",
        "        - use_lemma: –ø—Ä–∏–≤–æ–¥–∏—Ç—å —Å–ª–æ–≤–∞ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ? (–ø–æ–ª–µ–∑–Ω–æ –¥–ª—è ML, —á—Ç–æ–±—ã \"–∫–æ—Ç—ã\" –∏ \"–∫–æ—Ç\" —Å—á–∏—Ç–∞–ª–∏—Å—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º)\n",
        "        - remove_stopwords: —É–¥–∞–ª—è—Ç—å –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–µ —Å–ª–æ–≤–∞ –≤—Ä–æ–¥–µ \"—ç—Ç–æ\", \"—Ç–æ—Ç\", \"–±—ã–ª\"?\n",
        "\n",
        "        \"\"\"\n",
        "        self.use_lemma = use_lemma\n",
        "        self.remove_stopwords = remove_stopwords\n",
        "\n",
        "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞, –¥–ª—è \n",
        "        # –æ–ø—Ä–µ–¥–µ–Ω–∏—è —á–∞—Å—Ç–∏ —Ä–µ—á–∏, —Ä–æ–¥–∞, —á–∏—Å–ª–æ –∏ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ\n",
        "        self.morph = pymorphy3.MorphAnalyzer()\n",
        "\n",
        "        #  –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º (—Ç–∏–ø–∞ \"–∏\", \"–≤\", \"—á—Ç–æ\", \"–æ–Ω\")\n",
        "        self.stop_words = set(stopwords.words('russian'))\n",
        "\n",
        "    def preprocess(self, text: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        # –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å—ë –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
        "        text = text.lower()\n",
        "\n",
        "        # –£–¥–∞–ª—è–µ–º HTML-—Ç–µ–≥–∏ –∏ —Å—Å—ã–ª–∫–∏ \n",
        "        text = re.sub(r'<.*?>', ' ', text)      # <b></b> \n",
        "        text = re.sub(r'http\\S+', ' ', text)    # https://\n",
        "        text = re.sub(r'[^–∞-—è—ëa-z0-9\\s]', ' ', text)  # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –ø—Ä–æ–±–µ–ª—ã\n",
        "        text = re.sub(r'\\s+', ' ', text)        # –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª–æ–≤ \n",
        "\n",
        "        # 3Ô∏è‚É£ –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–æ–∫–µ–Ω—ã –ø–æ –ø—Ä–æ–±–µ–ª–∞–º\n",
        "        tokens = text.split()\n",
        "\n",
        "        # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞\n",
        "        if self.remove_stopwords:\n",
        "            tokens = [t for t in tokens if t not in self.stop_words]\n",
        "\n",
        "        # –ü—Ä–∏–≤–æ–¥–∏–º —Å–ª–æ–≤–∞ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ (–ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è)\n",
        "        if self.use_lemma:\n",
        "            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –±–µ—Ä—ë–º –ø–µ—Ä–≤—É—é (—Å–∞–º—É—é –≤–µ—Ä–æ—è—Ç–Ω—É—é) –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é\n",
        "            # –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ—ë –Ω–æ—Ä–º–∞–ª—å–Ω—É—é —Ñ–æ—Ä–º—É \n",
        "            tokens = [self.morph.parse(t)[0].normal_form for t in tokens]\n",
        "\n",
        "        # –£–¥–∞–ª—è–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–º–µ–Ω—å—à–µ 3 —Å–∏–º–≤–æ–ª–æ–≤)\n",
        "        tokens = [t for t in tokens if len(t) > 2]\n",
        "\n",
        "        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≥–æ—Ç–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ —á–∏—Å—Ç—ã—Ö, –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤\n",
        "        return tokens\n",
        "\n",
        "\n",
        "# –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞\n",
        "preprocessor = TextPreprocessor(use_lemma=True, remove_stopwords=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ—Ä–ø—É—Å–∞...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a92c04edb1ec45fa813bc62150b2d508",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9076 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: 59223 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤\n",
            "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: 73.9 —Ç–æ–∫–µ–Ω–æ–≤\n"
          ]
        }
      ],
      "source": [
        "# –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–µ—Å—å –∫–æ—Ä–ø—É—Å\n",
        "print(\"\\n–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ—Ä–ø—É—Å–∞...\")\n",
        "tokenized_docs = [preprocessor.preprocess(doc) for doc in tqdm(documents)]\n",
        "\n",
        "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
        "vocab = set()\n",
        "for doc in tokenized_docs:\n",
        "    vocab.update(doc)\n",
        "\n",
        "print(f\"\\n–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {len(vocab)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤\")\n",
        "print(f\"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {np.mean([len(doc) for doc in tokenized_docs]):.1f} —Ç–æ–∫–µ–Ω–æ–≤\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part2"
      },
      "source": [
        "## –ß–∞—Å—Ç—å 2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è BM25\n",
        "\n",
        "1. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –∫–æ—Ä–ø—É—Å–∞. –ò–Ω–¥–µ–∫—Å –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∞—Å—Ç–æ—Ç—É —Ç–µ—Ä–º–∏–Ω–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ (TF) –∏ –¥–æ–∫—É–º–µ–Ω—Ç–Ω—É—é —á–∞—Å—Ç–æ—Ç—É (DF).\n",
        "2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ–∏—Å–∫–∞ BM25 —Å –Ω—É–ª—è. –§–æ—Ä–º—É–ª–∞ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
        "\n",
        "$score(D, Q) = Œ£ IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D| / avgdl))$\n",
        "\n",
        "3. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞ k1, —á—Ç–æ–±—ã —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7527956ebad44bbf8218a87cd72ed070",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9076 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω: 59223 —Ç–µ—Ä–º–∏–Ω–æ–≤, 9076 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
            "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: 73.86 —Ç–æ–∫–µ–Ω–æ–≤\n",
            "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n",
            "total_terms: 59223\n",
            "total_docs: 9076\n",
            "avg_doc_length: 73.86073159982371\n",
            "avg_posting_length: 9.09006635935363\n",
            "max_posting_length: 4074\n",
            "memory_size_mb: 26.62065887451172\n"
          ]
        }
      ],
      "source": [
        "class InvertedIndex:\n",
        "    \"\"\"–ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è BM25\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.index = defaultdict(list)   # term -> [(doc_id, term_freq, positions)]\n",
        "        self.doc_lengths = {}            # doc_id -> length\n",
        "        self.doc_count = 0               # –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
        "        self.avg_doc_length = 0          # —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞\n",
        "        self.doc_freq = defaultdict(int) # term -> –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Ç–µ—Ä–º–∏–Ω–æ–º\n",
        "\n",
        "    def add_document(self, doc_id: int, tokens: List[str]):\n",
        "        \"\"\"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –∏–Ω–¥–µ–∫—Å\"\"\"\n",
        "        self.doc_count += 1\n",
        "        self.doc_lengths[doc_id] = len(tokens)\n",
        "\n",
        "        # –ü–æ–¥—Å—á—ë—Ç —á–∞—Å—Ç–æ—Ç –∏ –ø–æ–∑–∏—Ü–∏–π —Ç–µ—Ä–º–∏–Ω–æ–≤\n",
        "        term_positions = defaultdict(list)\n",
        "        term_freqs = Counter(tokens)\n",
        "\n",
        "        for pos, term in enumerate(tokens):\n",
        "            term_positions[term].append(pos)\n",
        "\n",
        "        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∏–Ω–¥–µ–∫—Å\n",
        "        for term, freq in term_freqs.items():\n",
        "            self.index[term].append({\n",
        "                'doc_id': doc_id,\n",
        "                'freq': freq,\n",
        "                'positions': term_positions[term]\n",
        "            })\n",
        "            self.doc_freq[term] += 1\n",
        "\n",
        "    def build(self, tokenized_docs: List[List[str]]):\n",
        "        \"\"\"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è –∫–æ—Ä–ø—É—Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\"\"\"\n",
        "        print(\"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...\")\n",
        "\n",
        "        for doc_id, tokens in enumerate(tqdm(tokenized_docs)):\n",
        "            self.add_document(doc_id, tokens)\n",
        "\n",
        "        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –¥–æ–∫—É–º–µ–Ω—Ç–∞\n",
        "        self.avg_doc_length = sum(self.doc_lengths.values()) / len(self.doc_lengths)\n",
        "\n",
        "        print(f\"–ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω: {len(self.index)} —Ç–µ—Ä–º–∏–Ω–æ–≤, {self.doc_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\")\n",
        "        print(f\"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {self.avg_doc_length:.2f} —Ç–æ–∫–µ–Ω–æ–≤\")\n",
        "\n",
        "    def get_posting_list(self, term: str) -> List[Dict]:\n",
        "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ posting list –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞\"\"\"\n",
        "        return self.index.get(term, [])\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        \"\"\"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞\"\"\"\n",
        "        posting_lengths = [len(postings) for postings in self.index.values()]\n",
        "        return {\n",
        "            'total_terms': len(self.index),\n",
        "            'total_docs': self.doc_count,\n",
        "            'avg_doc_length': self.avg_doc_length,\n",
        "            'avg_posting_length': np.mean(posting_lengths) if posting_lengths else 0,\n",
        "            'max_posting_length': max(posting_lengths) if posting_lengths else 0,\n",
        "            'memory_size_mb': self._estimate_memory() / (1024 * 1024)\n",
        "        }\n",
        "\n",
        "    def _estimate_memory(self) -> int:\n",
        "        \"\"\"–û—Ü–µ–Ω–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –≤ –±–∞–π—Ç–∞—Ö\"\"\"\n",
        "        # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞\n",
        "        size = 0\n",
        "        for term, postings in self.index.items():\n",
        "            size += len(term) * 2  # Unicode —Å–∏–º–≤–æ–ª—ã\n",
        "            size += len(postings) * 50  # –ü—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä posting\n",
        "        return size\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
        "index = InvertedIndex()\n",
        "index.build(tokenized_docs)\n",
        "\n",
        "stats = index.get_stats()\n",
        "print(\"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
        "for key, value in stats.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BM25:\n",
        "    \"\"\"–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ BM25\"\"\"\n",
        "\n",
        "    def __init__(self, index: InvertedIndex, k1: float = 1.2, b: float = 0.75):\n",
        "        \"\"\"\n",
        "        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
        "        - k1: –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–∞—Å—ã—â–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã —Ç–µ—Ä–º–∏–Ω–∞ (–æ–±—ã—á–Ω–æ 1.2-2.0)\n",
        "        - b: –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª–∏–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–æ–±—ã—á–Ω–æ 0.75)\n",
        "        \"\"\"\n",
        "        self.index = index\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.idf_cache = {}  # –ö—ç—à –¥–ª—è IDF –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "\n",
        "    def _compute_idf(self, term: str) -> float:\n",
        "        \"\"\"–í—ã—á–∏—Å–ª–µ–Ω–∏–µ IDF –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞\"\"\"\n",
        "        if term in self.idf_cache:\n",
        "            return self.idf_cache[term]\n",
        "\n",
        "        N = self.index.doc_count\n",
        "        df = self.index.doc_freq.get(term, 0)\n",
        "\n",
        "        if df == 0:\n",
        "            idf = 0\n",
        "        else:\n",
        "            # –§–æ—Ä–º—É–ª–∞ IDF –¥–ª—è BM25\n",
        "            idf = math.log((N - df + 0.5) / (df + 0.5) + 1)\n",
        "\n",
        "        self.idf_cache[term] = idf\n",
        "        return idf\n",
        "\n",
        "    def score(self, query_tokens: List[str], doc_id: int) -> float:\n",
        "        \"\"\"–í—ã—á–∏—Å–ª–µ–Ω–∏–µ BM25 —Å–∫–æ—Ä–∞ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞\"\"\"\n",
        "        score = 0.0\n",
        "        doc_length = self.index.doc_lengths.get(doc_id, 0)\n",
        "\n",
        "        if doc_length == 0:\n",
        "            return 0.0\n",
        "\n",
        "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª–∏–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞\n",
        "        norm_factor = 1 - self.b + self.b * (doc_length / self.index.avg_doc_length)\n",
        "\n",
        "        # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—ã —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ\n",
        "        doc_term_freqs = defaultdict(int)\n",
        "        for term in query_tokens:\n",
        "            postings = self.index.get_posting_list(term)\n",
        "            for posting in postings:\n",
        "                if posting['doc_id'] == doc_id:\n",
        "                    doc_term_freqs[term] = posting['freq']\n",
        "                    break\n",
        "\n",
        "        # –í—ã—á–∏—Å–ª—è–µ–º —Å–∫–æ—Ä\n",
        "        for term in set(query_tokens):  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∑–∞–ø—Ä–æ—Å–∞\n",
        "            if term not in doc_term_freqs:\n",
        "                continue\n",
        "\n",
        "            idf = self._compute_idf(term)\n",
        "            tf = doc_term_freqs[term]\n",
        "\n",
        "            # –§–æ—Ä–º—É–ª–∞ BM25\n",
        "            numerator = tf * (self.k1 + 1)\n",
        "            denominator = tf + self.k1 * norm_factor\n",
        "\n",
        "            score += idf * (numerator / denominator)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def search(self, query: str, top_k: int = 10) -> List[Tuple[int, float]]:\n",
        "        \"\"\"–ü–æ–∏—Å–∫ top-k –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞\"\"\"\n",
        "        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞\n",
        "        query_tokens = preprocessor.preprocess(query)\n",
        "\n",
        "        if not query_tokens:\n",
        "            return []\n",
        "\n",
        "        # –ù–∞—Ö–æ–¥–∏–º –¥–æ–∫—É–º–µ–Ω—Ç—ã-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã (—Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–µ—Ä–º–∏–Ω)\n",
        "        candidate_docs = set()\n",
        "        for term in query_tokens:\n",
        "            postings = self.index.get_posting_list(term)\n",
        "            for posting in postings:\n",
        "                candidate_docs.add(posting['doc_id'])\n",
        "\n",
        "        # –í—ã—á–∏—Å–ª—è–µ–º —Å–∫–æ—Ä—ã –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\n",
        "        scores = []\n",
        "        for doc_id in candidate_docs:\n",
        "            score = self.score(query_tokens, doc_id)\n",
        "            if score > 0:\n",
        "                scores.append((doc_id, score))\n",
        "\n",
        "        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–æ—Ä—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º top-k\n",
        "        scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        return scores[:top_k]\n",
        "\n",
        "# –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä BM25\n",
        "bm25 = BM25(index, k1=1.2, b=0.75)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ BM25 –ø–æ–∏—Å–∫–∞ –Ω–∞ k1=0.8:\n",
            "==================================================\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 3752 (score: 9.215): –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ –æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ ‚Äî –≤ –≤–∏–¥–µ –∏—Å—Ö–æ...\n",
            "  Doc 6183 (score: 8.960): –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ—Ä–æ—Ç, –ø—Ä–æ–∏–∑–æ—à–µ–¥—à–∏–π —Å 60-—Ö –≥–æ–¥–æ–≤ XVIII –¥–æ –ø–µ—Ä–≤–æ–π —á–µ—Ç–≤–µ—Ä—Ç–∏ XIX –≤–µ–∫–æÃÅ–≤ –≤ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω...\n",
            "  Doc 5764 (score: 7.383): –ü–µ—Ä–µ–≤–æÃÅ–¥ ‚Äî –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Å–º—ã—Å–ª–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ–¥–Ω–æ–º —è–∑—ã–∫–µ (–∏—Å—Ö–æ–¥–Ω–æ–º —è–∑—ã–∫–µ [–ò–Ø]) –∏ —Å–æ–∑–¥–∞–Ω...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 7764 (score: 16.253): –û–±–ª–∞—Å—Ç–∏ –º–æ–∑–≥–∞, –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ, –∫–æ–≥–¥–∞ —á–µ–ª–æ–≤–µ–∫ –∑–∞–Ω—è—Ç –≤–æ–ø—Ä–æ—Å–∞–º–∏ –º–æ—Ä–∞–ª–∏, –±—ã–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω—ã –∫–∞—á–µ—Å—Ç...\n",
            "  Doc 6086 (score: 6.005): –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Ä—ã–Ω–∫–∏ (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Å–µ—Ç–∏) ‚Äî —Å–µ—Ç–µ–≤—ã–µ —Ä—ã–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –¥–≤–µ –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –≤–æ–∑...\n",
            "  Doc 7568 (score: 5.871): –í–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Å–µ—Ç–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —è–≤–ª—è—é—Ç—Å—è –≥–æ–º–æ–≥–µ–Ω–Ω—ã–º–∏, —Ç–æ –µ—Å—Ç—å –æ–Ω–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏. –ù–∞–ø—Ä...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã BM25'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 4025 (score: 13.496): –î–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å[1]. –†–∞–±–æ...\n",
            "  Doc 4211 (score: 12.944): –ü–æ–ª–µ–∑–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –µ—é —Å—Ç—Ä–∞–Ω–∏—Ü. –•–æ—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏...\n",
            "  Doc 906 (score: 12.521): –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –≤ –∞—Ä–∞–±—Å–∫–æ–º –∏ –º—É...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: 'Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 1453 (score: 9.361): –í —Ç–µ–æ—Ä–∏–∏ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–∞–∫ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏, –∏–∑—É—á–∞—é—Ç –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é, –∞–Ω...\n",
            "  Doc 7576 (score: 8.534): –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–∏—Å—Ç–µ–º—ã —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è) –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è –∫–æ–Ω—Ç—Ä–æ–ª—å (—Å–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è). –§—É–Ω–∫—Ü–∏–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏...\n",
            "  Doc 1437 (score: 8.374): –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞ –ø—Ä–µ–ø–æ–¥–∞—ë—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –∞–≤...\n",
            "\n",
            "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ BM25 –ø–æ–∏—Å–∫–∞ –Ω–∞ k1=1.0:\n",
            "==================================================\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 3752 (score: 9.698): –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ –æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ ‚Äî –≤ –≤–∏–¥–µ –∏—Å—Ö–æ...\n",
            "  Doc 6183 (score: 9.383): –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ—Ä–æ—Ç, –ø—Ä–æ–∏–∑–æ—à–µ–¥—à–∏–π —Å 60-—Ö –≥–æ–¥–æ–≤ XVIII –¥–æ –ø–µ—Ä–≤–æ–π —á–µ—Ç–≤–µ—Ä—Ç–∏ XIX –≤–µ–∫–æÃÅ–≤ –≤ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω...\n",
            "  Doc 5442 (score: 7.747): –¶–∏—Ñ—Ä–æ–≤—ã–µ –æ–±—É—á–∞—é—â–∏–µ –∏–≥—Ä—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –∏–≥—Ä –∏ –Ω–µ –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∞ –∏–≥—Ä–∞—Ö —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 7764 (score: 16.936): –û–±–ª–∞—Å—Ç–∏ –º–æ–∑–≥–∞, –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ, –∫–æ–≥–¥–∞ —á–µ–ª–æ–≤–µ–∫ –∑–∞–Ω—è—Ç –≤–æ–ø—Ä–æ—Å–∞–º–∏ –º–æ—Ä–∞–ª–∏, –±—ã–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω—ã –∫–∞—á–µ—Å—Ç...\n",
            "  Doc 6086 (score: 6.523): –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Ä—ã–Ω–∫–∏ (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Å–µ—Ç–∏) ‚Äî —Å–µ—Ç–µ–≤—ã–µ —Ä—ã–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –¥–≤–µ –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –≤–æ–∑...\n",
            "  Doc 7568 (score: 6.346): –í–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Å–µ—Ç–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —è–≤–ª—è—é—Ç—Å—è –≥–æ–º–æ–≥–µ–Ω–Ω—ã–º–∏, —Ç–æ –µ—Å—Ç—å –æ–Ω–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏. –ù–∞–ø—Ä...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã BM25'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 4025 (score: 14.591): –î–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å[1]. –†–∞–±–æ...\n",
            "  Doc 4211 (score: 13.871): –ü–æ–ª–µ–∑–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –µ—é —Å—Ç—Ä–∞–Ω–∏—Ü. –•–æ—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏...\n",
            "  Doc 906 (score: 13.328): –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –≤ –∞—Ä–∞–±—Å–∫–æ–º –∏ –º—É...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: 'Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 1453 (score: 9.982): –í —Ç–µ–æ—Ä–∏–∏ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–∞–∫ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏, –∏–∑—É—á–∞—é—Ç –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é, –∞–Ω...\n",
            "  Doc 7576 (score: 8.942): –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–∏—Å—Ç–µ–º—ã —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è) –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è –∫–æ–Ω—Ç—Ä–æ–ª—å (—Å–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è). –§—É–Ω–∫—Ü–∏–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏...\n",
            "  Doc 1437 (score: 8.745): –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞ –ø—Ä–µ–ø–æ–¥–∞—ë—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –∞–≤...\n",
            "\n",
            "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ BM25 –ø–æ–∏—Å–∫–∞ –Ω–∞ k1=1.2:\n",
            "==================================================\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 3752 (score: 10.133): –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ –æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ ‚Äî –≤ –≤–∏–¥–µ –∏—Å—Ö–æ...\n",
            "  Doc 6183 (score: 9.759): –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ—Ä–æ—Ç, –ø—Ä–æ–∏–∑–æ—à–µ–¥—à–∏–π —Å 60-—Ö –≥–æ–¥–æ–≤ XVIII –¥–æ –ø–µ—Ä–≤–æ–π —á–µ—Ç–≤–µ—Ä—Ç–∏ XIX –≤–µ–∫–æÃÅ–≤ –≤ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω...\n",
            "  Doc 5442 (score: 8.225): –¶–∏—Ñ—Ä–æ–≤—ã–µ –æ–±—É—á–∞—é—â–∏–µ –∏–≥—Ä—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –∏–≥—Ä –∏ –Ω–µ –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∞ –∏–≥—Ä–∞—Ö —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 7764 (score: 17.544): –û–±–ª–∞—Å—Ç–∏ –º–æ–∑–≥–∞, –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ, –∫–æ–≥–¥–∞ —á–µ–ª–æ–≤–µ–∫ –∑–∞–Ω—è—Ç –≤–æ–ø—Ä–æ—Å–∞–º–∏ –º–æ—Ä–∞–ª–∏, –±—ã–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω—ã –∫–∞—á–µ—Å—Ç...\n",
            "  Doc 6086 (score: 7.018): –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Ä—ã–Ω–∫–∏ (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Å–µ—Ç–∏) ‚Äî —Å–µ—Ç–µ–≤—ã–µ —Ä—ã–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –¥–≤–µ –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –≤–æ–∑...\n",
            "  Doc 7568 (score: 6.796): –í–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Å–µ—Ç–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —è–≤–ª—è—é—Ç—Å—è –≥–æ–º–æ–≥–µ–Ω–Ω—ã–º–∏, —Ç–æ –µ—Å—Ç—å –æ–Ω–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏. –ù–∞–ø—Ä...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã BM25'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 4025 (score: 15.628): –î–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å[1]. –†–∞–±–æ...\n",
            "  Doc 4211 (score: 14.736): –ü–æ–ª–µ–∑–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –µ—é —Å—Ç—Ä–∞–Ω–∏—Ü. –•–æ—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏...\n",
            "  Doc 906 (score: 14.070): –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –≤ –∞—Ä–∞–±—Å–∫–æ–º –∏ –º—É...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: 'Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 1453 (score: 10.554): –í —Ç–µ–æ—Ä–∏–∏ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–∞–∫ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏, –∏–∑—É—á–∞—é—Ç –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é, –∞–Ω...\n",
            "  Doc 7576 (score: 9.307): –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–∏—Å—Ç–µ–º—ã —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è) –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è –∫–æ–Ω—Ç—Ä–æ–ª—å (—Å–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è). –§—É–Ω–∫—Ü–∏–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏...\n",
            "  Doc 1437 (score: 9.074): –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞ –ø—Ä–µ–ø–æ–¥–∞—ë—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –∞–≤...\n",
            "\n",
            "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ BM25 –ø–æ–∏—Å–∫–∞ –Ω–∞ k1=1.5:\n",
            "==================================================\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 3752 (score: 10.710): –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ –æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ ‚Äî –≤ –≤–∏–¥–µ –∏—Å—Ö–æ...\n",
            "  Doc 6183 (score: 10.253): –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ—Ä–æ—Ç, –ø—Ä–æ–∏–∑–æ—à–µ–¥—à–∏–π —Å 60-—Ö –≥–æ–¥–æ–≤ XVIII –¥–æ –ø–µ—Ä–≤–æ–π —á–µ—Ç–≤–µ—Ä—Ç–∏ XIX –≤–µ–∫–æÃÅ–≤ –≤ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω...\n",
            "  Doc 5442 (score: 8.883): –¶–∏—Ñ—Ä–æ–≤—ã–µ –æ–±—É—á–∞—é—â–∏–µ –∏–≥—Ä—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –∏–≥—Ä –∏ –Ω–µ –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∞ –∏–≥—Ä–∞—Ö —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 7764 (score: 18.344): –û–±–ª–∞—Å—Ç–∏ –º–æ–∑–≥–∞, –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ, –∫–æ–≥–¥–∞ —á–µ–ª–æ–≤–µ–∫ –∑–∞–Ω—è—Ç –≤–æ–ø—Ä–æ—Å–∞–º–∏ –º–æ—Ä–∞–ª–∏, –±—ã–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω—ã –∫–∞—á–µ—Å—Ç...\n",
            "  Doc 6086 (score: 7.721): –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Ä—ã–Ω–∫–∏ (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Å–µ—Ç–∏) ‚Äî —Å–µ—Ç–µ–≤—ã–µ —Ä—ã–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –¥–≤–µ –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –≤–æ–∑...\n",
            "  Doc 7568 (score: 7.427): –í–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Å–µ—Ç–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —è–≤–ª—è—é—Ç—Å—è –≥–æ–º–æ–≥–µ–Ω–Ω—ã–º–∏, —Ç–æ –µ—Å—Ç—å –æ–Ω–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏. –ù–∞–ø—Ä...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã BM25'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 4025 (score: 17.088): –î–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å[1]. –†–∞–±–æ...\n",
            "  Doc 4211 (score: 15.929): –ü–æ–ª–µ–∑–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –µ—é —Å—Ç—Ä–∞–Ω–∏—Ü. –•–æ—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏...\n",
            "  Doc 906 (score: 15.078): –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –≤ –∞—Ä–∞–±—Å–∫–æ–º –∏ –º—É...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: 'Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 1453 (score: 11.334): –í —Ç–µ–æ—Ä–∏–∏ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–∞–∫ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏, –∏–∑—É—á–∞—é—Ç –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é, –∞–Ω...\n",
            "  Doc 7576 (score: 9.785): –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–∏—Å—Ç–µ–º—ã —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è) –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è –∫–æ–Ω—Ç—Ä–æ–ª—å (—Å–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è). –§—É–Ω–∫—Ü–∏–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏...\n",
            "  Doc 1437 (score: 9.504): –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞ –ø—Ä–µ–ø–æ–¥–∞—ë—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –∞–≤...\n",
            "\n",
            "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ BM25 –ø–æ–∏—Å–∫–∞ –Ω–∞ k1=1.8:\n",
            "==================================================\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 3752 (score: 11.211): –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ –æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ ‚Äî –≤ –≤–∏–¥–µ –∏—Å—Ö–æ...\n",
            "  Doc 6183 (score: 10.677): –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ—Ä–æ—Ç, –ø—Ä–æ–∏–∑–æ—à–µ–¥—à–∏–π —Å 60-—Ö –≥–æ–¥–æ–≤ XVIII –¥–æ –ø–µ—Ä–≤–æ–π —á–µ—Ç–≤–µ—Ä—Ç–∏ XIX –≤–µ–∫–æÃÅ–≤ –≤ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω...\n",
            "  Doc 5442 (score: 9.479): –¶–∏—Ñ—Ä–æ–≤—ã–µ –æ–±—É—á–∞—é—â–∏–µ –∏–≥—Ä—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –∏–≥—Ä –∏ –Ω–µ –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∞ –∏–≥—Ä–∞—Ö —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 7764 (score: 19.033): –û–±–ª–∞—Å—Ç–∏ –º–æ–∑–≥–∞, –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ, –∫–æ–≥–¥–∞ —á–µ–ª–æ–≤–µ–∫ –∑–∞–Ω—è—Ç –≤–æ–ø—Ä–æ—Å–∞–º–∏ –º–æ—Ä–∞–ª–∏, –±—ã–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω—ã –∫–∞—á–µ—Å—Ç...\n",
            "  Doc 6086 (score: 8.380): –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Ä—ã–Ω–∫–∏ (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Å–µ—Ç–∏) ‚Äî —Å–µ—Ç–µ–≤—ã–µ —Ä—ã–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –¥–≤–µ –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –≤–æ–∑...\n",
            "  Doc 7568 (score: 8.012): –í–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Å–µ—Ç–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —è–≤–ª—è—é—Ç—Å—è –≥–æ–º–æ–≥–µ–Ω–Ω—ã–º–∏, —Ç–æ –µ—Å—Ç—å –æ–Ω–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏. –ù–∞–ø—Ä...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã BM25'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 4025 (score: 18.442): –î–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å[1]. –†–∞–±–æ...\n",
            "  Doc 4211 (score: 17.012): –ü–æ–ª–µ–∑–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –µ—é —Å—Ç—Ä–∞–Ω–∏—Ü. –•–æ—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏...\n",
            "  Doc 906 (score: 15.977): –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –≤ –∞—Ä–∞–±—Å–∫–æ–º –∏ –º—É...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: 'Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 1453 (score: 12.033): –í —Ç–µ–æ—Ä–∏–∏ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–∞–∫ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏, –∏–∑—É—á–∞—é—Ç –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é, –∞–Ω...\n",
            "  Doc 7576 (score: 10.197): –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–∏—Å—Ç–µ–º—ã —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è) –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è –∫–æ–Ω—Ç—Ä–æ–ª—å (—Å–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è). –§—É–Ω–∫—Ü–∏–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏...\n",
            "  Doc 1437 (score: 9.870): –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞ –ø—Ä–µ–ø–æ–¥–∞—ë—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –∞–≤...\n",
            "\n",
            "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ BM25 –ø–æ–∏—Å–∫–∞ –Ω–∞ k1=2.0:\n",
            "==================================================\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 3752 (score: 11.510): –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ –æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ ‚Äî –≤ –≤–∏–¥–µ –∏—Å—Ö–æ...\n",
            "  Doc 6183 (score: 10.928): –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ—Ä–æ—Ç, –ø—Ä–æ–∏–∑–æ—à–µ–¥—à–∏–π —Å 60-—Ö –≥–æ–¥–æ–≤ XVIII –¥–æ –ø–µ—Ä–≤–æ–π —á–µ—Ç–≤–µ—Ä—Ç–∏ XIX –≤–µ–∫–æÃÅ–≤ –≤ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω...\n",
            "  Doc 5442 (score: 9.846): –¶–∏—Ñ—Ä–æ–≤—ã–µ –æ–±—É—á–∞—é—â–∏–µ –∏–≥—Ä—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –∏–≥—Ä –∏ –Ω–µ –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∞ –∏–≥—Ä–∞—Ö —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 7764 (score: 19.442): –û–±–ª–∞—Å—Ç–∏ –º–æ–∑–≥–∞, –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ, –∫–æ–≥–¥–∞ —á–µ–ª–æ–≤–µ–∫ –∑–∞–Ω—è—Ç –≤–æ–ø—Ä–æ—Å–∞–º–∏ –º–æ—Ä–∞–ª–∏, –±—ã–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω—ã –∫–∞—á–µ—Å—Ç...\n",
            "  Doc 6086 (score: 8.798): –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Ä—ã–Ω–∫–∏ (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Å–µ—Ç–∏) ‚Äî —Å–µ—Ç–µ–≤—ã–µ —Ä—ã–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –¥–≤–µ –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –≤–æ–∑...\n",
            "  Doc 7568 (score: 8.378): –í–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Å–µ—Ç–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —è–≤–ª—è—é—Ç—Å—è –≥–æ–º–æ–≥–µ–Ω–Ω—ã–º–∏, —Ç–æ –µ—Å—Ç—å –æ–Ω–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏. –ù–∞–ø—Ä...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã BM25'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 4025 (score: 19.292): –î–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å[1]. –†–∞–±–æ...\n",
            "  Doc 4211 (score: 17.680): –ü–æ–ª–µ–∑–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –µ—é —Å—Ç—Ä–∞–Ω–∏—Ü. –•–æ—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏...\n",
            "  Doc 906 (score: 16.525): –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –≤ –∞—Ä–∞–±—Å–∫–æ–º –∏ –º—É...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: 'Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 1453 (score: 12.460): –í —Ç–µ–æ—Ä–∏–∏ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–∞–∫ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏, –∏–∑—É—á–∞—é—Ç –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é, –∞–Ω...\n",
            "  Doc 7576 (score: 10.441): –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–∏—Å—Ç–µ–º—ã —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è) –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è –∫–æ–Ω—Ç—Ä–æ–ª—å (—Å–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è). –§—É–Ω–∫—Ü–∏–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏...\n",
            "  Doc 1437 (score: 10.087): –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞ –ø—Ä–µ–ø–æ–¥–∞—ë—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –∞–≤...\n",
            "\n",
            "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ BM25 –ø–æ–∏—Å–∫–∞ –Ω–∞ k1=2.5:\n",
            "==================================================\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 3752 (score: 12.159): –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ –æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ ‚Äî –≤ –≤–∏–¥–µ –∏—Å—Ö–æ...\n",
            "  Doc 6183 (score: 11.468): –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ—Ä–æ—Ç, –ø—Ä–æ–∏–∑–æ—à–µ–¥—à–∏–π —Å 60-—Ö –≥–æ–¥–æ–≤ XVIII –¥–æ –ø–µ—Ä–≤–æ–π —á–µ—Ç–≤–µ—Ä—Ç–∏ XIX –≤–µ–∫–æÃÅ–≤ –≤ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω...\n",
            "  Doc 5442 (score: 10.672): –¶–∏—Ñ—Ä–æ–≤—ã–µ –æ–±—É—á–∞—é—â–∏–µ –∏–≥—Ä—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –∏–≥—Ä –∏ –Ω–µ –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∞ –∏–≥—Ä–∞—Ö —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 7764 (score: 20.327): –û–±–ª–∞—Å—Ç–∏ –º–æ–∑–≥–∞, –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ, –∫–æ–≥–¥–∞ —á–µ–ª–æ–≤–µ–∫ –∑–∞–Ω—è—Ç –≤–æ–ø—Ä–æ—Å–∞–º–∏ –º–æ—Ä–∞–ª–∏, –±—ã–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω—ã –∫–∞—á–µ—Å—Ç...\n",
            "  Doc 6086 (score: 9.771): –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Ä—ã–Ω–∫–∏ (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Å–µ—Ç–∏) ‚Äî —Å–µ—Ç–µ–≤—ã–µ —Ä—ã–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –¥–≤–µ –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –≤–æ–∑...\n",
            "  Doc 7568 (score: 9.222): –í–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Å–µ—Ç–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —è–≤–ª—è—é—Ç—Å—è –≥–æ–º–æ–≥–µ–Ω–Ω—ã–º–∏, —Ç–æ –µ—Å—Ç—å –æ–Ω–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏. –ù–∞–ø—Ä...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: '–ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã BM25'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 4025 (score: 21.252): –î–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å[1]. –†–∞–±–æ...\n",
            "  Doc 4211 (score: 19.190): –ü–æ–ª–µ–∑–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –µ—é —Å—Ç—Ä–∞–Ω–∏—Ü. –•–æ—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏...\n",
            "  Doc 906 (score: 17.743): –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –≤ –∞—Ä–∞–±—Å–∫–æ–º –∏ –º—É...\n",
            "\n",
            "–ó–∞–ø—Ä–æ—Å: 'Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'\n",
            "–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n",
            "  Doc 1453 (score: 13.411): –í —Ç–µ–æ—Ä–∏–∏ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–∞–∫ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏, –∏–∑—É—á–∞—é—Ç –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é, –∞–Ω...\n",
            "  Doc 7576 (score: 10.966): –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–∏—Å—Ç–µ–º—ã —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è) –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è –∫–æ–Ω—Ç—Ä–æ–ª—å (—Å–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è). –§—É–Ω–∫—Ü–∏–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏...\n",
            "  Doc 1437 (score: 10.549): –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞ –ø—Ä–µ–ø–æ–¥–∞—ë—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –∞–≤...\n"
          ]
        }
      ],
      "source": [
        "# –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑—É—è BM25\n",
        "k1_candidates = [0.8, 1.0, 1.2, 1.5, 1.8, 2.0, 2.5]\n",
        "\n",
        "\n",
        "def bm25_search_optimiser(k1):\n",
        "\n",
        "    bm25 = BM25(index, k1=k1, b=0.75)\n",
        "\n",
        "    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã\n",
        "    test_queries = [\n",
        "        \"–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\",\n",
        "        \"–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏\",\n",
        "        \"–ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã BM25\",\n",
        "        \"Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ\"\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ BM25 –ø–æ–∏—Å–∫–∞ –Ω–∞ k1={k1}:\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for query in test_queries:\n",
        "        results = bm25.search(query, top_k=3)\n",
        "        print(f\"\\n–ó–∞–ø—Ä–æ—Å: '{query}'\")\n",
        "        print(\"–¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\")\n",
        "\n",
        "        for doc_id, score in results:\n",
        "            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞—á–∞–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞\n",
        "            doc_preview = documents[doc_id][:100] + \"...\"\n",
        "            print(f\"  Doc {doc_id} (score: {score:.3f}): {doc_preview}\")\n",
        "            \n",
        "\n",
        "for i in k1_candidates:\n",
        "    bm25_search_optimiser(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –ù–∞–±–ª—é–¥–µ–Ω–∏—è:\n",
        "\n",
        "## –°–∫–æ—Ä—ã –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ —Ä–∞—Å—Ç—É—Ç —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º k1.\n",
        "\n",
        "### –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ \"–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏\":\n",
        "\n",
        "> k1=0.8 : Doc 7764: 16.253\n",
        "\n",
        "> k1=2.5 : Doc 7764: 20.327\n",
        "\n",
        "* –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ç–æ–ø-3) –æ—Å—Ç–∞—ë—Ç—Å—è —Å—Ç–∞–±–∏–ª—å–Ω—ã–º.\n",
        "\n",
        "* –î–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Ç–æ–ø-3 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ k1 - –º–µ–Ω—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Å–∫–æ—Ä—ã.\n",
        "\n",
        "* –≠—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –æ —Ç–æ–º, —á—Ç–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —É—Å—Ç–æ–π—á–∏–≤–∞ –∫ k1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part3"
      },
      "source": [
        "---\n",
        "---\n",
        "## –ß–∞—Å—Ç—å 3. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫\n",
        "\n",
        "1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å sentence-transformers –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π (—ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤) –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.\n",
        "2. –°–æ–∑–¥–∞–π—Ç–µ –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π —Å –ø–æ–º–æ—â—å—é faiss-cpu.\n",
        "3. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –ø–æ –∑–∞–ø—Ä–æ—Å—É –Ω–∞—Ö–æ–¥–∏—Ç top-k –Ω–∞–∏–±–æ–ª–µ–µ –±–ª–∏–∑–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã\n",
        "test_queries = [\n",
        "    \"–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\",\n",
        "    \"–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏\",\n",
        "    \"–ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã BM25\",\n",
        "    \"Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VectorSearch:\n",
        "    \"\"\"–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Sentence Transformers –∏ FAISS\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = 'BAAI/bge-m3'):\n",
        "        print(f\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name}...\")\n",
        "        self.model = SentenceTransformer(model_name, device='mps')\n",
        "        self.index = None\n",
        "        self.documents = None\n",
        "        self.doc_embeddings = None\n",
        "\n",
        "    def build_index(self, documents: List[str]):\n",
        "        \"\"\"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞\"\"\"\n",
        "        print(\"–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...\")\n",
        "        self.documents = documents\n",
        "\n",
        "        # –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
        "        self.doc_embeddings = self.model.encode(\n",
        "            documents,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
        "        faiss.normalize_L2(self.doc_embeddings)\n",
        "\n",
        "        # –°–æ–∑–¥–∞—ë–º FAISS –∏–Ω–¥–µ–∫—Å\n",
        "        dimension = self.doc_embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatIP(dimension)  # Inner Product = Cosine similarity –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "        self.index.add(self.doc_embeddings)\n",
        "\n",
        "        print(f\"–í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω: {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {dimension}\")\n",
        "\n",
        "    def search(self, query: str, top_k: int = 10) -> List[Tuple[int, float]]:\n",
        "        \"\"\"–ü–æ–∏—Å–∫ top-k –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\"\"\"\n",
        "        # –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞\n",
        "        query_embedding = self.model.encode([query], convert_to_numpy=True)\n",
        "        faiss.normalize_L2(query_embedding)\n",
        "\n",
        "        # –ü–æ–∏—Å–∫ –≤ –∏–Ω–¥–µ–∫—Å–µ\n",
        "        scores, indices = self.index.search(query_embedding, top_k)\n",
        "\n",
        "        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ (doc_id, score)\n",
        "        results = [(int(idx), float(score)) for idx, score in zip(indices[0], scores[0])]\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ BAAI/bge-m3...\n",
            "–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b64ae8227e934f28a827020ba956e87b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/284 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "Invalid buffer size: 8.87 GiB",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# –°–æ–∑–¥–∞—ë–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫\u001b[39;00m\n\u001b[32m      2\u001b[39m vector_search = VectorSearch()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mvector_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVectorSearch.build_index\u001b[39m\u001b[34m(self, documents)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mself\u001b[39m.documents = documents\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28mself\u001b[39m.doc_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞\u001b[39;00m\n\u001b[32m     24\u001b[39m faiss.normalize_L2(\u001b[38;5;28mself\u001b[39m.doc_embeddings)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1051\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1048\u001b[39m features.update(extra_features)\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1052\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1053\u001b[39m         out_features = copy.deepcopy(out_features)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1132\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1126\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1127\u001b[39m         module_kwargs = {\n\u001b[32m   1128\u001b[39m             key: value\n\u001b[32m   1129\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1130\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1131\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1132\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:234\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[32m    228\u001b[39m trans_features = {\n\u001b[32m    229\u001b[39m     key: value\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items()\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minputs_embeds\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    232\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    236\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:852\u001b[39m, in \u001b[36mXLMRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    845\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    846\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    847\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    848\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    849\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    850\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    865\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    866\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:606\u001b[39m, in \u001b[36mXLMRobertaEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    602\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    604\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    617\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:513\u001b[39m, in \u001b[36mXLMRobertaLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    503\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    511\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    512\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m513\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    522\u001b[39m     outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:440\u001b[39m, in \u001b[36mXLMRobertaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    431\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    438\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    439\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m    450\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/nlp_env/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:363\u001b[39m, in \u001b[36mXLMRobertaSdpaSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[32m    358\u001b[39m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[32m    360\u001b[39m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[32m    361\u001b[39m is_causal = \u001b[38;5;28mself\u001b[39m.is_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len > \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    373\u001b[39m attn_output = attn_output.reshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m.all_head_size)\n",
            "\u001b[31mRuntimeError\u001b[39m: Invalid buffer size: 8.87 GiB"
          ]
        }
      ],
      "source": [
        "# –°–æ–∑–¥–∞—ë–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫\n",
        "vector_search = VectorSearch()\n",
        "vector_search.build_index(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vector_search"
      },
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç–∏—Ä—É–µ–º\n",
        "print(\"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:\")\n",
        "for query in test_queries:\n",
        "    results = vector_search.search(query, top_k=3)\n",
        "    print(f\"–ó–∞–ø—Ä–æ—Å: '{query}'\")\n",
        "    for doc_id, score in results:\n",
        "        doc = documents[doc_id]\n",
        "        print(f\"  [{score:.3f}] {doc.title[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part4"
      },
      "source": [
        "___\n",
        "___\n",
        "\n",
        "## –ß–∞—Å—Ç—å 4. –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫\n",
        "\n",
        "1. –†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç BM25 –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.\n",
        "2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ö–∞–Ω–∏–∑–º –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è —Å–∫–æ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ Œ±:\n",
        "hybrid_score = Œ± * bm25_score + (1 - Œ±) * vector_score\n",
        "3. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ Œ± –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hybrid_search"
      },
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫\n",
        "print(\"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:\")\n",
        "for query in test_queries:\n",
        "    results = hybrid_search.search(query, top_k=3)\n",
        "    print(f\"–ó–∞–ø—Ä–æ—Å: '{query}'\")\n",
        "    for doc_id, score in results:\n",
        "        doc = documents[doc_id]\n",
        "        print(f\"  [{score:.3f}] {doc.title[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part6"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## –ß–∞—Å—Ç—å 5. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
        "\n",
        "1. –í—ã–±–µ—Ä–∏—Ç–µ –∏ **–æ–±–æ—Å–Ω—É–π—Ç–µ –º–µ—Ç—Ä–∏–∫—É** –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–∞—à–µ–π –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, MRR, MAP@k –∏–ª–∏ NDCG@k). **–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–¥—É–º–∞–π—Ç–µ –æ —Ç–æ–º, –∫–∞–∫–æ–π —Ç–æ–ø-–∫ –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –∏—Å—Ö–æ–¥—è –∏–∑ –¥–∞–Ω–Ω—ã—Ö**.\n",
        "2. **–°–æ–∑–¥–∞–π—Ç–µ –Ω–µ–±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏**, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.  \n",
        "3. **–°—Ä–∞–≤–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ** –≤—Å–µ—Ö —Ç—Ä–µ—Ö —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ (BM25, –≤–µ–∫—Ç–æ—Ä–Ω—ã–π, –≥–∏–±—Ä–∏–¥–Ω—ã–π) –Ω–∞ –≤–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "metrics"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
