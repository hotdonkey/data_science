{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrqlVxgXfbbS"
      },
      "source": [
        "# **Семинар 1. Технический мониторинг с помощью Prometheus и Grafana**\n",
        "\n",
        "---\n",
        "\n",
        "## **Цель семинара**\n",
        "\n",
        "Познакомиться с инструментами мониторинга инфраструктуры ML-сервисов и научиться собирать, хранить и визуализировать метрики с помощью **Prometheus** и **Grafana**.\n",
        "\n",
        "После занятия студент сможет:\n",
        "\n",
        "- добавлять системные и пользовательские метрики в код ML-сервиса;  \n",
        "- настраивать сбор данных Prometheus;  \n",
        "- визуализировать метрики в Grafana;  \n",
        "- задавать пороговые алерты и анализировать состояние модели.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-GrQJFKfbn2",
        "outputId": "a6e43d64-6280-41ce-a78b-9a470b0b02ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.118.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.12/dist-packages (0.23.1)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (3.11)\n",
            "/bin/bash: line 1: docker: command not found\n",
            "/bin/bash: line 1: docker: command not found\n"
          ]
        }
      ],
      "source": [
        "# 1. Подготовка окружения\n",
        "\n",
        "!pip install fastapi uvicorn prometheus_client\n",
        "!docker pull prom/prometheus\n",
        "!docker pull grafana/grafana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92jmU_zcfycK"
      },
      "source": [
        "## **2. Создание простого ML-сервиса с метриками**\n",
        "\n",
        "Создадим FastAPI-приложение, которое будет:\n",
        "\n",
        "- считать количество запросов к эндпоинту `/predict`;\n",
        "- измерять задержку (latency);\n",
        "- подсчитывать количество ошибок;\n",
        "- экспортировать метрики на порт `8001` для Prometheus.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyJkOt6efyxK"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from prometheus_client import Counter, Histogram, start_http_server\n",
        "import time, os, random\n",
        "\n",
        "app = FastAPI(title=\"ML Monitoring Demo\")\n",
        "\n",
        "# --- метрики Prometheus ---\n",
        "REQUEST_COUNT = Counter(\"predict_requests_total\", \"Total number of prediction requests\")\n",
        "LATENCY = Histogram(\"prediction_latency_seconds\", \"Model prediction latency (s)\")\n",
        "ERROR_COUNT = Counter(\"predict_errors_total\", \"Total number of prediction errors\")\n",
        "\n",
        "# --- версия модели ---\n",
        "VERSION = os.getenv(\"MODEL_VERSION\", \"v1.0.0\")\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\"status\": \"ok\", \"version\": VERSION}\n",
        "\n",
        "@app.get(\"/predict\")\n",
        "def predict():\n",
        "    start = time.time()\n",
        "    REQUEST_COUNT.inc()\n",
        "    try:\n",
        "        # имитируем задержку и случайную ошибку\n",
        "        if random.random() < 0.1:\n",
        "            raise ValueError(\"Random failure!\")\n",
        "        time.sleep(random.uniform(0.05, 0.3))\n",
        "        LATENCY.observe(time.time() - start)\n",
        "        return {\"prediction\": \"class_A\", \"version\": VERSION}\n",
        "    except Exception as e:\n",
        "        ERROR_COUNT.inc()\n",
        "        LATENCY.observe(time.time() - start)\n",
        "        return {\"error\": str(e), \"version\": VERSION}\n",
        "\n",
        "# сервер метрик Prometheus (порт 8001)\n",
        "start_http_server(8001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLQS5slKf502"
      },
      "outputs": [],
      "source": [
        "# запуск приложения локально\n",
        "uvicorn main:app --host 0.0.0.0 --port 8000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-XAQdLlf8xf"
      },
      "source": [
        "После запуска:\n",
        "\n",
        "- ML-сервис доступен по адресу: http://localhost:8000  \n",
        "- метрики — на http://localhost:8001/metrics  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHm5LIatf_CE"
      },
      "source": [
        "## **3. Настройка Prometheus**\n",
        "\n",
        "Создаём файл `prometheus.yml` в корне проекта:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXOpG9bWgBHJ"
      },
      "source": [
        "global:\n",
        "  scrape_interval: 5s\n",
        "\n",
        "scrape_configs:\n",
        "  - job_name: \"ml_service\"\n",
        "    static_configs:\n",
        "      - targets: [\"host.docker.internal:8001\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYhlSxdOf6vr"
      },
      "outputs": [],
      "source": [
        "# запуск Prometheus\n",
        "docker run -d --name prometheus \\\n",
        "  -p 9090:9090 \\\n",
        "  -v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml \\\n",
        "  prom/prometheus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHkXnmjigFaO"
      },
      "source": [
        "Prometheus UI: http://localhost:9090  \n",
        "Попробуем выполнить запрос:\n",
        "predict_requests_total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO2b9GpHgNXV"
      },
      "source": [
        "## **4. Настройка Grafana**\n",
        "\n",
        "Grafana собирает данные из Prometheus и визуализирует их.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZDmxpwogDlv"
      },
      "outputs": [],
      "source": [
        "# запуск Grafana\n",
        "docker run -d -p 3000:3000 --name=grafana grafana/grafana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZLTsBADgQwf"
      },
      "source": [
        "1. Откройте http://localhost:3000  \n",
        "   Вход: **admin / admin**\n",
        "\n",
        "2. Добавьте источник данных:\n",
        "   - Type: Prometheus  \n",
        "   - URL: `http://host.docker.internal:9090`\n",
        "\n",
        "3. Создайте Dashboard с панелями:\n",
        "   - `rate(predict_requests_total[1m])` — частота запросов;  \n",
        "   - `histogram_quantile(0.95, sum(rate(prediction_latency_seconds_bucket[1m])) by (le))` — 95-й перцентиль задержки;  \n",
        "   - `increase(predict_errors_total[5m])` — число ошибок за 5 минут.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCiNjvqAgTdK"
      },
      "source": [
        "## **5. Настройка алертов**\n",
        "\n",
        "Создайте alert в Grafana:\n",
        "\n",
        "**Условие:**  \n",
        "`avg(prediction_latency_seconds_sum / prediction_latency_seconds_count) > 1`\n",
        "\n",
        "**Действие:**  \n",
        "Slack / Email-уведомление или визуальный триггер.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTB3ELSBgVX4"
      },
      "source": [
        "## **6. Интерактивные вопросы**\n",
        "\n",
        "**Почему нельзя использовать print-логи вместо Prometheus-метрик?**  \n",
        "Логи — неструктурированные данные, их трудно агрегировать; метрики позволяют отслеживать состояние сервиса в реальном времени.\n",
        "\n",
        "**Какие метрики особенно важны для ML-моделей?**  \n",
        "Latency, error rate, CPU/RAM usage, количество запросов, drift accuracy, confidence score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqJ00oG-gX6q"
      },
      "source": [
        "## **7. Мини-практикум**\n",
        "\n",
        "1. Добавьте новую метрику `MODEL_CONFIDENCE` — Histogram распределения уверенности модели.  \n",
        "2. Выведите среднюю уверенность на дашборде Grafana.  \n",
        "3. Настройте alert, если средняя уверенность < 0.6.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c7jLlcYgZfx"
      },
      "source": [
        "## **8. Итог семинара**\n",
        "\n",
        "После занятия вы получили:\n",
        "\n",
        "- ML-сервис с эндпоинтами `/predict` и `/metrics`;  \n",
        "- настроенный Prometheus для сбора метрик;  \n",
        "- Grafana-дашборд с графиками и алертами.  \n",
        "\n",
        "Мониторинг — ключевой элемент MLOps:  \n",
        "он позволяет вовремя обнаруживать деградацию модели, перегрузку сервера и ошибки деплоя.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNWArKKWgQ_F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
