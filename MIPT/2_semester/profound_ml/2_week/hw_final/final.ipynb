{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDIwm2-sjVU1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw_mlAWbErMa"
      },
      "source": [
        "# Задача\n",
        "\n",
        "В данном задании вам предлагается решить задачу извлечения аргументов (объектов, аспектов и предикатов) из предложения. Такая модель должна быть обучена на предложениях, где слова или фразы имеют разметку последовательности – каждому слову соответствует его тег.\n",
        "\n",
        "> **Пример.** Postgres is easier to install and maintain than Oracle.\n",
        ">\n",
        "> [Postgres **OBJECT**] is [easier **PREDICATE**] to [install **ASPECT**] and [maintain **ASPECT**] than [Oracle **OBJECT**].\n",
        ">\n",
        "> Сущности могут состоять из нескольких слов: Advil works better for body aches and pains than Motrin.\n",
        ">\n",
        "> [Advil **OBJECT**] works [better **PREDICATE**] for [body aches **ASPECT**] and [pains **ASPECT**] than [Motrin **OBJECT**].\n",
        "\n",
        "Данные состоят из сравнительных предложений (т.е. предложений, содержащих сравнение двух или более объектов). В предложениях содержится следующая информация:\n",
        "\n",
        "- *Объекты* – объекты, которые сравниваются\n",
        "- *Аспекты* – характеристики, по которым сравниваются объекты\n",
        "- *Сказуемое* – слова или фразы, которые реализуют сравнение (обычно сравнительные прилагательные или наречия)\n",
        "\n",
        "В наборе данных используется схема BIO:\n",
        "\n",
        "- Первое слово сущности помечается тегом `B-<entity-type>` (начало сущности).\n",
        "- Второе и последующие слова сущности помечаются тегом `I-<entity-type>` (внутри сущности).\n",
        "- Слова, которые не являются частью сущности, помечаются тегом `O` (вне сущности).\n",
        "\n",
        "Поэтому в нашем наборе данных используются следующие метки:\n",
        "- O\n",
        "- B-Object\n",
        "- I-Object\n",
        "- B-Aspect\n",
        "- I-Aspect\n",
        "- B-Predicate\n",
        "- I-Predicate\n",
        "\n",
        "**Ваша задача** – присвоить одну из таких меток каждому токену данных путем обучения модели на основе LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePN09DRHjVU3"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Alc6_gXUjVU5"
      },
      "outputs": [],
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Paddoz90jVU6"
      },
      "outputs": [],
      "source": [
        "def read_dataset(filename, splitter=\"\\t\"):\n",
        "    data = []\n",
        "    sentence = []\n",
        "    tags = []\n",
        "    with open(filename) as f:\n",
        "        for line in f:\n",
        "            if not line.isspace():\n",
        "                word, tag = line.split(splitter)\n",
        "                sentence.append(word)\n",
        "                tags.append(tag.strip())\n",
        "            else:\n",
        "                data.append((sentence, tags))\n",
        "                sentence = []\n",
        "                tags = []\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpWefqBUjbNO"
      },
      "outputs": [],
      "source": [
        "!gdown 1wkfEJCUKF5nbZ6lV6HlRtcEaNkLrLo7y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMurdqezdznJ"
      },
      "outputs": [],
      "source": [
        "!gdown 10kS7glt0sLoh6UIn0RtpREW-zcU_zIay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdSkztDBjVU7"
      },
      "outputs": [],
      "source": [
        "training_data = read_dataset(\"train.tsv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuWSZoeDjVU8"
      },
      "outputs": [],
      "source": [
        "training_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu8zGCcZjVU9"
      },
      "outputs": [],
      "source": [
        "test_data = read_dataset(\"test_no_answer.tsv\", splitter=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqFdS2ioeMYf"
      },
      "outputs": [],
      "source": [
        "test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ0n6C0UjVU-"
      },
      "outputs": [],
      "source": [
        "word_to_ix = {}\n",
        "\n",
        "# For each words-list (sentence) and tags-list in each tuple of training_data\n",
        "for sent, tags in training_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:  # word has not been assigned an index yet\n",
        "            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n",
        "\n",
        "for sent, tags in test_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:  # word has not been assigned an index yet\n",
        "            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n",
        "\n",
        "tag_to_ix = {\n",
        "    \"O\": 0,\n",
        "    \"B-Object\": 1,\n",
        "    \"I-Object\": 2,\n",
        "    \"B-Aspect\": 3,\n",
        "    \"I-Aspect\": 4,\n",
        "    \"B-Predicate\": 5,\n",
        "    \"I-Predicate\": 6\n",
        "}  # Assign each tag with a unique index\n",
        "\n",
        "idx_to_tag = dict(map(reversed, tag_to_ix.items()))\n",
        "\n",
        "EMBEDDING_DIM = 32\n",
        "HIDDEN_DIM = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27DtLuc4jVU_"
      },
      "source": [
        "# Tagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gpSyN6CIOAL"
      },
      "source": [
        "Опишите архитектуру нейросети. Все необходимые слои описаны в комментариях. В качестве выхода из модели используйте логистический softmax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t9SrivpjVVA"
      },
      "outputs": [],
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        torch.manual_seed(5)\n",
        "        torch.cuda.manual_seed(5)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # The Embedding layer with size of the dictionary vocab_size\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        tag_space = self.hidden2tag(lstm_out)\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CixPZbLqjVVA"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EriYw-bCjVVA"
      },
      "outputs": [],
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQMTfQWfjVVB"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(10)):  # normally you would NOT do 300 epochs, it is toy data\n",
        "    for sentence, tags in training_data:\n",
        "        model.zero_grad()\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "        tag_scores = model(sentence_in.unsqueeze(0))\n",
        "        loss = loss_function(tag_scores.view(1, -1), targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgp0MceljVVC"
      },
      "source": [
        "# Inference\n",
        "Предскажите метки для слов из первого предложения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxYeVqwdjVVC"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(test_data[0][0], word_to_ix)\n",
        "    tag_scores = model(inputs.unsqueeze(0))\n",
        "    predicted_tags = [idx_to_tag[int(i)] for i in tag_scores.argmax(dim=-1)]\n",
        "    print(list(zip(test_data[0][0], predicted_tags)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL3VSMUX9Kqs"
      },
      "source": [
        "Предскажите метки для слов из десятого предложения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LarAmbAa9GPF"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(test_data[9][0], word_to_ix)\n",
        "    tag_scores = model(inputs.unsqueeze(0))\n",
        "    predicted_tags = [idx_to_tag[int(i)] for i in tag_scores.argmax(dim=-1)]\n",
        "    print(list(zip(test_data[9][0], predicted_tags)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUH0T10j9MWQ"
      },
      "source": [
        "Предскажите метки для слов из сотого предложения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfLiquQb9Csk"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(test_data[99][0], word_to_ix)\n",
        "    tag_scores = model(inputs.unsqueeze(0))\n",
        "    predicted_tags = [idx_to_tag[int(i)] for i in tag_scores.argmax(dim=-1)]\n",
        "    print(list(zip(test_data[99][0], predicted_tags)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPIv233-jPtj"
      },
      "source": [
        "Сохраните результаты предсказания на тестовом наборе (`test_data`) в файл, запустив код ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz7osROSjVVD"
      },
      "outputs": [],
      "source": [
        "with open(\"out_test.tsv\", \"w\") as w:\n",
        "    with torch.no_grad():\n",
        "        for sentence in tqdm(test_data):\n",
        "            inputs = prepare_sequence(sentence[0], word_to_ix)\n",
        "            tag_scores = model(inputs.unsqueeze(0))\n",
        "            tags = [idx_to_tag[int(i)] for i in tag_scores.argmax(dim=-1)]\n",
        "            for i, y in zip(sentence[0], tags):\n",
        "                w.write(f\"{i}\\t{y}\\n\")\n",
        "            w.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KHcgCVgH1B5"
      },
      "source": [
        "Файл `test.tsv` содержит разметку тестовых данных. Сравните файлы построчно, запустив код ниже. Сколько суммарно меток было предсказано верно (то есть сколько строк совпало)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXOaAmKLjft5"
      },
      "outputs": [],
      "source": [
        "!gdown 1mUtlDtb7naXDi1U8x73UdyncnHv1BOjd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rnMnOHjjVVD"
      },
      "outputs": [],
      "source": [
        "points = 0\n",
        "with open(\"test.tsv\", \"r\") as f_eval, open(\"out_test.tsv\", \"r\") as f:\n",
        "  for line_eval, line in zip(f_eval.readlines(), f.readlines()):\n",
        "    if line_eval == line: points += 1\n",
        "print(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51qugWgyk5pL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dlenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
