{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f164e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTS = [\n",
    "    {\"name\": \"Teaser\",             \"start\": 0.00,   \"end\": 0.06,   \"ratio\": 0.05},\n",
    "    {\"name\": \"Act 1 / –ó–∞–≤—è–∑–∫–∞\",    \"start\": 0.06,   \"end\": 0.25,   \"ratio\": 0.07},\n",
    "    {\"name\": \"Act 2 / –†–∞–∑–≤–∏—Ç–∏–µ\",   \"start\": 0.25,   \"end\": 0.50,   \"ratio\": 0.23},\n",
    "    {\"name\": \"Act 3 / –ü–æ–¥—ä—ë–º\",     \"start\": 0.50,   \"end\": 0.75,   \"ratio\": 0.20},\n",
    "    {\"name\": \"Climax / –ö—É–ª—å–º–∏–Ω–∞—Ü–∏—è\",\"start\": 0.75,  \"end\": 0.875,  \"ratio\": 0.20},\n",
    "    {\"name\": \"Tag / –†–∞–∑–≤—è–∑–∫–∞\",     \"start\": 0.875,  \"end\": 1.00,   \"ratio\": 0.25},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4070c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIM_START = 0\n",
    "TRIM_END = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dbab48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ß—Ç–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ...\n",
      "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 3697 —Å–µ–∫\n",
      "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ—ç–Ω–µ—Ä–≥–∏–∏...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/pkm5cmhs3p782092gzybbqrw0000gn/T/ipykernel_1538/2962972768.py:28: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, _ = librosa.load(video_path, sr=sr)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ê–Ω–∞–ª–∏–∑ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏...\n",
      "–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏...\n",
      "–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏...\n",
      "–°–æ—Ö—Ä–∞–Ω—ë–Ω: activity_plot.png\n",
      "üéØ –ü–æ–∏—Å–∫ –ø–∏–∫–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏...\n",
      "1. 45s ‚Üí 51s\n",
      "2. 178s ‚Üí 184s\n",
      "3. 456s ‚Üí 462s\n",
      "4. 643s ‚Üí 649s\n",
      "5. 1175s ‚Üí 1181s\n",
      "6. 1189s ‚Üí 1195s\n",
      "7. 1252s ‚Üí 1258s\n",
      "8. 1336s ‚Üí 1342s\n",
      "9. 1342s ‚Üí 1348s\n",
      "10. 1348s ‚Üí 1354s\n",
      "11. 1363s ‚Üí 1369s\n",
      "12. 1383s ‚Üí 1389s\n",
      "13. 1452s ‚Üí 1458s\n",
      "14. 2456s ‚Üí 2462s\n",
      "15. 2470s ‚Üí 2476s\n",
      "16. 2479s ‚Üí 2485s\n",
      "17. 2487s ‚Üí 2493s\n",
      "18. 2498s ‚Üí 2504s\n",
      "19. 2710s ‚Üí 2716s\n",
      "20. 2724s ‚Üí 2730s\n",
      "21. 2734s ‚Üí 2740s\n",
      "22. 2791s ‚Üí 2797s\n",
      "23. 2822s ‚Üí 2828s\n",
      "24. 2838s ‚Üí 2844s\n",
      "25. 2911s ‚Üí 2917s\n",
      "26. 2930s ‚Üí 2936s\n",
      "27. 2965s ‚Üí 2971s\n",
      "28. 2985s ‚Üí 2991s\n",
      "29. 2991s ‚Üí 2997s\n",
      "30. 3254s ‚Üí 3260s\n",
      "31. 3367s ‚Üí 3373s\n",
      "32. 3375s ‚Üí 3381s\n",
      "33. 3400s ‚Üí 3406s\n",
      "34. 3410s ‚Üí 3416s\n",
      "35. 3434s ‚Üí 3440s\n",
      "36. 3464s ‚Üí 3470s\n",
      "37. 3517s ‚Üí 3523s\n",
      "38. 3602s ‚Üí 3608s\n",
      "39. 3608s ‚Üí 3614s\n",
      "–í—ã—Ä–µ–∑–∫–∞ –∫–ª–∏–ø–æ–≤...\n",
      "–°–∫–ª–µ–π–∫–∞ recap...\n",
      "–ì–æ—Ç–æ–≤–æ! –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª: recap_action.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import librosa\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "VIDEO_PATH = \"episode.mkv\"\n",
    "OUTPUT_RECAP = \"recap_action.mp4\"\n",
    "CLIP_LENGTH = 6\n",
    "TOP_K = 40\n",
    "FRAME_STEP = 5\n",
    "AUDIO_SAMPLE_RATE = 22050\n",
    "PLOT_PATH = \"activity_plot.png\"\n",
    "\n",
    "def get_duration(video_path):\n",
    "    result = subprocess.run([\n",
    "        \"ffprobe\", \"-v\", \"error\",\n",
    "        \"-show_entries\", \"format=duration\",\n",
    "        \"-of\", \"json\", video_path\n",
    "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    return int(float(json.loads(result.stdout)[\"format\"][\"duration\"]))\n",
    "\n",
    "def extract_audio_activity(video_path, sr=AUDIO_SAMPLE_RATE):\n",
    "    y, _ = librosa.load(video_path, sr=sr)\n",
    "    rms = librosa.feature.rms(y=y)[0]\n",
    "    onset = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)[0]\n",
    "\n",
    "    # –≤—ã—Ä–æ–≤–Ω—è—Ç—å –¥–ª–∏–Ω—É\n",
    "    min_len = min(len(rms), len(onset), len(flatness))\n",
    "    rms = normalize(rms[:min_len])\n",
    "    onset = normalize(onset[:min_len])\n",
    "    flatness = normalize(flatness[:min_len])\n",
    "\n",
    "    # —Å–º–µ—à–∏–≤–∞–µ–º: RMS (–æ–±—â–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å) + Onset (–≤—Å–ø–ª–µ—Å–∫–∏) + Flatness (—à—É–º)\n",
    "    return 0.5 * rms + 0.35 * onset + 0.15 * flatness\n",
    "\n",
    "def extract_visual_diffs(video_path, every_n_frames=FRAME_STEP):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    prev_gray = None\n",
    "    diffs = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % every_n_frames == 0:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            if prev_gray is not None:\n",
    "                diff = cv2.absdiff(prev_gray, gray)\n",
    "                score = diff.mean()\n",
    "                diffs.append(score)\n",
    "            prev_gray = gray\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return diffs\n",
    "\n",
    "def normalize(x):\n",
    "    x = np.array(x)\n",
    "    return (x - x.min()) / (x.max() - x.min() + 1e-6)\n",
    "\n",
    "def combine_activity(audio_rms, visual_diffs):\n",
    "    min_len = min(len(audio_rms), len(visual_diffs))\n",
    "    a = normalize(audio_rms[:min_len])\n",
    "    v = normalize(visual_diffs[:min_len])\n",
    "    return 0.75 * a + 0.25 * v\n",
    "\n",
    "def build_activity_per_second(activity, fps, duration):\n",
    "    per_second = np.zeros(int(duration))\n",
    "    for i, val in enumerate(activity):\n",
    "        sec = int(i / fps)\n",
    "        if sec < len(per_second):\n",
    "            per_second[sec] += val\n",
    "    return per_second\n",
    "\n",
    "def find_top_intervals_by_acts(activity, duration, clip_len=10, top_k=10, acts=None):\n",
    "    seconds = build_activity_per_second(activity, fps=1, duration=duration)\n",
    "    selected = []\n",
    "    used = set()\n",
    "\n",
    "    trim_start = TRIM_START\n",
    "    trim_end = TRIM_END\n",
    "    duration_eff = duration - trim_end\n",
    "\n",
    "    for act in acts:\n",
    "        s_start = int(duration * act[\"start\"])\n",
    "        s_end = int(duration * act[\"end\"])\n",
    "\n",
    "        s_start = max(s_start, trim_start)\n",
    "        s_end = min(s_end, duration_eff)\n",
    "\n",
    "        act_top_k = max(1, int(top_k * act[\"ratio\"]))\n",
    "        act_range = range(s_start, s_end)\n",
    "        sorted_indices = sorted(act_range, key=lambda i: seconds[i], reverse=True)\n",
    "\n",
    "        count = 0\n",
    "        for sec in sorted_indices:\n",
    "            if count >= act_top_k:\n",
    "                break\n",
    "            if any(abs(sec - s) < clip_len for s in used):\n",
    "                continue\n",
    "            used.add(sec)\n",
    "            selected.append((max(0, sec - clip_len // 2), min(duration, sec + clip_len // 2)))\n",
    "            count += 1\n",
    "\n",
    "    return sorted(selected)\n",
    "\n",
    "def extract_visual_diffs(video_path, every_n_frames=10):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    prev_gray = None\n",
    "    diffs = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % every_n_frames == 0:\n",
    "            frame = cv2.resize(frame, (320, 180))\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            if prev_gray is not None:\n",
    "                flow = cv2.calcOpticalFlowFarneback(\n",
    "                    prev_gray, gray, None,\n",
    "                    0.5, 3, 15, 3, 5, 1.2, 0\n",
    "                )\n",
    "                mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "                motion_score = np.mean(mag)\n",
    "                diffs.append(motion_score)\n",
    "\n",
    "            prev_gray = gray\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return diffs\n",
    "\n",
    "def concat_clips_ffmpeg(clip_paths, output_path):\n",
    "    list_path = \"concat_activity.txt\"\n",
    "    with open(list_path, \"w\") as f:\n",
    "        for p in clip_paths:\n",
    "            f.write(f\"file '{os.path.abspath(p)}'\\n\")\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", list_path,\n",
    "        \"-c\", \"copy\", \"-y\", output_path\n",
    "    ]\n",
    "    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "def extract_clips_ffmpeg(video_path, intervals, output_dir=\"clips_activity\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    paths = []\n",
    "\n",
    "    for idx, (start, end) in enumerate(intervals):\n",
    "        out_path = os.path.join(output_dir, f\"clip_{idx:02}.mp4\")\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-ss\", str(start), \"-i\", video_path,\n",
    "            \"-t\", str(end - start),\n",
    "            \"-c:v\", \"libx264\", \"-preset\", \"fast\",\n",
    "            \"-c:a\", \"aac\", \"-b:a\", \"128k\", \"-y\", out_path\n",
    "        ]\n",
    "        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        paths.append(out_path)\n",
    "\n",
    "    return paths\n",
    "\n",
    "def plot_activity_graph(activity, save_path):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(activity, label=\"Combined Audio+Visual Activity\")\n",
    "    plt.xlabel(\"Time Frame Index\")\n",
    "    plt.ylabel(\"Normalized Intensity\")\n",
    "    plt.title(\"Activity Over Time\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def detect_music(y, sr):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)[0]\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    return flatness.mean() > 0.15 and tempo > 60 and zcr.mean() > 0.05\n",
    "\n",
    "def detect_speech(y, sr):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    return np.std(delta) < 20\n",
    "\n",
    "def detect_static_visuals(video_path, duration=420, step=2, threshold=3.0):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    prev_frame = None\n",
    "    static_score = []\n",
    "\n",
    "    for i in range(0, duration, step):\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, i * 1000)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (160, 90))\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if prev_frame is not None:\n",
    "            diff = np.abs(gray.astype(np.float32) - prev_frame.astype(np.float32)).mean()\n",
    "            static_score.append(diff)\n",
    "        prev_frame = gray\n",
    "\n",
    "    cap.release()\n",
    "    return np.mean(static_score) < threshold\n",
    "\n",
    "def main():\n",
    "    print(\"–ß—Ç–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ...\")\n",
    "    duration = get_duration(VIDEO_PATH)\n",
    "    print(f\"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration} —Å–µ–∫\")\n",
    "\n",
    "    print(\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ—ç–Ω–µ—Ä–≥–∏–∏...\")\n",
    "    audio = extract_audio_activity(VIDEO_PATH)\n",
    "\n",
    "    print(\"–ê–Ω–∞–ª–∏–∑ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏...\")\n",
    "    visual = extract_visual_diffs(VIDEO_PATH)\n",
    "\n",
    "    print(\"–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏...\")\n",
    "    activity = combine_activity(audio, visual)\n",
    "\n",
    "    print(\"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏...\")\n",
    "    plot_activity_graph(activity, PLOT_PATH)\n",
    "    print(f\"–°–æ—Ö—Ä–∞–Ω—ë–Ω: {PLOT_PATH}\")\n",
    "\n",
    "    print(\"–ü–æ–∏—Å–∫ –ø–∏–∫–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏...\")\n",
    "    intervals = find_top_intervals_by_acts(\n",
    "        activity,\n",
    "        duration,\n",
    "        clip_len=CLIP_LENGTH,\n",
    "        top_k=TOP_K,\n",
    "        acts=ACTS\n",
    "    )\n",
    "\n",
    "    for i, (start, end) in enumerate(intervals):\n",
    "        print(f\"{i+1}. {start}s ‚Üí {end}s\")\n",
    "\n",
    "    print(\"–í—ã—Ä–µ–∑–∫–∞ –∫–ª–∏–ø–æ–≤...\")\n",
    "    clips = extract_clips_ffmpeg(VIDEO_PATH, intervals)\n",
    "\n",
    "    print(\"–°–∫–ª–µ–π–∫–∞ recap...\")\n",
    "    concat_clips_ffmpeg(clips, OUTPUT_RECAP)\n",
    "\n",
    "    print(f\"–ì–æ—Ç–æ–≤–æ! –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª: {OUTPUT_RECAP}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12de5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
