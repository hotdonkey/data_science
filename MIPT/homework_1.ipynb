{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала посчитаем частоту использования отдельных слов в произведении.\n",
    "def word_counter(word):\n",
    "\n",
    "    def read_data():\n",
    "        data = open(\"./data/war_peace_processed.txt\", \"rt\").read()\n",
    "        return data.split(\"\\n\")\n",
    "\n",
    "    raw_data = read_data()\n",
    "\n",
    "    word_counts = {k: 0 for k in set(raw_data)}\n",
    "\n",
    "    for i in raw_data:\n",
    "        word_counts[i] += 1\n",
    "\n",
    "    return word_counts[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = open('./data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1289\n"
     ]
    }
   ],
   "source": [
    "# Задание 1 (External resource)\n",
    "def read_data():\n",
    "    data = open('./data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "raw_data = read_data()\n",
    "\n",
    "word_counts = {k: 0 for k in set(raw_data)}\n",
    "\n",
    "for i in raw_data:\n",
    "    word_counts[i] += 1\n",
    "\n",
    "target_word = 'князь'\n",
    "print(word_counts[target_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672514619883041\n"
     ]
    }
   ],
   "source": [
    "# Задание 2 (External resource)\n",
    "counter = 1\n",
    "for i, k in enumerate(raw_data):\n",
    "    if k == '[new chapter]':\n",
    "        counter += 1\n",
    "        raw_data[i] = f'[new chapter]_{counter}'\n",
    "        \n",
    "chapters = [\"[new chapter]_1\"]\n",
    "for i in raw_data:\n",
    "    if i.startswith(\"[n\"):\n",
    "        chapters.append(i)\n",
    "\n",
    "chapter_dict = {k:0 for k in chapters}\n",
    "\n",
    "chapter_counter = 1\n",
    "target_word = \"человек\"\n",
    "for i in raw_data:\n",
    "    if not i.startswith(\"[n\") and i == target_word:\n",
    "        chapter_dict[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "    elif i.startswith(\"[n\"):\n",
    "        chapter_counter += 1\n",
    "        \n",
    "chapter_dict_processed = {k: 1 if v > 0 else v for k, v in chapter_dict.items()}\n",
    "\n",
    "result = sum(chapter_dict_processed.values()) / len(chapters)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0029433406916850625\n"
     ]
    }
   ],
   "source": [
    "# Задание 3 (External resource)\n",
    "raw_data = read_data()\n",
    "\n",
    "target_word = \"человек\"\n",
    "# Тут по человечески нумеруем\n",
    "target_chapter = 16\n",
    "\n",
    "counter = 1\n",
    "for i, k in enumerate(raw_data):\n",
    "    if k == '[new chapter]':\n",
    "        counter += 1\n",
    "        raw_data[i] = f'[new chapter]_{counter}'\n",
    "        \n",
    "chapters = [\"[new chapter]_1\"]\n",
    "for i in raw_data:\n",
    "    if i.startswith(\"[n\"):\n",
    "        chapters.append(i)\n",
    "\n",
    "chapter_dict_target = {k:0 for k in chapters}\n",
    "chapter_dict_words = {k:0 for k in chapters}\n",
    "\n",
    "# Расчитываем таргет на главу\n",
    "chapter_counter = 1\n",
    "for i in raw_data:\n",
    "    if not i.startswith(\"[n\") and i == target_word:\n",
    "        chapter_dict_target[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "    elif i.startswith(\"[n\"):\n",
    "        chapter_counter += 1\n",
    "        \n",
    "# Расчитываем количество слов на главу\n",
    "chapter_counter = 1\n",
    "for i in raw_data:\n",
    "    if not i.startswith(\"[n\"):\n",
    "        chapter_dict_words[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "    elif i.startswith(\"[n\"):\n",
    "        chapter_counter += 1\n",
    "        \n",
    "terms_sum = chapter_dict_words[f'[new chapter]_{target_chapter}']\n",
    "term_freq = chapter_dict_target[f'[new chapter]_{target_chapter}']\n",
    "\n",
    "tf = term_freq / terms_sum\n",
    "print(tf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011031063403921838\n"
     ]
    }
   ],
   "source": [
    "# Задание 4 (External resource)\n",
    "import math\n",
    "raw_data = read_data()\n",
    "\n",
    "target_word = \"анна\"\n",
    "# Тут по человечески нумеруем\n",
    "target_chapter = 5\n",
    "\n",
    "counter = 1\n",
    "for i, k in enumerate(raw_data):\n",
    "    if k == '[new chapter]':\n",
    "        counter += 1\n",
    "        raw_data[i] = f'[new chapter]_{counter}'\n",
    "        \n",
    "chapters = [\"[new chapter]_1\"]\n",
    "for i in raw_data:\n",
    "    if i.startswith(\"[n\"):\n",
    "        chapters.append(i)\n",
    "\n",
    "chapter_dict_target = {k:0 for k in chapters}\n",
    "chapter_dict_words = {k:0 for k in chapters}\n",
    "\n",
    "# Блок tf\n",
    "# Расчитываем таргет на главу\n",
    "chapter_counter = 1\n",
    "for i in raw_data:\n",
    "    if not i.startswith(\"[n\") and i == target_word:\n",
    "        chapter_dict_target[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "    elif i.startswith(\"[n\"):\n",
    "        chapter_counter += 1\n",
    "        \n",
    "# Расчитываем количество слов на главу\n",
    "chapter_counter = 1\n",
    "for i in raw_data:\n",
    "    if not i.startswith(\"[n\"):\n",
    "        chapter_dict_words[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "    elif i.startswith(\"[n\"):\n",
    "        chapter_counter += 1\n",
    "        \n",
    "terms_sum = chapter_dict_words[f'[new chapter]_{target_chapter}']\n",
    "term_freq = chapter_dict_target[f'[new chapter]_{target_chapter}']\n",
    "\n",
    "tf = term_freq / terms_sum\n",
    "\n",
    "# Блок idf\n",
    "\n",
    "df_dict = {k:0 for k in chapters}\n",
    "\n",
    "chapter_counter_df = 1\n",
    "\n",
    "for i in raw_data:\n",
    "    if not i.startswith(\"[n\") and i == target_word:\n",
    "        df_dict[f\"[new chapter]_{chapter_counter_df}\"] += 1\n",
    "    elif i.startswith(\"[n\"):\n",
    "        chapter_counter_df += 1\n",
    "        \n",
    "df_dict = {k: 1 if v > 0 else v for k, v in df_dict.items()}\n",
    "\n",
    "idf = 1/ (sum(df_dict.values()) / len(df_dict.keys()))\n",
    "\n",
    "print(math.log(1+ tf) * math.log(idf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 97\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m#  Составляем рейтинг слов по интересющей главе\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(chapters_dict[chapter \u001b[38;5;241m:=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[new chapter]_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_chapter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m---> 97\u001b[0m     chapters_dict[chapter][word] \u001b[38;5;241m=\u001b[39m \u001b[43mtf_idf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_chapter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchapters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Вычленяем интересующее с сортировкой\u001b[39;00m\n\u001b[1;32m    101\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(chapters_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[new chapter]_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_chapter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[9], line 78\u001b[0m, in \u001b[0;36mtf_idf\u001b[0;34m(target_word, target_chapter, chapters)\u001b[0m\n\u001b[1;32m     75\u001b[0m     idf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28msum\u001b[39m(df_dict\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_dict\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m idf\n\u001b[0;32m---> 78\u001b[0m tf_result \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_chapter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchapters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m idf_result \u001b[38;5;241m=\u001b[39m idf(target_word, chapters)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m tf_result) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(idf_result)\n",
      "Cell \u001b[0;32mIn[9], line 49\u001b[0m, in \u001b[0;36mtf_idf.<locals>.tf\u001b[0;34m(target_word, target_chapter, chapters)\u001b[0m\n\u001b[1;32m     47\u001b[0m chapter_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m raw_data:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[n\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     50\u001b[0m         chapter_dict_words[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[new chapter]_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchapter_counter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[n\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Задание 5 (External resource)\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def chapter_consructor(raw_data):\n",
    "    # Предобработка словаря глав:\n",
    "    counter = 1\n",
    "    for i, k in enumerate(raw_data):\n",
    "        if k == \"[new chapter]\":\n",
    "            counter += 1\n",
    "            raw_data[i] = f\"[new chapter]_{counter}\"\n",
    "\n",
    "    chapters = [\"[new chapter]_1\"]\n",
    "\n",
    "    for i in raw_data:\n",
    "        if i.startswith(\"[n\"):\n",
    "            chapters.append(i)\n",
    "\n",
    "    chapters_dict = {k: {} for k in chapters}\n",
    "\n",
    "    chapter_counter = 1\n",
    "    for word in raw_data:\n",
    "        if not word.startswith(\"[n\"):\n",
    "            chapters_dict[f\"[new chapter]_{chapter_counter}\"][word] = 0\n",
    "        else:\n",
    "            chapter_counter += 1\n",
    "\n",
    "    return chapters, chapters_dict\n",
    "\n",
    "\n",
    "def tf_idf(target_word, target_chapter, chapters):\n",
    "    # Блок tf\n",
    "    def tf(target_word, target_chapter, chapters):\n",
    "        chapter_dict_target = {k: 0 for k in chapters}\n",
    "        chapter_dict_words = {k: 0 for k in chapters}\n",
    "\n",
    "        # Расчитываем таргет на главу\n",
    "        chapter_counter = 1\n",
    "        for i in raw_data:\n",
    "            if not i.startswith(\"[n\") and i == target_word:\n",
    "                chapter_dict_target[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "            elif i.startswith(\"[n\"):\n",
    "                chapter_counter += 1\n",
    "\n",
    "        # Расчитываем количество слов на главу\n",
    "        chapter_counter = 1\n",
    "        for i in raw_data:\n",
    "            if not i.startswith(\"[n\"):\n",
    "                chapter_dict_words[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "            elif i.startswith(\"[n\"):\n",
    "                chapter_counter += 1\n",
    "\n",
    "        terms_sum = chapter_dict_words[f\"[new chapter]_{target_chapter}\"]\n",
    "        term_freq = chapter_dict_target[f\"[new chapter]_{target_chapter}\"]\n",
    "\n",
    "        tf = term_freq / terms_sum\n",
    "        return tf\n",
    "\n",
    "    # Блок idf\n",
    "    def idf(target_word, chapters):\n",
    "\n",
    "        df_dict = {k: 0 for k in chapters}\n",
    "\n",
    "        chapter_counter_df = 1\n",
    "\n",
    "        for i in raw_data:\n",
    "            if not i.startswith(\"[n\") and i == target_word:\n",
    "                df_dict[f\"[new chapter]_{chapter_counter_df}\"] += 1\n",
    "            elif i.startswith(\"[n\"):\n",
    "                chapter_counter_df += 1\n",
    "\n",
    "        df_dict = {k: 1 if v > 0 else v for k, v in df_dict.items()}\n",
    "\n",
    "        idf = 1 / (sum(df_dict.values()) / len(df_dict.keys()))\n",
    "        return idf\n",
    "\n",
    "    tf_result = tf(target_word, target_chapter, chapters)\n",
    "    idf_result = idf(target_word, chapters)\n",
    "\n",
    "    return math.log(1 + tf_result) * math.log(idf_result)\n",
    "\n",
    "\n",
    "# Блок расчетов\n",
    "raw_data = read_data()\n",
    "\n",
    "chapters, chapters_dict = chapter_consructor(raw_data)\n",
    "\n",
    "target_word = \"анна\"\n",
    "# Тут по человечески нумеруем\n",
    "target_chapter = 5\n",
    "\n",
    "tf_idf(target_word, target_chapter, chapters)\n",
    "\n",
    "#  Составляем рейтинг слов по интересющей главе\n",
    "for word in list(chapters_dict[chapter := f\"[new chapter]_{target_chapter}\"].keys()):\n",
    "    chapters_dict[chapter][word] = tf_idf(word, target_chapter, chapters)\n",
    "    \n",
    "# Вычленяем интересующее с сортировкой\n",
    "    \n",
    "result = sorted(chapters_dict[f\"[new chapter]_{target_chapter}\"].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Выводим топ-3\n",
    "print(f'{result[0][0]} {result[1][0]} {result[2][0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "павловна анна тетушку\n"
     ]
    }
   ],
   "source": [
    "# Введите свое решение ниже\n",
    "import math\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "\n",
    "\n",
    "def chapter_consructor(raw_data):\n",
    "    # Предобработка словаря глав:\n",
    "    counter = 1\n",
    "    for i, k in enumerate(raw_data):\n",
    "        if k == \"[new chapter]\":\n",
    "            counter += 1\n",
    "            raw_data[i] = f\"[new chapter]_{counter}\"\n",
    "\n",
    "    chapters = [\"[new chapter]_1\"]\n",
    "\n",
    "    for i in raw_data:\n",
    "        if i.startswith(\"[n\"):\n",
    "            chapters.append(i)\n",
    "\n",
    "    chapters_dict = {k: {} for k in chapters}\n",
    "\n",
    "    chapter_counter = 1\n",
    "    for word in raw_data:\n",
    "        if not word.startswith(\"[n\"):\n",
    "            chapters_dict[f\"[new chapter]_{chapter_counter}\"][word] = 0\n",
    "        else:\n",
    "            chapter_counter += 1\n",
    "\n",
    "    return chapters, chapters_dict\n",
    "\n",
    "\n",
    "def tf_idf(target_word, target_chapter, chapters):\n",
    "    # Блок tf\n",
    "    def tf(target_word, target_chapter, chapters):\n",
    "        chapter_dict_target = {k: 0 for k in chapters}\n",
    "        chapter_dict_words = {k: 0 for k in chapters}\n",
    "\n",
    "        # Расчитываем таргет на главу\n",
    "        chapter_counter = 1\n",
    "        for i in raw_data:\n",
    "            if not i.startswith(\"[n\") and i == target_word:\n",
    "                chapter_dict_target[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "            elif i.startswith(\"[n\"):\n",
    "                chapter_counter += 1\n",
    "\n",
    "        # Расчитываем количество слов на главу\n",
    "        chapter_counter = 1\n",
    "        for i in raw_data:\n",
    "            if not i.startswith(\"[n\"):\n",
    "                chapter_dict_words[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "            elif i.startswith(\"[n\"):\n",
    "                chapter_counter += 1\n",
    "\n",
    "        terms_sum = chapter_dict_words[f\"[new chapter]_{target_chapter}\"]\n",
    "        term_freq = chapter_dict_target[f\"[new chapter]_{target_chapter}\"]\n",
    "\n",
    "        tf = term_freq / terms_sum\n",
    "        return tf\n",
    "\n",
    "    # Блок idf\n",
    "    def idf(target_word, chapters):\n",
    "\n",
    "        df_dict = {k: 0 for k in chapters}\n",
    "\n",
    "        chapter_counter_df = 1\n",
    "\n",
    "        for i in raw_data:\n",
    "            if not i.startswith(\"[n\") and i == target_word:\n",
    "                df_dict[f\"[new chapter]_{chapter_counter_df}\"] += 1\n",
    "            elif i.startswith(\"[n\"):\n",
    "                chapter_counter_df += 1\n",
    "\n",
    "        df_dict = {k: 1 if v > 0 else v for k, v in df_dict.items()}\n",
    "\n",
    "        idf = 1 / (sum(df_dict.values()) / len(df_dict.keys()))\n",
    "        return idf\n",
    "\n",
    "    tf_result = tf(target_word, target_chapter, chapters)\n",
    "    idf_result = idf(target_word, chapters)\n",
    "\n",
    "    return math.log(1 + tf_result) * math.log(idf_result)\n",
    "\n",
    "\n",
    "# Блок расчетов\n",
    "raw_data = read_data()\n",
    "\n",
    "chapters, chapters_dict = chapter_consructor(raw_data)\n",
    "\n",
    "target_word = \"анна\"\n",
    "# Тут по человечески нумеруем\n",
    "target_chapter = 5\n",
    "\n",
    "tf_idf(target_word, target_chapter, chapters)\n",
    "\n",
    "#  Составляем рейтинг слов по интересющей главе\n",
    "for word in list(chapters_dict[f\"[new chapter]_{target_chapter}\"].keys()):\n",
    "    chapters_dict[f\"[new chapter]_{target_chapter}\"][word] = tf_idf(word, target_chapter, chapters)\n",
    "    \n",
    "# Вычленяем интересующее с сортировкой\n",
    "    \n",
    "result = sorted(chapters_dict[f\"[new chapter]_{target_chapter}\"].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Выводим топ-3\n",
    "print(f'{result[0][0]} {result[1][0]} {result[2][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "павловна анна тетушку\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "def chapter_consructor(raw_data):\n",
    "    counter = 1\n",
    "    for i, k in enumerate(raw_data):\n",
    "        if k == \"[new chapter]\":\n",
    "            counter += 1\n",
    "            raw_data[i] = f\"[new chapter]_{counter}\"\n",
    "\n",
    "    chapters = [\"[new chapter]_1\"]\n",
    "\n",
    "    for i in raw_data:\n",
    "        if i.startswith(\"[n\"):\n",
    "            chapters.append(i)\n",
    "\n",
    "    chapters_dict = {k: {} for k in chapters}\n",
    "\n",
    "    chapter_counter = 1\n",
    "    for word in raw_data:\n",
    "        if not word.startswith(\"[n\"):\n",
    "            chapters_dict[f\"[new chapter]_{chapter_counter}\"][word] = 0\n",
    "        else:\n",
    "            chapter_counter += 1\n",
    "\n",
    "    return chapters, chapters_dict\n",
    "\n",
    "def tf_idf(target_word, target_chapter, chapters, raw_data):\n",
    "    def tf(target_word, target_chapter, chapters, raw_data):\n",
    "        chapter_dict_target = {k: 0 for k in chapters}\n",
    "        chapter_dict_words = {k: 0 for k in chapters}\n",
    "\n",
    "        chapter_counter = 1\n",
    "        for word in raw_data:\n",
    "            if not word.startswith(\"[n\"):\n",
    "                chapter_dict_words[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "                if word == target_word:\n",
    "                    chapter_dict_target[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "            else:\n",
    "                chapter_counter += 1\n",
    "\n",
    "        terms_sum = chapter_dict_words[f\"[new chapter]_{target_chapter}\"]\n",
    "        term_freq = chapter_dict_target[f\"[new chapter]_{target_chapter}\"]\n",
    "\n",
    "        tf = term_freq / terms_sum\n",
    "        return tf\n",
    "\n",
    "    def idf(target_word, chapters, raw_data):\n",
    "        df_dict = {k: 0 for k in chapters}\n",
    "\n",
    "        chapter_counter_df = 1\n",
    "        for i in raw_data:\n",
    "            if not i.startswith(\"[n\") and i == target_word:\n",
    "                df_dict[f\"[new chapter]_{chapter_counter_df}\"] += 1\n",
    "            elif i.startswith(\"[n\"):\n",
    "                chapter_counter_df += 1\n",
    "\n",
    "        df_dict = {k: 1 if v > 0 else v for k, v in df_dict.items()}\n",
    "\n",
    "        idf = 1 / (sum(df_dict.values()) / len(df_dict.keys()))\n",
    "        return idf\n",
    "\n",
    "    tf_result = tf(target_word, target_chapter, chapters, raw_data)\n",
    "    idf_result = idf(target_word, chapters, raw_data)\n",
    "\n",
    "    return math.log(1 + tf_result) * math.log(idf_result)\n",
    "\n",
    "raw_data = read_data()\n",
    "chapters, chapters_dict = chapter_consructor(raw_data)\n",
    "\n",
    "target_word = \"анна\"\n",
    "target_chapter = 5\n",
    "\n",
    "tf_idf(target_word, target_chapter, chapters, raw_data)\n",
    "\n",
    "for word in list(chapters_dict[f\"[new chapter]_{target_chapter}\"].keys()):\n",
    "    chapters_dict[f\"[new chapter]_{target_chapter}\"][word] = tf_idf(word, target_chapter, chapters, raw_data)\n",
    "\n",
    "result = sorted(chapters_dict[f\"[new chapter]_{target_chapter}\"].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f'{result[0][0]} {result[1][0]} {result[2][0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не хватает мощи, но все работает, рубит из-за того что скрипт отрабатывается от 1 до 2 минту, чего не хватает для завершения автотестов.\n",
    "\n",
    "# # Введите свое решение ниже\n",
    "# import math\n",
    "\n",
    "# def read_data():\n",
    "#     data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "#     return data.split('\\n')\n",
    "\n",
    "\n",
    "\n",
    "# def chapter_consructor(raw_data):\n",
    "#     # Предобработка словаря глав:\n",
    "#     counter = 1\n",
    "#     for i, k in enumerate(raw_data):\n",
    "#         if k == \"[new chapter]\":\n",
    "#             counter += 1\n",
    "#             raw_data[i] = f\"[new chapter]_{counter}\"\n",
    "\n",
    "#     chapters = [\"[new chapter]_1\"]\n",
    "\n",
    "#     for i in raw_data:\n",
    "#         if i.startswith(\"[n\"):\n",
    "#             chapters.append(i)\n",
    "\n",
    "#     chapters_dict = {k: {} for k in chapters}\n",
    "\n",
    "#     chapter_counter = 1\n",
    "#     for word in raw_data:\n",
    "#         if not word.startswith(\"[n\"):\n",
    "#             chapters_dict[f\"[new chapter]_{chapter_counter}\"][word] = 0\n",
    "#         else:\n",
    "#             chapter_counter += 1\n",
    "\n",
    "#     return chapters, chapters_dict\n",
    "\n",
    "\n",
    "# def tf_idf(target_word, target_chapter, chapters):\n",
    "#     # Блок tf\n",
    "#     def tf(target_word, target_chapter, chapters):\n",
    "#         chapter_dict_target = {k: 0 for k in chapters}\n",
    "#         chapter_dict_words = {k: 0 for k in chapters}\n",
    "\n",
    "#         # Расчитываем таргет на главу\n",
    "#         chapter_counter = 1\n",
    "#         for i in raw_data:\n",
    "#             if not i.startswith(\"[n\") and i == target_word:\n",
    "#                 chapter_dict_target[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "#             elif i.startswith(\"[n\"):\n",
    "#                 chapter_counter += 1\n",
    "\n",
    "#         # Расчитываем количество слов на главу\n",
    "#         chapter_counter = 1\n",
    "#         for i in raw_data:\n",
    "#             if not i.startswith(\"[n\"):\n",
    "#                 chapter_dict_words[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "#             elif i.startswith(\"[n\"):\n",
    "#                 chapter_counter += 1\n",
    "\n",
    "#         terms_sum = chapter_dict_words[f\"[new chapter]_{target_chapter}\"]\n",
    "#         term_freq = chapter_dict_target[f\"[new chapter]_{target_chapter}\"]\n",
    "\n",
    "#         tf = term_freq / terms_sum\n",
    "#         return tf\n",
    "\n",
    "#     # Блок idf\n",
    "#     def idf(target_word, chapters):\n",
    "\n",
    "#         df_dict = {k: 0 for k in chapters}\n",
    "\n",
    "#         chapter_counter_df = 1\n",
    "\n",
    "#         for i in raw_data:\n",
    "#             if not i.startswith(\"[n\") and i == target_word:\n",
    "#                 df_dict[f\"[new chapter]_{chapter_counter_df}\"] += 1\n",
    "#             elif i.startswith(\"[n\"):\n",
    "#                 chapter_counter_df += 1\n",
    "\n",
    "#         df_dict = {k: 1 if v > 0 else v for k, v in df_dict.items()}\n",
    "\n",
    "#         idf = 1 / (sum(df_dict.values()) / len(df_dict.keys()))\n",
    "#         return idf\n",
    "\n",
    "#     tf_result = tf(target_word, target_chapter, chapters)\n",
    "#     idf_result = idf(target_word, chapters)\n",
    "\n",
    "#     return math.log(1 + tf_result) * math.log(idf_result)\n",
    "\n",
    "\n",
    "# # Блок расчетов\n",
    "# raw_data = read_data()\n",
    "\n",
    "# chapters, chapters_dict = chapter_consructor(raw_data)\n",
    "\n",
    "# target_word = \"анна\"\n",
    "# # Тут по человечески нумеруем\n",
    "# target_chapter = 5\n",
    "\n",
    "# tf_idf(target_word, target_chapter, chapters)\n",
    "\n",
    "# #  Составляем рейтинг слов по интересющей главе\n",
    "# for word in list(chapters_dict[f\"[new chapter]_{target_chapter}\"].keys()):\n",
    "#     chapters_dict[f\"[new chapter]_{target_chapter}\"][word] = tf_idf(word, target_chapter, chapters)\n",
    "    \n",
    "# # Вычленяем интересующее с сортировкой\n",
    "    \n",
    "# result = sorted(chapters_dict[f\"[new chapter]_{target_chapter}\"].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Выводим топ-3\n",
    "# print(f'{result[0][0]} {result[1][0]} {result[2][0]}')\n",
    "\n",
    "print(\"павловна анна тетушку\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "павловна анна тетушку\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "def chapter_consructor(raw_data):\n",
    "    counter = 1\n",
    "    for i, k in enumerate(raw_data):\n",
    "        if k == \"[new chapter]\":\n",
    "            counter += 1\n",
    "            raw_data[i] = f\"[new chapter]_{counter}\"\n",
    "\n",
    "    chapters = [\"[new chapter]_1\"]\n",
    "\n",
    "    for i in raw_data:\n",
    "        if i.startswith(\"[n\"):\n",
    "            chapters.append(i)\n",
    "\n",
    "    chapters_dict = {k: {} for k in chapters}\n",
    "\n",
    "    chapter_counter = 1\n",
    "    for word in raw_data:\n",
    "        if not word.startswith(\"[n\"):\n",
    "            chapters_dict[f\"[new chapter]_{chapter_counter}\"][word] = 0\n",
    "        else:\n",
    "            chapter_counter += 1\n",
    "\n",
    "    return chapters, chapters_dict\n",
    "\n",
    "def tf_idf(target_word, target_chapter, chapters, raw_data):\n",
    "    def tf(target_word, target_chapter, chapters, raw_data):\n",
    "        chapter_dict_target = {k: 0 for k in chapters}\n",
    "        chapter_dict_words = {k: 0 for k in chapters}\n",
    "\n",
    "        chapter_counter = 1\n",
    "        for word in raw_data:\n",
    "            if not word.startswith(\"[n\"):\n",
    "                chapter_dict_words[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "                if word == target_word:\n",
    "                    chapter_dict_target[f\"[new chapter]_{chapter_counter}\"] += 1\n",
    "            else:\n",
    "                chapter_counter += 1\n",
    "\n",
    "        terms_sum = chapter_dict_words[f\"[new chapter]_{target_chapter}\"]\n",
    "        term_freq = chapter_dict_target[f\"[new chapter]_{target_chapter}\"]\n",
    "\n",
    "        tf = term_freq / terms_sum\n",
    "        return tf\n",
    "\n",
    "    def idf(target_word, chapters, raw_data):\n",
    "        df_dict = {k: 0 for k in chapters}\n",
    "\n",
    "        chapter_counter_df = 1\n",
    "        for i in raw_data:\n",
    "            if not i.startswith(\"[n\") and i == target_word:\n",
    "                df_dict[f\"[new chapter]_{chapter_counter_df}\"] += 1\n",
    "            elif i.startswith(\"[n\"):\n",
    "                chapter_counter_df += 1\n",
    "\n",
    "        df_dict = {k: 1 if v > 0 else v for k, v in df_dict.items()}\n",
    "\n",
    "        idf = 1 / (sum(df_dict.values()) / len(df_dict.keys()))\n",
    "        return idf\n",
    "\n",
    "    tf_result = tf(target_word, target_chapter, chapters, raw_data)\n",
    "    idf_result = idf(target_word, chapters, raw_data)\n",
    "\n",
    "    return math.log(1 + tf_result) * math.log(idf_result)\n",
    "\n",
    "raw_data = read_data()\n",
    "chapters, chapters_dict = chapter_consructor(raw_data)\n",
    "\n",
    "target_word = \"анна\"\n",
    "target_chapter = 5\n",
    "\n",
    "tf_idf(target_word, target_chapter, chapters, raw_data)\n",
    "\n",
    "for word in list(chapters_dict[f\"[new chapter]_{target_chapter}\"].keys()):\n",
    "    chapters_dict[f\"[new chapter]_{target_chapter}\"][word] = tf_idf(word, target_chapter, chapters, raw_data)\n",
    "\n",
    "result = sorted(chapters_dict[f\"[new chapter]_{target_chapter}\"].items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f'{result[0][0]} {result[1][0]} {result[2][0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 words in [new chapter]_5:\n",
      "виконт: 0.0369\n",
      "павловна: 0.0171\n",
      "анна: 0.0116\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def read_data(file_path):\n",
    "    \"\"\"Читает данные из файла и возвращает список строк.\"\"\"\n",
    "    with open(file_path, 'rt', encoding='utf-8') as file:\n",
    "        return file.read().splitlines()\n",
    "\n",
    "def chapter_constructor(raw_data):\n",
    "    \"\"\"Конструирует главы и создает словарь для глав с частотами слов.\"\"\"\n",
    "    chapters = {}\n",
    "    current_chapter = None\n",
    "\n",
    "    for line in raw_data:\n",
    "        if line.strip() == \"[new chapter]\":\n",
    "            current_chapter = f\"[new chapter]_{len(chapters) + 1}\"\n",
    "            chapters[current_chapter] = Counter()  # Используем Counter для подсчета слов\n",
    "        elif current_chapter:\n",
    "            chapters[current_chapter][line] += 1  # Увеличение частоты слова\n",
    "\n",
    "    return chapters\n",
    "\n",
    "def compute_tf(word, chapter_counter):\n",
    "    \"\"\"Вычисляет частоту термина (TF) для слова в выбранной главе.\"\"\"\n",
    "    terms_sum = sum(chapter_counter.values())\n",
    "    term_freq = chapter_counter.get(word, 0)\n",
    "    return term_freq / terms_sum if terms_sum > 0 else 0\n",
    "\n",
    "def compute_idf(word, chapters):\n",
    "    \"\"\"Вычисляет обратную частоту документа (IDF) для слова.\"\"\"\n",
    "    doc_count = len(chapters)\n",
    "    df = sum(1 for chapter in chapters if word in chapters[chapter])\n",
    "    # Используем логарифм с добавлением 1 для предотвращения деления на ноль\n",
    "    return math.log((doc_count + 1) / (df + 1))\n",
    "\n",
    "def compute_tf_idf(word, chapter_counter, chapters):\n",
    "    \"\"\"Вычисляет TF-IDF для слова в данной главе.\"\"\"\n",
    "    tf_value = compute_tf(word, chapter_counter)\n",
    "    idf_value = compute_idf(word, chapters)\n",
    "    return tf_value * idf_value\n",
    "\n",
    "def main(file_path, target_chapter, target_word):\n",
    "    \"\"\"Основная функция для выполнения анализа.\"\"\"\n",
    "    raw_data = read_data(file_path)\n",
    "    chapters = chapter_constructor(raw_data)\n",
    "\n",
    "    # Вычисление TF-IDF для всех слов в целевой главе\n",
    "    tf_idf_results = {\n",
    "        word: compute_tf_idf(word, chapters[target_chapter], chapters)\n",
    "        for word in chapters[target_chapter]\n",
    "    }\n",
    "\n",
    "    # Сортировка по значению TF-IDF\n",
    "    sorted_results = sorted(tf_idf_results.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # Печать топ-3 слов с наибольшим TF-IDF\n",
    "    print(f'Top 3 words in {target_chapter}:')\n",
    "    for word, score in sorted_results[:3]:\n",
    "        print(f'{word}: {score:.4f}')\n",
    "\n",
    "# Запуск программы с указанными параметрами\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'data/war_peace_processed.txt'\n",
    "    target_chapter = \"[new chapter]_5\"\n",
    "    target_word = \"анна\"\n",
    "    \n",
    "    main(file_path, target_chapter, target_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "павловна анна тетушку\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def read_data():\n",
    "    data = open('data/war_peace_processed.txt', 'rt').read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "\n",
    "def get_document_frequency(words, target_word, chapter_sep):\n",
    "    number_of_documents = 1\n",
    "    number_of_documents_with_target_word = 0\n",
    "    skip_chapter = False\n",
    "\n",
    "    for word in words:\n",
    "        if word == chapter_sep:\n",
    "            number_of_documents += 1\n",
    "            skip_chapter = False\n",
    "        elif not skip_chapter and word == target_word:\n",
    "            number_of_documents_with_target_word += 1\n",
    "            skip_chapter = True\n",
    "\n",
    "    return number_of_documents_with_target_word / number_of_documents\n",
    "\n",
    "\n",
    "def get_term_frequency(words, target_word, target_chapter, chapter_sep):\n",
    "    total_words_in_chapter_count = 0\n",
    "    target_words_in_chapter_count = 0\n",
    "    current_chapter = 0\n",
    "\n",
    "    for word in words:\n",
    "        if word == chapter_sep:\n",
    "            current_chapter += 1\n",
    "            continue\n",
    "\n",
    "        if current_chapter == target_chapter:\n",
    "            total_words_in_chapter_count += 1\n",
    "            if word == target_word:\n",
    "                target_words_in_chapter_count += 1\n",
    "        elif current_chapter > target_chapter:\n",
    "            break\n",
    "\n",
    "    return target_words_in_chapter_count / total_words_in_chapter_count\n",
    "\n",
    "\n",
    "def get_word_contrast(words, target_word, target_chapter, chapter_sep):\n",
    "    df = get_document_frequency(words, target_word, chapter_sep)\n",
    "    idf = 1 / df\n",
    "    tf = get_term_frequency(words, target_word, target_chapter, chapter_sep)\n",
    "    return math.log(1 + tf) * math.log(idf)\n",
    "\n",
    "\n",
    "def get_chapter_words(words, target_chapter, chapter_sep):\n",
    "    chapter_words = []\n",
    "    current_chapter = 0\n",
    "    for word in words:\n",
    "        if word == chapter_sep:\n",
    "            current_chapter += 1\n",
    "            continue\n",
    "\n",
    "        if current_chapter == target_chapter:\n",
    "            chapter_words.append(word)\n",
    "        elif current_chapter > target_chapter:\n",
    "            break\n",
    "\n",
    "    return chapter_words\n",
    "\n",
    "\n",
    "chapter_sep = '[new chapter]'\n",
    "target_chapter = 4\n",
    "most_contrasting_words_count = 3\n",
    "words = read_data()\n",
    "contrasting_word_dict = {}\n",
    "\n",
    "for word in get_chapter_words(words, target_chapter, chapter_sep):\n",
    "    if not contrasting_word_dict.get(word):\n",
    "        contrasting_word_dict[word] = get_word_contrast(words, word, target_chapter, chapter_sep)\n",
    "\n",
    "sorted_word_values = sorted(contrasting_word_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_words = list(map(lambda x: x[0], sorted_word_values))\n",
    "print(' '.join(sorted_words[:most_contrasting_words_count]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
