{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение данных для коллаборативной фильтрации\n",
    "events_raw = pd.read_csv(\"./data/events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основная функция рекомендаций\n",
    "def rs_batch(data, lb_interactions, upb_ineractions, top_items):\n",
    "    lower_border = lb_interactions\n",
    "    upper_border = upb_ineractions\n",
    "    item_border = top_items\n",
    "\n",
    "    events = data.copy()\n",
    "\n",
    "    # Приведем к временному формату данные из timestapm\n",
    "    events[\"timestamp\"] = pd.to_datetime(events[\"timestamp\"], unit=\"ms\")\n",
    "    events.rename(columns={\"timestamp\": \"date\"}, inplace=True)\n",
    "    events[\"date\"] = pd.to_datetime(events[\"date\"].dt.date)\n",
    "    events = events.sort_values(\"date\").reset_index(drop=True)\n",
    "    events = events[[\"visitorid\", \"itemid\", \"event\", \"date\"]]\n",
    "\n",
    "    # Фильтруем по количеству больше 30 и оставляем только itemid и count\n",
    "    top_items = pd.DataFrame(\n",
    "        events.groupby(\"itemid\")[\"event\"].value_counts()\n",
    "    ).reset_index()\n",
    "    top_items = top_items[top_items[\"count\"] >= item_border][[\"itemid\", \"count\"]]\n",
    "    top_items = top_items.groupby(\"itemid\")[\"count\"].sum().to_dict()\n",
    "\n",
    "    # Создаем новый столбец num_occur, в котором хранится количество событий для каждого itemid\n",
    "    events[\"num_occur\"] = events[\"itemid\"].map(top_items)\n",
    "\n",
    "    # Фильтруем события, оставляем только те, у которых num_occur больше 1000\n",
    "    events_processed = events[\n",
    "        (events[\"num_occur\"] >= lower_border) & (events[\"num_occur\"] < upper_border)\n",
    "    ]\n",
    "    events_processed = events_processed.drop(columns=\"num_occur\")\n",
    "    events_processed = events_processed.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Выделяем обучающий набор данных до сентября\n",
    "    events_train = events_processed[events_processed[\"date\"].dt.month < 8]\n",
    "    # Выделяем тестовый набор данных с сентября и позже\n",
    "    events_test = events_processed[events_processed[\"date\"].dt.month >= 8]\n",
    "\n",
    "    # Фильтруем тестовый набор данных\n",
    "    events_test = events_test[\n",
    "        (events_test[\"visitorid\"].isin(events_train[\"visitorid\"]))\n",
    "        & (events_test[\"itemid\"].isin(events_train[\"itemid\"]))\n",
    "    ]\n",
    "\n",
    "    # Список категориальных признаков\n",
    "    id_cols = [\"visitorid\", \"itemid\"]\n",
    "\n",
    "    # Создаем словарь для закодированных значений обучающего набора\n",
    "    trans_cat_train = dict()\n",
    "    # Создаем словарь для закодированных значений тестового набора\n",
    "    trans_cat_test = dict()\n",
    "\n",
    "    for k in id_cols:\n",
    "        cate_enc = LabelEncoder()\n",
    "        trans_cat_train[k] = cate_enc.fit_transform(\n",
    "            events_train[k].values\n",
    "        )  # Кодируем значения обучающего набора\n",
    "        trans_cat_test[k] = cate_enc.transform(\n",
    "            events_test[k].values\n",
    "        )  # Кодируем значения тестового набора\n",
    "\n",
    "    # Создаем словарь для закодированных значений целевой переменной\n",
    "    ratings = dict()\n",
    "\n",
    "    cate_enc_2 = LabelEncoder()\n",
    "    ratings[\"train\"] = cate_enc_2.fit_transform(\n",
    "        events_train.event\n",
    "    )  # Кодируем целевую переменную для обучающего набора\n",
    "    ratings[\"test\"] = cate_enc_2.transform(\n",
    "        events_test.event\n",
    "    )  # Кодируем целевую переменную для тестового набора\n",
    "\n",
    "    # Вычисляем количество уникальных пользователей\n",
    "    n_users = len(np.unique(trans_cat_train[\"visitorid\"]))\n",
    "    # Вычисляем количество уникальных товаров\n",
    "    n_items = len(np.unique(trans_cat_train[\"itemid\"]))\n",
    "\n",
    "    # Создаем словарь для матриц оценок\n",
    "    rate_matrix = dict()\n",
    "\n",
    "    # Создаем разреженную матрицу для обучающего набора\n",
    "    rate_matrix[\"train\"] = coo_matrix(\n",
    "        (ratings[\"train\"], (trans_cat_train[\"visitorid\"], trans_cat_train[\"itemid\"])),\n",
    "        shape=(n_users, n_items),\n",
    "    )\n",
    "    # Создаем разреженную матрицу для тестового набора\n",
    "    rate_matrix[\"test\"] = coo_matrix(\n",
    "        (\n",
    "            ratings[\"test\"],  # данные\n",
    "            (trans_cat_test[\"visitorid\"], trans_cat_test[\"itemid\"]),\n",
    "        ),  # индексы строк (trans_cat_test[“visitorid”]) и индексы столбцов (trans_cat_test[“itemid”])\n",
    "        shape=(n_users, n_items),\n",
    "    )\n",
    "\n",
    "    # Создаем модель LightFM с указанием параметров\n",
    "    model = LightFM(no_components=10, loss=\"warp\")\n",
    "    # Обучаем модель на обучающей матрице\n",
    "    model.fit(rate_matrix[\"train\"], epochs=100, num_threads=8)\n",
    "\n",
    "    # Вычисляем среднюю точность на тестовой матрице для k=3\n",
    "    map_at3 = precision_at_k(model, rate_matrix[\"test\"], k=3).mean()\n",
    "    print(f\"Mean Average Precision at 3: {round(map_at3*100, 3)} %\")\n",
    "\n",
    "    # Используем обученную модель для предсказания предпочтений пользователей для товаров в тестовой выборке\n",
    "    predicted_scores = model.predict(\n",
    "        trans_cat_test[\"visitorid\"], trans_cat_test[\"itemid\"], num_threads=8\n",
    "    )\n",
    "\n",
    "    # Создаем функцию для получения предсказанных оценок для всех возможных пар (пользователь, товар) в тестовой выборке\n",
    "    def get_predicted_ratings(visitor_ids, item_ids, scores):\n",
    "        predicted_ratings = pd.DataFrame(\n",
    "            {\"visitorid\": visitor_ids, \"itemid\": item_ids, \"predicted_score\": scores}\n",
    "        )\n",
    "        return predicted_ratings\n",
    "\n",
    "    # Преобразуем полученные предсказанные оценки в датафрейм с колонками visitorid и itemid\n",
    "    predicted_ratings_df = get_predicted_ratings(\n",
    "        events_test[\"visitorid\"], events_test[\"itemid\"], predicted_scores\n",
    "    )\n",
    "\n",
    "    predicted_ratings_df = predicted_ratings_df[\n",
    "        predicted_ratings_df[\"predicted_score\"] < 0\n",
    "    ]\n",
    "\n",
    "    predicted_ratings_pivot = pd.pivot_table(\n",
    "        data=predicted_ratings_df,\n",
    "        index=\"visitorid\",\n",
    "        columns=\"itemid\",\n",
    "        values=\"predicted_score\",\n",
    "        aggfunc=\"sum\",\n",
    "    )\n",
    "\n",
    "    users = predicted_ratings_pivot.index.to_list()\n",
    "    items = predicted_ratings_pivot.columns.to_list()\n",
    "    scores = np.array(predicted_ratings_pivot)\n",
    "\n",
    "    rec_list = []\n",
    "    for i in range(len(users)):\n",
    "\n",
    "        var_list = []\n",
    "        best_var = np.argsort(scores[i])[:3].tolist()\n",
    "        for j in best_var:\n",
    "            var_list.append(items[j])\n",
    "\n",
    "        # print({users[i]: var_list})\n",
    "        rec_list.append(var_list)\n",
    "\n",
    "    recomendations = pd.DataFrame(data={\"users\": users, \"recomendations\": rec_list})\n",
    "\n",
    "    return recomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем 3 основные группы пользователей\n",
    "random_customers = rs_batch(\n",
    "    data=events_raw, lb_interactions=0, upb_ineractions=100, top_items=4\n",
    ")\n",
    "temp_customers = rs_batch(\n",
    "    data=events_raw, lb_interactions=500, upb_ineractions=1000, top_items=4\n",
    ")\n",
    "mvp_customers = rs_batch(\n",
    "    data=events_raw, lb_interactions=1000, upb_ineractions=100000, top_items=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Почистим дублирующие рекомендации для юзеров с приоритетом MVP->Temp->Random\n",
    "temp_customers = temp_customers[~temp_customers[\"users\"].isin(mvp_customers[\"users\"])]\n",
    "\n",
    "random_customers = random_customers[\n",
    "    ~random_customers[\"users\"].isin(mvp_customers[\"users\"])\n",
    "]\n",
    "random_customers = random_customers[\n",
    "    ~random_customers[\"users\"].isin(temp_customers[\"users\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируем датафрейм с рекомендациями для пользователей проявивших хоть какую-то активность\n",
    "rec_df = pd.concat([random_customers, temp_customers, mvp_customers]).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируем рекомендации для оставшихся\n",
    "# \n",
    "unique_usrs = events_raw[\"visitorid\"].unique().tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
