{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение данных для коллаборативной фильтрации\n",
    "events_raw = pd.read_csv(\"./data/events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основная функция рекомендаций\n",
    "def rs_batch(data, lb_interactions, upb_ineractions, top_items, month_border=7):\n",
    "    events = data.copy()\n",
    "\n",
    "    # Приведем к временному формату данные из timestapm\n",
    "    events[\"timestamp\"] = pd.to_datetime(events[\"timestamp\"], unit=\"ms\")\n",
    "    events.rename(columns={\"timestamp\": \"date\"}, inplace=True)\n",
    "    events[\"date\"] = pd.to_datetime(events[\"date\"].dt.date)\n",
    "    events = events.sort_values(\"date\").reset_index(drop=True)\n",
    "    events = events[[\"visitorid\", \"itemid\", \"event\", \"date\"]]\n",
    "\n",
    "    # Фильтруем по количеству больше указываемой отметки и оставляем только itemid и count\n",
    "    item_border = top_items\n",
    "\n",
    "    top_items = pd.DataFrame(\n",
    "        events.groupby(\"itemid\")[\"event\"].value_counts()\n",
    "    ).reset_index()\n",
    "    top_items = top_items[top_items[\"count\"] >= item_border][[\"itemid\", \"count\"]]\n",
    "    top_items = top_items.groupby(\"itemid\")[\"count\"].sum().to_dict()\n",
    "\n",
    "    # Создаем новый столбец num_occur, в котором хранится количество событий для каждого itemid\n",
    "    # сюда входят просмотры, добавления и покупки\n",
    "    events[\"num_occur\"] = events[\"itemid\"].map(top_items)\n",
    "\n",
    "    # Фильтруем события, оставляем только те, у которых num_occur находится в заданом интервале\n",
    "    lower_border = lb_interactions\n",
    "    upper_border = upb_ineractions\n",
    "\n",
    "    events_processed = events[\n",
    "        (events[\"num_occur\"] >= lower_border) & (events[\"num_occur\"] < upper_border)\n",
    "    ]\n",
    "    events_processed = events_processed.drop(columns=\"num_occur\")\n",
    "    events_processed = events_processed.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Выделяем обучающий набор данных до указаной отметки\n",
    "    events_train = events_processed[events_processed[\"date\"].dt.month < month_border]\n",
    "    # Выделяем тестовый набор данных после указаной отметки\n",
    "    events_test = events_processed[events_processed[\"date\"].dt.month >= month_border]\n",
    "\n",
    "    # Фильтруем тестовый набор данных\n",
    "    events_test = events_test[\n",
    "        (events_test[\"visitorid\"].isin(events_train[\"visitorid\"]))\n",
    "        & (events_test[\"itemid\"].isin(events_train[\"itemid\"]))\n",
    "    ]\n",
    "\n",
    "    # Список категориальных признаков\n",
    "    id_cols = [\"visitorid\", \"itemid\"]\n",
    "\n",
    "    # Создаем словарь для закодированных значений обучающего набора\n",
    "    trans_cat_train = dict()\n",
    "    # Создаем словарь для закодированных значений тестового набора\n",
    "    trans_cat_test = dict()\n",
    "    \n",
    "    # Применяем кодирование юзеров и айтемов\n",
    "    for k in id_cols:\n",
    "        cate_enc = LabelEncoder()\n",
    "        trans_cat_train[k] = cate_enc.fit_transform(\n",
    "            events_train[k].values\n",
    "        )  # Кодируем значения обучающего набора\n",
    "        trans_cat_test[k] = cate_enc.transform(\n",
    "            events_test[k].values\n",
    "        )  # Кодируем значения тестового набора\n",
    "\n",
    "    # Создаем словарь для закодированных значений целевой переменной\n",
    "    ratings = dict()\n",
    "    \n",
    "    cate_enc_2 = LabelEncoder()\n",
    "    ratings[\"train\"] = cate_enc_2.fit_transform(\n",
    "        events_train.event\n",
    "    )  # Кодируем целевую переменную для обучающего набора\n",
    "    ratings[\"test\"] = cate_enc_2.transform(\n",
    "        events_test.event\n",
    "    )  # Кодируем целевую переменную для тестового набора\n",
    "\n",
    "    # Вычисляем количество уникальных пользователей\n",
    "    n_users = len(np.unique(trans_cat_train[\"visitorid\"]))\n",
    "    # Вычисляем количество уникальных товаров\n",
    "    n_items = len(np.unique(trans_cat_train[\"itemid\"]))\n",
    "\n",
    "    # Создаем словарь для матриц оценок\n",
    "    rate_matrix = dict()\n",
    "\n",
    "    # Создаем разреженную матрицу для обучающего набора\n",
    "    rate_matrix[\"train\"] = coo_matrix(\n",
    "        (ratings[\"train\"], (trans_cat_train[\"visitorid\"], trans_cat_train[\"itemid\"])),\n",
    "        shape=(n_users, n_items),\n",
    "    )\n",
    "    # Создаем разреженную матрицу для тестового набора\n",
    "    rate_matrix[\"test\"] = coo_matrix(\n",
    "        (\n",
    "            ratings[\"test\"],  # данные\n",
    "            (trans_cat_test[\"visitorid\"], trans_cat_test[\"itemid\"]),\n",
    "        ),  # индексы строк (trans_cat_test[“visitorid”]) и индексы столбцов (trans_cat_test[“itemid”])\n",
    "        shape=(n_users, n_items),\n",
    "    )\n",
    "\n",
    "    # Создаем модель LightFM с указанием параметров\n",
    "    model = LightFM(no_components=50, loss=\"warp\")\n",
    "    # Обучаем модель на обучающей матрице\n",
    "    model.fit(rate_matrix[\"train\"], epochs=100, num_threads=8)\n",
    "\n",
    "    # Вычисляем среднюю точность на тестовой матрице для k=3\n",
    "    map_at3 = precision_at_k(model, rate_matrix[\"test\"], k=3).mean()\n",
    "    print(f\"For batch {lb_interactions}-{upb_ineractions} interactions\")\n",
    "    print(f\"Mean Average Precision at 3: {round(map_at3*100, 3)} %.\")\n",
    "\n",
    "    # Используем обученную модель для предсказания предпочтений пользователей для товаров в тестовой выборке\n",
    "    predicted_scores = model.predict(\n",
    "        trans_cat_test[\"visitorid\"], trans_cat_test[\"itemid\"], num_threads=8\n",
    "    )\n",
    "\n",
    "    # Создаем функцию для получения предсказанных оценок для всех возможных пар (пользователь, товар) в тестовой выборке\n",
    "    def get_predicted_ratings(visitor_ids, item_ids, scores):\n",
    "        predicted_ratings = pd.DataFrame(\n",
    "            {\"visitorid\": visitor_ids, \"itemid\": item_ids, \"predicted_score\": scores}\n",
    "        )\n",
    "        return predicted_ratings\n",
    "\n",
    "    # Преобразуем полученные предсказанные оценки в датафрейм с колонками visitorid и itemid\n",
    "    predicted_ratings_df = get_predicted_ratings(\n",
    "        events_test[\"visitorid\"], events_test[\"itemid\"], predicted_scores\n",
    "    )\n",
    "    \n",
    "    # Берем только отрицательные значения ибо они то нам и нужны\n",
    "    predicted_ratings_df = predicted_ratings_df[\n",
    "        predicted_ratings_df[\"predicted_score\"] < 0\n",
    "    ]\n",
    "    \n",
    "    # Создаем сводную содержащую скоры ны пересечении айтемов и юзеров\n",
    "    predicted_ratings_pivot = pd.pivot_table(\n",
    "        data=predicted_ratings_df,\n",
    "        index=\"visitorid\",\n",
    "        columns=\"itemid\",\n",
    "        values=\"predicted_score\",\n",
    "        aggfunc=\"sum\",\n",
    "    )\n",
    "    \n",
    "    # Вытащим внутрености сводной\n",
    "    users = predicted_ratings_pivot.index.to_list()\n",
    "    items = predicted_ratings_pivot.columns.to_list()\n",
    "    scores = np.array(predicted_ratings_pivot)\n",
    "    \n",
    "    # Начинаем вытаскивать предикты ибо lightfm возвращает индексы\n",
    "    rec_list = []\n",
    "    \n",
    "    # Проходимся циклом по юзерам\n",
    "    for i in range(len(users)):\n",
    "        var_list = []\n",
    "        # Ищем 3 максимальных индекса\n",
    "        best_var = np.argsort(scores[i])[:3].tolist()\n",
    "        \n",
    "        # Бежим по индексам и вытаскиваем айтемы\n",
    "        for j in best_var:\n",
    "            var_list.append(items[j])\n",
    "\n",
    "        rec_list.append(var_list)\n",
    "    \n",
    "    # Заворачиваем в датафрейм\n",
    "    recomendations = pd.DataFrame(data={\"users\": users, \"recomendations\": rec_list})\n",
    "\n",
    "    return recomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rs_system(data_rs):\n",
    "\n",
    "    # Формируем 3 основные группы пользователей\n",
    "    # Рандомов с ниским количеством интеракций\n",
    "    random_customers = rs_batch(\n",
    "        data=data_rs, lb_interactions=0, upb_ineractions=1000, top_items=4\n",
    "    )\n",
    "    \n",
    "    # Посльзователей из средней группы\n",
    "    temp_customers = rs_batch(\n",
    "        data=data_rs, lb_interactions=1000, upb_ineractions=1500, top_items=10\n",
    "    )\n",
    "    \n",
    "    # И самых выжных\n",
    "    mvp_customers = rs_batch(\n",
    "        data=data_rs, lb_interactions=1500, upb_ineractions=100000, top_items=10\n",
    "    )\n",
    "\n",
    "    # Почистим дублирующие рекомендации для юзеров с приоритетом MVP->Temp->Random\n",
    "    temp_customers = temp_customers[\n",
    "        ~temp_customers[\"users\"].isin(mvp_customers[\"users\"])\n",
    "    ]\n",
    "\n",
    "    random_customers = random_customers[\n",
    "        ~random_customers[\"users\"].isin(mvp_customers[\"users\"])\n",
    "    ]\n",
    "    random_customers = random_customers[\n",
    "        ~random_customers[\"users\"].isin(temp_customers[\"users\"])\n",
    "    ]\n",
    "\n",
    "    recomendation_df = pd.concat(\n",
    "        [random_customers, temp_customers, mvp_customers]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    return recomendation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дефолтная рекомендация\n",
    "def default_recommendation(data_raw, data_rec):\n",
    "    # Получим топ-3 товара\n",
    "    data = data_raw.copy()\n",
    "    \n",
    "    top_3_items = (\n",
    "        data[data[\"event\"] == \"transaction\"][\"itemid\"]\n",
    "        .value_counts()[:3]\n",
    "        .index.to_list()\n",
    "    )\n",
    "    top_3_items\n",
    "\n",
    "    # Вытащим всех уникальных пользователей\n",
    "    unique_usrs = set(data[\"visitorid\"])\n",
    "\n",
    "    # Юзеры для которых были сгенерированы рекомендации\n",
    "    recommended_users = set(data_rec[\"users\"])\n",
    "\n",
    "    default_usr = list(unique_usrs - recommended_users)\n",
    "    default_rec = pd.DataFrame(data={\"users\": default_usr, \"recomendations\": 0})\n",
    "    default_rec[\"recomendations\"] = default_rec[\"recomendations\"].apply(\n",
    "        lambda x: top_3_items\n",
    "    )\n",
    "\n",
    "    return default_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0-1000 interactions\n",
      "Mean Average Precision at 3: 6.375 %.\n",
      "For batch 1000-1500 interactions\n",
      "Mean Average Precision at 3: 31.301 %.\n",
      "For batch 1500-100000 interactions\n",
      "Mean Average Precision at 3: 30.62 %.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        recommendation_df = rs_system(events_raw)\n",
    "        default_rec_df = default_recommendation(events_raw, recommendation_df)\n",
    "        final_df = pd.concat([recommendation_df, default_rec_df]).reset_index(drop=True)\n",
    "    except KeyError:\n",
    "        print(\"Проверьте источник данных на соответствие структуре\")\n",
    "    except ValueError:\n",
    "        print(\"Вероятное превышение границы временного интервала в rs_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
